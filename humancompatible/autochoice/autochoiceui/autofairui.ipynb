{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-07 07:25:15.713001: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-07 07:25:15.719497: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-05-07 07:25:15.726554: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-05-07 07:25:15.728682: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-05-07 07:25:15.734313: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-05-07 07:25:16.113718: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/kddlab/anaconda3/lib/python3.11/site-packages/torch/_functorch/deprecated.py:61: UserWarning: We've integrated functorch into PyTorch. As the final step of the integration, functorch.vmap is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use torch.vmap instead; see the PyTorch 2.0 release notes and/or the torch.func migration guide for more details https://pytorch.org/docs/master/func.migrating.html\n",
      "  warn_deprecated('vmap', 'torch.vmap')\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import VBox, Layout, Button\n",
    "#from IPython.display import HTML, display\n",
    "from IPython.display import display\n",
    "from ipywidgets import HTML\n",
    "\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "import hydra\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "# AIF 360\n",
    "from aif360.detectors.mdss.ScoringFunctions import Bernoulli\n",
    "from aif360.detectors.mdss.MDSS import MDSS\n",
    "from aif360.sklearn.datasets.openml_datasets import fetch_adult\n",
    "from aif360.sklearn.detectors.facts.clean import clean_dataset\n",
    "from aif360.algorithms.preprocessing.optim_preproc_helpers.data_preproc_functions import load_preproc_data_adult\n",
    "from aif360.sklearn.detectors.facts import FACTS_bias_scan, FACTS\n",
    "from aif360.sklearn.metrics import ot_distance\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Plots\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Sklearn imports\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# DiCE\n",
    "import dice_ml\n",
    "from dice_ml.utils import helpers  # helper functions\n",
    "import io\n",
    "import base64\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "from typing import Any, Dict, List, Mapping, Optional, Tuple\n",
    "\n",
    "DATA_HELPER_PATH = os.path.join(\"..\", \"autochoicebackend\", \"data_helper.py\")\n",
    "\n",
    "from data_helper import *\n",
    "#init_mlflow_from_cfg, mlflow_client_from_cfg\n",
    "\n",
    "\n",
    "def mlflow_init_cfg(\n",
    "    config_dir: Optional[Union[str, Path]] = None,\n",
    "    *,\n",
    "    config_name: str = \"config\",\n",
    "    honor_env_var: bool = True,\n",
    ") -> Tuple[DictConfig, MlflowClient]:\n",
    "    \"\"\"\n",
    "    Initialize MLflow from a Hydra config and return (cfg, MlflowClient).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    config_dir : str | Path | None, optional\n",
    "        Directory containing the Hydra YAML (e.g., ``humancompatible`` if your\n",
    "        file lives at ``humancompatible/config.yaml``). If ``None``, this function\n",
    "        will use the environment variable ``AUTOCHOICE_CONFIG_DIR`` when\n",
    "        ``honor_env_var=True``, otherwise it defaults to ``Path.cwd() / 'humancompatible'``.\n",
    "    config_name : str, default=\"config\"\n",
    "        Base name of the YAML file (without extension).\n",
    "    honor_env_var : bool, default=True\n",
    "        If True, use ``AUTOCHOICE_CONFIG_DIR`` when ``config_dir`` is not provided.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    cfg : omegaconf.DictConfig\n",
    "        The composed Hydra configuration.\n",
    "    client : mlflow.tracking.MlflowClient\n",
    "        An MLflow client configured according to the YAML.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    - This function clears any previous Hydra global state so it can be safely\n",
    "      re-run in notebooks without raising \"Hydra is already initialized\".\n",
    "    - It calls :func:`init_mlflow_from_cfg` to set tracking/registry URIs and env\n",
    "      variables, then builds a :class:`MlflowClient` via\n",
    "      :func:`mlflow_client_from_cfg`.\n",
    "    \"\"\"\n",
    "    # Resolve the config directory\n",
    "    if config_dir is None and honor_env_var:\n",
    "        env_dir = Path(str(Path.cwd() / \"humancompatible\"))  # sensible default\n",
    "        auto_env = os.environ.get(\"AUTOCHOICE_CONFIG_DIR\")\n",
    "        config_dir = Path(auto_env) if auto_env else env_dir\n",
    "    elif config_dir is None:\n",
    "        config_dir = Path.cwd() / \"humancompatible\"\n",
    "    else:\n",
    "        config_dir = Path(config_dir)\n",
    "\n",
    "    cfg_path = config_dir / f\"{config_name}.yaml\"\n",
    "    if not cfg_path.exists():\n",
    "        raise FileNotFoundError(f\"Config not found: {cfg_path}\")\n",
    "\n",
    "    # Hydra-safe init for notebooks\n",
    "    GlobalHydra.instance().clear()\n",
    "    with initialize(version_base=None, config_path=str(config_dir)):\n",
    "        cfg: DictConfig = compose(config_name=config_name)\n",
    "\n",
    "    # Initialize MLflow from YAML and return a matching client\n",
    "    init_mlflow_from_cfg(cfg)\n",
    "    client = mlflow_client_from_cfg(cfg)\n",
    "    return cfg, client\n",
    "\n",
    "\n",
    "\n",
    "def load_hydra_config(config_path=\"config.yaml\"):\n",
    "    \"\"\"\n",
    "    Load the configuration file using OmegaConf for use in a Voila-compatible notebook.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(config_path):\n",
    "        raise FileNotFoundError(f\"Configuration file '{config_path}' not found. Ensure it exists.\")\n",
    "    return OmegaConf.load(config_path)\n",
    "\n",
    "# Load config\n",
    "config = load_hydra_config()\n",
    "\n",
    "# Access URI and set it\n",
    "mlflow.set_tracking_uri(config.mlflow.tracking_uri)\n",
    "# MLFLOW_TRACKING_URI = \"http://192.168.1.151:5000\"\n",
    "# mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "\n",
    "PARALLEL_SCRIPT_PATH = os.path.join(\"..\", \"autochoicebackend\", \"run_experiments_parallel.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe56faf377fe4eddb0af81dd248df61f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.mi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Include the Font Awesome CSS\n",
    "font_awesome_link = HTML('<link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css\" />')\n",
    "display(font_awesome_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c12d3a35ecb45c2a1afd4852e733b7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<style>.my-font {\\n    font-family: optima;\\n    font-size: medium;\\n}\\n\\n.circular {\\n    border-…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Embed the CSS file\n",
    "with open('style.css', 'r') as css_file:\n",
    "    css_content = css_file.read()\n",
    "    display(HTML(f'<style>{css_content}</style>'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_navigation_buttons():\n",
    "    # Custom CSS for the buttons\n",
    "    custom_css = \"\"\"\n",
    "    <style>\n",
    "        .custom-nav-button {\n",
    "            background-color: MediumSeaGreen !important;  /* Green background */\n",
    "            color: white !important;               /* White text */\n",
    "            border: none;                          /* No border */\n",
    "            padding: 10px 20px;                    /* Padding */\n",
    "            text-align: center;                    /* Centered text */\n",
    "            text-decoration: none;                 /* No underline */\n",
    "            display: inline-block;                 /* Inline-block display */\n",
    "            font-size: 16px;                       /* Font size */\n",
    "            margin: 4px 2px;                       /* Margin */\n",
    "            cursor: pointer;                       /* Pointer cursor on hover */\n",
    "            border-radius: 5px;                    /* Rounded corners */\n",
    "            line-height: 1.2;                      /* Line height */\n",
    "            vertical-align: middle;                /* Vertical alignment */\n",
    "        }\n",
    "        .custom-nav-button:hover {\n",
    "            background-color: #45a049;             /* Darker green on hover */\n",
    "        }\n",
    "    </style>\n",
    "    \"\"\"\n",
    "\n",
    "    # Display the CSS\n",
    "    display(HTML(custom_css))\n",
    "\n",
    "    # Create back button\n",
    "    back_button = widgets.Button(\n",
    "        description='Back',\n",
    "        layout=widgets.Layout(width='100px', height='40px', margin='5px 5px 5px 5px'),\n",
    "        style={'button_color': 'lightgray'}\n",
    "    )\n",
    "    back_button.add_class('custom-nav-button')\n",
    "    \n",
    "    # Create next button\n",
    "    next_button = widgets.Button(\n",
    "        description='Next',\n",
    "        layout=widgets.Layout(width='100px', height='40px', margin='5px 5px 5px 5px'),\n",
    "        style={'button_color': 'lightgray'}\n",
    "    )\n",
    "    next_button.add_class('custom-nav-button')\n",
    "    \n",
    "    return back_button, next_button\n",
    "\n",
    "\n",
    "\n",
    "current_state = None\n",
    "\n",
    "prev_state = {\"Data\" : None, \"Analyze\" : \"Data\", \"Features\" : \"Analyze\", \"Model\" : \"Features\", \"Parameters\" : \"Model\", \"Run\": \"Parameters\"}\n",
    "\n",
    "next_state = {\"Data\" : \"Analyze\", \"Analyze\" : \"Features\", \"Features\" : \"Model\", \"Model\" : \"Parameters\", \"Parameters\" : \"Run\"}\n",
    "\n",
    "\n",
    "\n",
    "def on_back_button_click(b):\n",
    "    if prev_state[current_state] == \"Data\":\n",
    "        upload_bias_detection_data(b)\n",
    "    elif prev_state[current_state] == \"Analyze\":\n",
    "        dataset_analysis(b)\n",
    "    elif prev_state[current_state] == \"Features\":\n",
    "        select_features(b)\n",
    "    elif prev_state[current_state] == \"Model\":\n",
    "        give_model_to_detect_bias_updated_checkboxes_new(b)\n",
    "    elif prev_state[current_state] == \"Parameters\":\n",
    "        give_parameters_updated_and_extended_all_newer_integr(b)\n",
    "        \n",
    "def on_next_button_click(b):\n",
    "    if next_state[current_state] == \"Analyze\":\n",
    "        dataset_analysis(b)\n",
    "    elif next_state[current_state] == \"Features\":\n",
    "        select_features(b)\n",
    "    elif next_state[current_state] == \"Model\":\n",
    "        give_model_to_detect_bias_updated_checkboxes_new(b)\n",
    "    elif next_state[current_state] == \"Parameters\":\n",
    "        give_parameters_updated_and_extended_all_newer_integr(b)\n",
    "    elif next_state[current_state] == \"Run\":\n",
    "        run_bias_detection_newer_version(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "567d0c146f1349b69eb3d9ad6a6b7f13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='\\n    <style>\\n        .custom-nav-button {\\n            background-color: MediumSeaGreen !importa…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Global variables\n",
    "global_output = widgets.Output()\n",
    "header = widgets.VBox()\n",
    "steps_box = widgets.HBox()\n",
    "\n",
    "back_button, next_button = create_navigation_buttons()\n",
    "back_button.on_click(on_back_button_click)\n",
    "next_button.on_click(on_next_button_click)\n",
    "\n",
    "nav_buttons_box = widgets.HBox([back_button, next_button], layout=widgets.Layout(justify_content='space-between'))\n",
    "\n",
    "output_status = widgets.HTML(\n",
    "    value='',\n",
    "    layout=widgets.Layout(margin='0px', width='100%', padding='5px 0px 5px 0px')\n",
    ")\n",
    "features_status_output = widgets.Output()\n",
    "\n",
    "df = None # Store the dataset here\n",
    "selected_dataset = None\n",
    "selected_algorithm = None\n",
    "selected_algorithm_parameters = dict()\n",
    "\n",
    "x = None \n",
    "y = None \n",
    "sample_weight = None\n",
    "\n",
    "home_grid = None\n",
    "features_4_scanning = None\n",
    "random_seed = 131313 # for reproducibility\n",
    "\n",
    "not_to_change_features = None\n",
    "has_selected_not_to_change_features = False\n",
    "not_to_change_features_status_output = widgets.Output(layout=widgets.Layout(margin='10px 10px', padding='5px 0px 5px 0px'))\n",
    "\n",
    "# Map the dataset names to dataset files\n",
    "dataset_name_2_file_name = dict()\n",
    "dataset_name_2_file_name['Ad Campaign'] = \"ad_campaign_data_small.csv\"\n",
    "dataset_name_2_file_name['Workable'] = \"dataset1M.parquet\"\n",
    "# Dataset options with \"Learn more\" links\n",
    "dataset_options = [\n",
    "    {'name': 'Ad Campaign', 'url': 'https://developer.ibm.com/exchanges/data/all/bias-in-advertising/'},\n",
    "    {'name': 'Adult (Census Income)', 'url': 'https://archive.ics.uci.edu/dataset/2/adult'},\n",
    "    {'name': 'Workable', 'url': 'https://workable.com'}\n",
    "]\n",
    "\n",
    "def set_variables():\n",
    "    global df, features_4_scanning, home_grid, has_selected_features\n",
    "    df = None # Store the dataset here\n",
    "    has_selected_features = False\n",
    "    features_4_scanning = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display functions\n",
    "def display_info_box(algorithm, dataset):\n",
    "    info_message = f\"\"\"\n",
    "    <div style=\"background-color: #f0f0f0; border: 1px solid #ccc; border-radius: 5px; padding: 10px; width: auto; margin: 10px auto; text-align: left;\">\n",
    "        <span style=\"font-weight: bold; color: #333333; font-size: 16px\">How to interpret the bias detection results?</span>\n",
    "        <p>We are using the algorithm <b>{algorithm}</b> on the dataset '<b>{dataset}</b>'.</p>\n",
    "        <p>The algorithm found the above subset as biased. Following is the distribution of values for each feature of the biased subset to help you analyze and understand their impact on the overall model performance.</p>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    display(HTML(info_message))\n",
    "\n",
    "def display_message(message, color='black', font_size='16px', font_weight='normal'):\n",
    "    html_message = widgets.HTML(\n",
    "        value=f\"<span style='color: {color}; font-size: {font_size}; font-weight: {font_weight};'>{message}</span>\",\n",
    "        layout=widgets.Layout(width='95%')\n",
    "    )\n",
    "    display(html_message)\n",
    "    \n",
    "def display_running_animation(color='black', duration=5):\n",
    "    # Create the initial message widget\n",
    "    running_msg = widgets.HTML(\n",
    "        value='',\n",
    "        layout=widgets.Layout(margin='0px', width='100%', padding='5px 0px 5px 0px')\n",
    "    )\n",
    "    display(running_msg)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    while time.time() - start_time < duration:\n",
    "        for i in range(4):  # For number of dots from 0 to 3\n",
    "            dots = '.' * i\n",
    "            running_message = f\"\"\"\n",
    "            <div style=\"background-color: #f0f0f0; border: 1px solid #ccc; color: {color}; padding: 10px; border-radius: 5px;\">\n",
    "                <span style=\"font-weight: bold;\">Running{dots}</span>\n",
    "            </div>\n",
    "            \"\"\"\n",
    "            running_msg.value = running_message\n",
    "            time.sleep(0.5) \n",
    "\n",
    "def display_dataframe_styled(dataframe):\n",
    "    # Apply your styling to the dataframe\n",
    "    styled_df = dataframe.style.set_properties(**{\n",
    "        'background-color': 'white',  # Background color\n",
    "        'border': '1px solid lightgray',  # Border properties\n",
    "        'font-size': '14px',  # Adjust font size\n",
    "        'text-align': 'left',  # Text alignment\n",
    "        'width': '95%',\n",
    "    }).set_table_styles([{\n",
    "        'selector': 'th',\n",
    "        'props': [\n",
    "            ('background-color', '#f4f4f4'),  # Header background color\n",
    "            ('text-align', 'left')]  # Header text alignment\n",
    "    }])\n",
    "\n",
    "    # Display the centered HTML\n",
    "    display(styled_df)\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import base64\n",
    "import io\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "\n",
    "def plot_histogram_grid_top10_spaced(df):\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "    features = df.columns\n",
    "    num_features = len(features)\n",
    "    num_cols = 2  # Fewer columns to give more width per plot\n",
    "    num_rows = num_features // num_cols + (num_features % num_cols > 0)\n",
    "\n",
    "    fig, axes = plt.subplots(num_rows, num_cols, figsize=(12 * num_cols, 5 * num_rows))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i, feature in enumerate(features):\n",
    "        ax = axes[i]\n",
    "        series = df[feature].dropna()\n",
    "\n",
    "        try:\n",
    "            is_numeric = pd.api.types.is_numeric_dtype(series)\n",
    "\n",
    "            if is_numeric:\n",
    "                sns.histplot(data=series, bins=20, kde=True, ax=ax, color=sns.color_palette(\"Set2\")[i % 8])\n",
    "            else:\n",
    "                top10 = series.value_counts().nlargest(10)\n",
    "                sns.barplot(x=top10.index, y=top10.values, ax=ax, color=sns.color_palette(\"Set2\")[i % 8])\n",
    "                ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha='right', fontsize=10)\n",
    "\n",
    "            ax.set_title(f'Histogram of {feature}', fontsize=14, fontweight='bold')\n",
    "            ax.set_xlabel(feature, fontsize=12)\n",
    "            ax.set_ylabel('Frequency', fontsize=12)\n",
    "\n",
    "        except Exception as e:\n",
    "            ax.text(0.5, 0.5, f'Error: {str(e)}', ha='center', va='center')\n",
    "\n",
    "    for i in range(num_features, len(axes)):\n",
    "        fig.delaxes(axes[i])\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95], h_pad=3.0, w_pad=3.0)\n",
    "\n",
    "    img_buf = io.BytesIO()\n",
    "    plt.savefig(img_buf, format='png', bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    img_buf.seek(0)\n",
    "\n",
    "    img_base64 = base64.b64encode(img_buf.read()).decode('utf-8')\n",
    "    img_html = f'<div style=\"width: 90%; margin: auto; text-align: center;\"><img src=\"data:image/png;base64,{img_base64}\" style=\"width: 100%;\"/></div>'\n",
    "    display(HTML(img_html))\n",
    "\n",
    "\n",
    "def plot_histogram_grid_new(df):\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "    features = df.columns\n",
    "    num_features = len(features)\n",
    "    num_rows = num_features // 3 + (num_features % 3 > 0)\n",
    "\n",
    "    fig, axes = plt.subplots(num_rows, 3, figsize=(18, 5 * num_rows))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i, feature in enumerate(features):\n",
    "        ax = axes[i]\n",
    "        \n",
    "        # Ensure the column is numeric and drop NaNs\n",
    "        try:\n",
    "            data = pd.to_numeric(df[feature], errors='coerce').dropna()\n",
    "            if len(data) == 0:\n",
    "                ax.text(0.5, 0.5, 'No valid data', ha='center', va='center')\n",
    "                continue\n",
    "\n",
    "            sns.histplot(data=data, bins=20, kde=True, ax=ax, color=sns.color_palette(\"Set2\")[i % 8])\n",
    "            ax.set_title(f'Histogram of {feature}', fontsize=14, fontweight='bold')\n",
    "            ax.set_xlabel(feature, fontsize=12)\n",
    "            ax.set_ylabel('Frequency', fontsize=12)\n",
    "\n",
    "            if len(data.unique()) > 10:\n",
    "                ax.set_xticks(ax.get_xticks()[::3])\n",
    "\n",
    "            ax.tick_params(axis='x', rotation=45)\n",
    "\n",
    "        except Exception as e:\n",
    "            ax.text(0.5, 0.5, f'Error: {str(e)}', ha='center', va='center')\n",
    "\n",
    "    # Remove unused axes\n",
    "    for i in range(num_features, len(axes)):\n",
    "        fig.delaxes(axes[i])\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Encode and display the image\n",
    "    img_buf = io.BytesIO()\n",
    "    plt.savefig(img_buf, format='png', bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    img_buf.seek(0)\n",
    "\n",
    "    img_base64 = base64.b64encode(img_buf.read()).decode('utf-8')\n",
    "    img_html = f'<div style=\"width: 90%; margin: auto; text-align: center;\"><img src=\"data:image/png;base64,{img_base64}\" style=\"width: 100%;\"/></div>'\n",
    "    display(HTML(img_html))\n",
    "\n",
    "\n",
    "\n",
    "# Old function\n",
    "def plot_histogram_grid(features):\n",
    "    sns.set_theme(style=\"whitegrid\")  # Use a white grid theme\n",
    "    num_features = len(features)\n",
    "    num_rows = num_features // 3 + (num_features % 3 > 0)  # Calculate the number of rows for the grid\n",
    "    \n",
    "    fig, axes = plt.subplots(num_rows, 3, figsize=(18, 5 * num_rows))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i, feature in enumerate(features):\n",
    "        ax = axes[i]\n",
    "        sns.histplot(data=df, x=feature, bins=20, kde=True, ax=ax, color=sns.color_palette(\"Set2\")[i % 8])\n",
    "        ax.set_title(f'Histogram of {feature}', fontsize=14, fontweight='bold')\n",
    "        ax.set_xlabel(feature, fontsize=12)\n",
    "        ax.set_ylabel('Frequency', fontsize=12)\n",
    "        ax.tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # Reduce the number of x-axis ticks\n",
    "        if len(df[feature].unique()) > 10:  # Adjust the threshold as needed\n",
    "            ax.set_xticks(ax.get_xticks()[::3])\n",
    "        \n",
    "        ax.tick_params(axis='x', rotation=45)\n",
    "        \n",
    "    # Remove any empty subplots\n",
    "    for i in range(num_features, len(axes)):\n",
    "        fig.delaxes(axes[i])\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Convert the figure to a PNG image in memory\n",
    "    img_buf = io.BytesIO()\n",
    "    plt.savefig(img_buf, format='png', bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    img_buf.seek(0)\n",
    "    \n",
    "    # Encode the image in base64 and display it within an HTML block that centers it\n",
    "    img_base64 = base64.b64encode(img_buf.read()).decode('utf-8')\n",
    "    img_html = f'<div style=\"width: 90%; margin: auto; text-align: center;\"><img src=\"data:image/png;base64,{img_base64}\" style=\"width: 100%;\"/></div>'\n",
    "    display(HTML(img_html))\n",
    "\n",
    "# New but still not working function\n",
    "# def plot_histogram_grid(features):\n",
    "#     sns.set_theme(style=\"whitegrid\")  # Use a white grid theme\n",
    "\n",
    "#     # Filter out features that cannot be plotted\n",
    "#     valid_features = []\n",
    "#     for feature in features:\n",
    "#         if pd.api.types.is_numeric_dtype(df[feature]) or pd.api.types.is_categorical_dtype(df[feature]):\n",
    "#             valid_features.append(feature)\n",
    "#     with global_output:\n",
    "#         display(valid_features)\n",
    "        \n",
    "#     num_features = len(valid_features)\n",
    "#     num_cols = 3\n",
    "#     num_rows = (num_features + num_cols - 1) // num_cols  # Calculate the number of rows needed\n",
    "    \n",
    "#     fig, axes = plt.subplots(num_rows, num_cols, figsize=(18, 5 * num_rows))\n",
    "#     axes = axes.flatten()\n",
    "\n",
    "#     for i, feature in enumerate(valid_features):\n",
    "#         ax = axes[i]\n",
    "#         sns.histplot(data=df, x=feature, bins=20, kde=True, ax=ax, color=sns.color_palette(\"Set2\")[i % 8])\n",
    "#         ax.set_title(f'Histogram of {feature}', fontsize=14, fontweight='bold')\n",
    "#         ax.set_xlabel(feature, fontsize=12)\n",
    "#         ax.set_ylabel('Frequency', fontsize=12)\n",
    "#         ax.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "#     # Hide any remaining empty subplots\n",
    "#     for i in range(num_features, len(axes)):\n",
    "#         fig.delaxes(axes[i])\n",
    "\n",
    "#     plt.tight_layout(pad=3.0)\n",
    "    \n",
    "#     # Convert the figure to a PNG image in memory\n",
    "#     img_buf = io.BytesIO()\n",
    "#     plt.savefig(img_buf, format='png', bbox_inches='tight')\n",
    "#     plt.close(fig)\n",
    "#     img_buf.seek(0)\n",
    "    \n",
    "#     # Encode the image in base64 and display it within an HTML block that centers it\n",
    "#     img_base64 = base64.b64encode(img_buf.read()).decode('utf-8')\n",
    "#     img_html = f'<div style=\"width: 95%; margin: auto; text-align: center;\"><img src=\"data:image/png;base64,{img_base64}\" style=\"width: 100%;\"/></div>'\n",
    "#     display(HTML(img_html))\n",
    "    \n",
    "def plot_distribution(data, title, ax):\n",
    "    sns.barplot(x=list(data.keys()), y=list(data.values()), palette=\"Set2\", ax=ax)\n",
    "    ax.set_title(title, fontsize=14, fontweight='bold')\n",
    "    ax.set_xlabel('Category', fontsize=12)\n",
    "    ax.set_ylabel('Count', fontsize=12)\n",
    "    ax.tick_params(axis='x', rotation=45)\n",
    "\n",
    "def print_report(_, subset):  # From AIF360 Notebook (modified for prettier printing)\n",
    "    global df\n",
    "\n",
    "    if subset:\n",
    "        to_choose = df[subset.keys()].isin(subset).all(axis=1)\n",
    "        filtered_df = df[['true_conversion', 'predicted_conversion']][to_choose]\n",
    "    else:\n",
    "        for col in features_4_scanning:\n",
    "            subset[col] = list(df[col].unique())\n",
    "        filtered_df = df[['true_conversion', 'predicted_conversion']]\n",
    "\n",
    "    true = filtered_df['true_conversion'].sum()\n",
    "    pred = filtered_df['predicted_conversion'].sum()\n",
    "\n",
    "    # Enhanced subset information\n",
    "    subset_html = '''\n",
    "    <div>\n",
    "        <h2>The algorithm found the following subset:</h2>\n",
    "        <table style=\"width: 100%; border-collapse: collapse;\">\n",
    "            <thead>\n",
    "                <tr>\n",
    "                    <th style=\"border: 1px solid #ddd; padding: 8px; background-color: #f2f2f2;\">Feature</th>\n",
    "                    <th style=\"border: 1px solid #ddd; padding: 8px; background-color: #f2f2f2;\">Values</th>\n",
    "                </tr>\n",
    "            </thead>\n",
    "            <tbody>\n",
    "    '''\n",
    "    for key, values in subset.items():\n",
    "        values_str = ', '.join(map(str, values))\n",
    "        subset_html += f'''\n",
    "                <tr>\n",
    "                    <td style=\"border: 1px solid #ddd; padding: 8px;\">{key}</td>\n",
    "                    <td style=\"border: 1px solid #ddd; padding: 8px;\">{values_str}</td>\n",
    "                </tr>\n",
    "        '''\n",
    "    subset_html += '''\n",
    "            </tbody>\n",
    "        </table>\n",
    "        <p><strong>Subset Size:</strong> {subset_size}</p>\n",
    "        <p><strong>True Clicks:</strong> {true}</p>\n",
    "        <p><strong>Predicted Clicks:</strong> {pred}</p>\n",
    "    </div>\n",
    "    '''.format(subset_size=len(filtered_df), true=true, pred=pred)\n",
    "    display(HTML(subset_html))\n",
    "\n",
    "    # display_info_box(\"Multi-Dimensional Subset Scan (MDSS)\", \"Ad Campaign Dataset\")\n",
    "    \n",
    "    # Calculate number of rows and columns for the grid\n",
    "    num_plots = len(subset)\n",
    "    num_cols = 4 # keep it to at most 4 plots per row\n",
    "    num_rows = (num_plots + num_cols - 1) // num_cols  # Calculate the number of rows needed\n",
    "\n",
    "    fig, axes = plt.subplots(num_rows, num_cols, figsize=(6 * num_cols, 6 * num_rows))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    # Plot distribution for each subset key\n",
    "    for i, (key, values) in enumerate(subset.items()):\n",
    "        value_counts = df[key].value_counts().to_dict()\n",
    "        subset_counts = {value: value_counts.get(value, 0) for value in values}\n",
    "        plot_distribution(subset_counts, f\"Distribution of {key}\", axes[i])\n",
    "    \n",
    "    # Remove any empty subplots\n",
    "    for i in range(num_plots, len(axes)):\n",
    "        fig.delaxes(axes[i])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_toolkit_content():\n",
    "    with global_output:\n",
    "        global_output.clear_output(wait=True)  # Use wait=True for smoother updates\n",
    "        display(header)\n",
    "        display(steps_box)\n",
    "        display(nav_buttons_box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Event handlers\n",
    "    \n",
    "def on_button_click(b):\n",
    "    if b.description == 'Detect Bias':\n",
    "        show_bias_detection_toolkit()\n",
    "    elif b.description == 'Explainability Toolkit':\n",
    "        #show_bias_detection_toolkit()\n",
    "        show_explainability_toolkit()\n",
    "    elif b.description == 'Fairness Trade-offs':\n",
    "        show_tradeoff_toolkit()\n",
    "    elif b.description == 'Apriori Certify Fairness':\n",
    "        show_apriori_certification()\n",
    "    else:\n",
    "        raise ValueError\n",
    "\n",
    "def update_status(loaded=False):\n",
    "    status_color = 'red' if not loaded else 'green'\n",
    "    status_text = 'No dataset is loaded.' if not loaded else 'Dataset loaded successfully.'\n",
    "    status_message = f'<div style=\"background-color: #f0f0f0; border: 1px solid #ccc; border-radius: 5px; padding: 10px; width: auto; margin: 10px auto; text-align: left;\">'\n",
    "    status_message += f'<span style=\"font-weight: bold; color: #333333;\">Status:</span> '\n",
    "    status_message += f'<span style=\"color: {status_color}; font-weight: bold;\">{status_text}</span>'\n",
    "    status_message += '</div>'\n",
    "    display(HTML(status_message))\n",
    "\n",
    "# def on_file_upload_change(change):\n",
    "#     global df, global_output\n",
    "#     with global_output:\n",
    "#         if change.new:\n",
    "#             uploaded_file = change.new[0]\n",
    "#             df = pd.read_csv(io.BytesIO(uploaded_file['content']))\n",
    "#             clean_toolkit_content()\n",
    "#             update_status(loaded=True)\n",
    "#             display(output_status)\n",
    "#             # display_message(\"Data Analysis\", color='grey', font_size='28px', font_weight='bold')\n",
    "#             display_dataframe_styled(df.head())\n",
    "#             # display(display_dataframe_styled(df.describe()))\n",
    "#             features_to_plot = ['religion', 'politics', 'college_educated', \\\n",
    "#                                 'parents', 'homeowner', 'gender', 'age', \\\n",
    "#                                 'income', 'area']\n",
    "#             plot_histogram_grid(features_to_plot)\n",
    "\n",
    "# def update_selected_features(change):\n",
    "#     global features_4_scanning, global_output\n",
    "#     features_4_scanning = list(change.new)\n",
    "    \n",
    "#     # Construct the message based on selected features\n",
    "#     if features_4_scanning:\n",
    "#         selected_features_str = ', '.join(features_4_scanning)\n",
    "#         color = 'black'  # Use green color to indicate selection\n",
    "#     else:\n",
    "#         color = 'red'  # Use red color to indicate no selection\n",
    "\n",
    "#     # Construct the HTML message with the specified styling\n",
    "#     status_message = f'<div style=\"background-color: #f0f0f0; border: 1px solid #ccc; border-radius: 5px; padding: 10px; width: auto; margin: 10px auto; text-align: left;\">'\n",
    "#     if color == 'black':\n",
    "#         status_message += f'<span style=\"color: {color}; font-weight: bold;\">Selected features: </span>'\n",
    "#         status_message += f'<span style=\"color: {color};\">{selected_features_str}</span>'\n",
    "#     else:\n",
    "#         status_message += f'<span style=\"color: {color}; font-weight: bold;\">No selected features:</span>'\n",
    "        \n",
    "#     status_message += '</div>'\n",
    "    \n",
    "#     # Display the message in the global_output\n",
    "#     with global_output:\n",
    "#         display(HTML(status_message))   \n",
    "        \n",
    "def update_selected_features(change):\n",
    "    global features_4_scanning, global_output, has_selected_features, features_status_output\n",
    "    features_4_scanning = list(change.new)\n",
    "    \n",
    "    # Construct the message based on selected features\n",
    "    if features_4_scanning:\n",
    "        selected_features_str = ', '.join(features_4_scanning)\n",
    "        has_selected_features = True\n",
    "    else:\n",
    "        has_selected_features = False\n",
    "\n",
    "    # Construct the HTML message with the specified styling\n",
    "    status_message = f'<div style=\"background-color: #f0f0f0; border: 1px solid #ccc; border-radius: 5px; padding: 10px; width: auto; margin: 10px auto; text-align: left;\">'\n",
    "    if has_selected_features:\n",
    "        status_message += f'<span style=\"color: black; font-weight: bold;\">Selected features/protected attributes: </span>'\n",
    "        status_message += f'<span style=\"color: black;\">{selected_features_str}</span>'\n",
    "    else:\n",
    "        status_message += f'<span style=\"color: red; font-weight: bold;\">No selected features/protected attributes.</span>'\n",
    "        \n",
    "    status_message += '</div>'\n",
    "    \n",
    "    # Display the message in the global_output\n",
    "    with features_status_output:\n",
    "        features_status_output.clear_output(wait=True)\n",
    "        display(HTML(status_message))\n",
    "        \n",
    "def update_selected_not_to_change_features(change):\n",
    "    global not_to_change_features, global_output, \\\n",
    "        has_selected_not_to_change_features, \\\n",
    "        not_to_change_features_status_output\n",
    "    \n",
    "    not_to_change_features = list(change.new)\n",
    "    # Construct the message based on selected features\n",
    "    if not_to_change_features:\n",
    "        not_to_change_features_str = ', '.join(not_to_change_features)\n",
    "        has_selected_not_to_change_features = True\n",
    "    else:\n",
    "        has_selected_not_to_change_features = False\n",
    "\n",
    "    # Construct the HTML message with the specified styling\n",
    "    status_message = f'<div style=\"background-color: #f0f0f0; border: 1px solid #ccc; border-radius: 5px; padding: 10px; width: auto; margin: 10px auto; text-align: left;\">'\n",
    "    if has_selected_not_to_change_features:\n",
    "        status_message += f'<span style=\"color: black; font-weight: bold;\">Selected features not to change: </span>'\n",
    "        status_message += f'<span style=\"color: black;\">{not_to_change_features_str}</span>'\n",
    "    else:\n",
    "        status_message += f'<span style=\"color: red; font-weight: bold;\">No selected features.</span>'\n",
    "        \n",
    "    status_message += '</div>'\n",
    "    \n",
    "    # Display the message in the global_output\n",
    "    with not_to_change_features_status_output:\n",
    "        not_to_change_features_status_output.clear_output(wait=True)\n",
    "        display(HTML(status_message))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cc22092fe7e4c71895c6c531562ff02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='\\n<style>\\n    .text-button-class {\\n        background-color: transparent !important;\\n    }\\n</s…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee888e70638a48b696aa81667c6a8302",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output(layout=Layout(margin='0px', padding='10px', width='100%'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Styling\n",
    "\n",
    "# Common image dimensions\n",
    "image_height = 100\n",
    "image_width = 100\n",
    "\n",
    "# Common layouts\n",
    "text_button_css = \"\"\"\n",
    "<style>\n",
    "    .text-button-class {\n",
    "        background-color: transparent !important;\n",
    "    }\n",
    "</style>\n",
    "\"\"\"\n",
    "\n",
    "display(HTML(text_button_css))\n",
    "\n",
    "text_button_layout = widgets.Layout(\n",
    "    height='auto',      \n",
    "    width='250px',  \n",
    "    margin='10px 5px', \n",
    "    padding='10px',  \n",
    "    border='1px solid #ccc',  \n",
    "    background_color='transparent',  \n",
    "    flex_flow='row wrap',  \n",
    "    justify_content='flex-start',  \n",
    "    align_items='center',  \n",
    "    box_shadow='0 2px 4px 0 rgba(0,0,0,0.1)',\n",
    ")\n",
    "\n",
    "step_layout = widgets.Layout(display='flex', flex_flow='column', align_items='center', justify_content='center')\n",
    "\n",
    "pipeline_title_style = {'font_size': '30px', \n",
    "                        'color': '#333333',                 # Dark grey text\n",
    "                        'background_color': '#F0F0F0',      # Light background color\n",
    "                        'border_radius': '5px',             # Slightly rounded corners\n",
    "                        'border': '1px solid #CCCCCC'       # Light grey border\n",
    "                        }\n",
    "\n",
    "# Layout for step buttons\n",
    "button_layout_wide = widgets.Layout(\n",
    "    width='300px',  \n",
    "    height='50px',\n",
    "    margin='5px',  \n",
    "    padding='5px',  \n",
    "    border='1px solid #CCCCCC',     # Light grey border\n",
    "    border_radius='5px',            # Slightly rounded corners\n",
    "    font_weight='bold',\n",
    "    color='#333333',                # Dark text color\n",
    "    background_color='#F0F0F0',     # Light background color\n",
    "    align_items='center',\n",
    "    justify_content='center'\n",
    ")\n",
    "\n",
    "# Define the layout for the main content to allow it to be scrollable\n",
    "main_content_layout = widgets.Layout(\n",
    "    overflow_y='auto',  # Allow vertical scrolling\n",
    "    margin='0px', \n",
    "    padding='10px', \n",
    "    width='100%'\n",
    ")\n",
    "global global_output\n",
    "global_output.layout = main_content_layout\n",
    "display(global_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_home_screen():\n",
    "    global global_output\n",
    "    with global_output:\n",
    "        global_output.clear_output(wait=True)  # Clear existing content\n",
    "        # Title\n",
    "        title = widgets.Label(value='humancompatible.autochoice', \n",
    "                              layout=widgets.Layout(margin='120px 0px 20px 0px'), \n",
    "                              style={'font_size': '38px'})\n",
    "        title.add_class('my-font')\n",
    "\n",
    "\n",
    "        # Subtitle\n",
    "        subtitle = widgets.Label(value='An automated tool for evaluating fairness in AI/ML models', \n",
    "                              layout=widgets.Layout(margin='10px 0px 70px 0px'), \n",
    "                              style={'font_size': '24px'})\n",
    "        subtitle.add_class('my-font')\n",
    "\n",
    "        subtitle2 = widgets.Label(value='Developed and maintained by NKUA team', \n",
    "                              layout=widgets.Layout(margin='10px 0px 70px 0px'), \n",
    "                              style={'font_size': '20px'})\n",
    "        subtitle2.add_class('my-font')        \n",
    "\n",
    "\n",
    "        # Define layout for rows and columns\n",
    "        vbox_layout = widgets.Layout(display='flex', flex_flow='column', \n",
    "                                     align_items='center', justify_content='center')\n",
    "        \n",
    "        hbox_layout = widgets.Layout(display='flex',\n",
    "                                     flex_flow='row',\n",
    "                                     align_items='center',\n",
    "                                     justify_content='space-between')  # Use space-between for even spacing\n",
    "\n",
    "\n",
    "        # Load icons\n",
    "        with open('detect_bias_icon.png', 'rb') as file:\n",
    "            detect_bias_icon = file.read()\n",
    "        with open('explainability_toolkit_icon.png', 'rb') as file:\n",
    "            explainability_icon = file.read()\n",
    "        with open('tradeoff_icon.png', 'rb') as file:\n",
    "            tradeoff_icon = file.read()\n",
    "        with open('certification_icon.png', 'rb') as file:\n",
    "            certification_icon = file.read()\n",
    "\n",
    "        # Creating image and button widgets\n",
    "        detect_bias_image = widgets.Image(value=detect_bias_icon, format='png', width=image_width, height=image_height)\n",
    "        bias_detection_button = widgets.Button(description='Detect Bias', layout=text_button_layout, style={'button_color': 'white'})\n",
    "        bias_detection_button.on_click(on_button_click)\n",
    "        bias_detection_button.add_class('my-font')\n",
    "        bias_detection_button.add_class('text-button-class')\n",
    "\n",
    "        explainability_image = widgets.Image(value=explainability_icon, format='png', width=image_width, height=image_height)\n",
    "        explainability_button = widgets.Button(description='Explainability Toolkit', layout=text_button_layout, style={'button_color': 'white'})\n",
    "        explainability_button.on_click(on_button_click)\n",
    "        explainability_button.add_class('my-font')\n",
    "        explainability_button.add_class('text-button-class')\n",
    "\n",
    "        tradeoff_image = widgets.Image(value=tradeoff_icon, format='png', width=image_width, height=image_height)\n",
    "        tradeoff_button = widgets.Button(description='Fairness Trade-offs', layout=text_button_layout, style={'button_color': 'white'})\n",
    "        tradeoff_button.on_click(on_button_click)\n",
    "        tradeoff_button.add_class('my-font')\n",
    "        tradeoff_button.add_class('text-button-class')\n",
    "\n",
    "        certification_image = widgets.Image(value=certification_icon, format='png', width=image_width, height=image_height)\n",
    "        certification_button = widgets.Button(description='Apriori Certify Fairness', layout=text_button_layout, style={'button_color': 'white'})\n",
    "        certification_button.on_click(on_button_click)\n",
    "        certification_button.add_class('my-font')\n",
    "        certification_button.add_class('text-button-class')\n",
    "\n",
    "        detect_bias_step = widgets.VBox([detect_bias_image, bias_detection_button], layout=step_layout)\n",
    "        explainability_step = widgets.VBox([explainability_image, explainability_button], layout=step_layout)\n",
    "        tradeoff_step = widgets.VBox([tradeoff_image, tradeoff_button], layout=step_layout)\n",
    "        certification_step = widgets.VBox([certification_image, certification_button], layout=step_layout)\n",
    "\n",
    "        arrow_button = widgets.Button(\n",
    "            description='',         # No text, only icon\n",
    "            icon='arrow-right',     # Specify the FontAwesome icon name here\n",
    "            layout=widgets.Layout(width='auto', height='auto', overflow='visible'),\n",
    "            style={'button_color': 'transparent'}  # Attempt to set the button background to transparent\n",
    "        )\n",
    "\n",
    "        arrow_button.add_class('my-font')\n",
    "        row = widgets.HBox([detect_bias_step, arrow_button, \n",
    "                            explainability_step, arrow_button, \n",
    "                            tradeoff_step, arrow_button, certification_step], layout=hbox_layout)\n",
    "\n",
    "        # Adjust the layout to place the arrows correctly\n",
    "        row.layout.justify_content = 'space-between'\n",
    "        # Combine title and row in a VBox\n",
    "        home_screen_layout = widgets.VBox([title, subtitle, subtitle2, row], layout=vbox_layout)\n",
    "        \n",
    "        display(home_screen_layout)  # Display home screen layout in global_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_bias_detection_welcome_page():\n",
    "    info_message = \"\"\"\n",
    "    <div style=\"background-color: #f0f0f0; border: 1px solid #ccc; color: #333333; padding: 15px; border-radius: 5px; width: auto; margin: 10px auto; text-align: left;\">\n",
    "        <span style=\"font-weight: bold; color: #333333; font-size: 16px;\">\n",
    "            <i class=\"fa fa-info-circle\" style=\"margin-right: 10px;\"></i> This is the automated bias detection toolkit.\n",
    "        </span>\n",
    "        <p style=\"font-size: 14px; margin-top: 10px;\">\n",
    "            Follow the pipeline to load your desired data, analyze them, and run bias detection algorithms.\n",
    "        </p>\n",
    "        <h3 style=\"font-size: 16px; color: #333333;\">Bias Detection</h3>\n",
    "        <p style=\"font-size: 14px;\">\n",
    "            Bias occurs in data used to train a model. We provide sample datasets, metrics and algorithms that you can use to explore bias checking.\n",
    "        </p>\n",
    "        <h3 style=\"font-size: 16px; color: #333333;\">How to Use This Toolkit</h3>\n",
    "        <ol style=\"font-size: 14px; padding-left: 20px;\">\n",
    "            <li>Load your dataset by following the pipeline steps. Currently you can only select from available options.</li>\n",
    "            <li>Analyze the dataset and plot metrics for potential biases.</li>\n",
    "            <li>Select and run the bias detection algorithm to identify biased subgroups.</li>\n",
    "            <li>Review the results and take necessary actions to mitigate bias.</li>\n",
    "        </ol>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    \n",
    "    info_box = widgets.HTML(\n",
    "        value=info_message,\n",
    "        layout=widgets.Layout(margin='0px', width='100%', padding='5px 0px 5px 0px')\n",
    "    )\n",
    "    with global_output:\n",
    "        display(info_box)\n",
    "\n",
    "\n",
    "def display_explainability_toolkit_welcome_page():\n",
    "    info_message = \"\"\"\n",
    "    <div style=\"background-color: #f0f0f0; border: 1px solid #ccc; color: #333333; padding: 15px; border-radius: 5px; width: auto; margin: 10px auto; text-align: left;\">\n",
    "        <span style=\"font-weight: bold; color: #333333; font-size: 16px;\">\n",
    "            <i class=\"fa fa-info-circle\" style=\"margin-right: 10px;\"></i> This is the automated explainability toolkit.\n",
    "        </span>\n",
    "        <p style=\"font-size: 14px; margin-top: 10px;\">\n",
    "            Follow the pipeline to load your desired data, analyze them, and run explainability algorithms.\n",
    "        </p>\n",
    "        <h3 style=\"font-size: 16px; color: #333333;\">Explainability</h3>\n",
    "        <p style=\"font-size: 14px;\">\n",
    "            Explainability focuses on the reasoning behind the decisions or predictions made by ML models to make them more understandable and transparent. We provide sample datasets, metrics and algorithms that you can use to explore explainability.\n",
    "        </p>\n",
    "        <h3 style=\"font-size: 16px; color: #333333;\">How to Use This Toolkit</h3>\n",
    "        <ol style=\"font-size: 14px; padding-left: 20px;\">\n",
    "            <li>Load your dataset by following the pipeline steps. Currently you can upload your own or select from available options.</li>\n",
    "            <li>Analyze the dataset and plot metrics for potential biases.</li>\n",
    "            <li>Select and run explainability algorithms with different parameters to identify biased subgroups.</li>\n",
    "            <li>Review the results and take necessary actions to mitigate bias.</li>\n",
    "        </ol>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    \n",
    "    info_box = widgets.HTML(\n",
    "        value=info_message,\n",
    "        layout=widgets.Layout(margin='0px', width='100%', padding='5px 0px 5px 0px')\n",
    "    )\n",
    "    with global_output:\n",
    "        display(info_box)\n",
    "\n",
    "\n",
    "\n",
    "def display_fairness_measures_welcome_page():\n",
    "    info_message = \"\"\"\n",
    "    <div style=\"background-color: #f0f0f0; border: 1px solid #ccc; color: #333333; padding: 15px; border-radius: 5px; width: auto; margin: 10px auto; text-align: left;\">\n",
    "        <span style=\"font-weight: bold; color: #333333; font-size: 16px;\">\n",
    "            <i class=\"fa fa-info-circle\" style=\"margin-right: 10px;\"></i> This is the fairness measures trade-off toolkit.\n",
    "        </span>\n",
    "        <p style=\"font-size: 14px; margin-top: 10px;\">\n",
    "            Follow the pipeline to load your desired data, analyze them, and run fairness measures trade-off algorithms.\n",
    "        </p>\n",
    "        <h3 style=\"font-size: 16px; color: #333333;\">Fairness Measures Trade-offs</h3>\n",
    "        <p style=\"font-size: 14px;\">\n",
    "            The tradeo  between di erent measures of fairness is captured by the so-called Pareto front, a visual representing the most one can achieve of a particular measure without sacri cing another.\n",
    "        </p>\n",
    "        <h3 style=\"font-size: 16px; color: #333333;\">How to Use This Toolkit</h3>\n",
    "        <ol style=\"font-size: 14px; padding-left: 20px;\">\n",
    "            <li>Load your dataset by following the pipeline steps. Currently you can upload your own or select from available options.</li>\n",
    "            <li>Analyze the dataset and plot metrics for potential biases.</li>\n",
    "            <li>Select and run exploration of trade-off measures algorithms with different parameters.</li>\n",
    "            <li>Review the results and take necessary actions.</li>\n",
    "        </ol>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    \n",
    "    info_box = widgets.HTML(\n",
    "        value=info_message,\n",
    "        layout=widgets.Layout(margin='0px', width='100%', padding='5px 0px 5px 0px')\n",
    "    )\n",
    "    with global_output:\n",
    "        display(info_box)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_arrow():\n",
    "    \"\"\"Creates an arrow symbol between step widgets.\"\"\"\n",
    "    return widgets.HTML(value='<i class=\"fa fa-arrow-right\" style=\"font-size:18px;color:grey;\"></i>',\n",
    "                layout=widgets.Layout(display='flex', justify_content='center', align_items='center', height='auto', width='auto', margin='0px 10px'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Work Packages\n",
    "\n",
    "def create_step_widget(icon, text):\n",
    "    \"\"\"Creates a circular button with an icon and a text label below it.\"\"\"\n",
    "    # Button with an icon\n",
    "    button = widgets.Button(icon=icon, layout=Layout(width='70px', height='70px', margin='0px 5px'))\n",
    "    button.style.button_color = 'lightgray'\n",
    "    button.style.border_radius = '35px'\n",
    "    button.add_class('circular')\n",
    "    label = widgets.HTML(value=f\"<div style='text-align:center; color:grey;'>{text}</div>\", \n",
    "                 layout=Layout(height='auto', width='auto'))\n",
    "    label.add_class('my-font')\n",
    "    # Combine button and label in a VBox\n",
    "    step_widget = VBox([button, label], layout=Layout(align_items='center', justify_content='center', margin='0px 10px', overflow='hidden'))\n",
    "    return step_widget\n",
    "\n",
    "def show_bias_detection_toolkit():\n",
    "    with global_output:\n",
    "        global_output.clear_output(wait=True)\n",
    "        set_variables()\n",
    "        # Home button\n",
    "        home_button = Button(\n",
    "            description='Home',\n",
    "            layout=Layout(width='auto', \n",
    "                        height='auto', \n",
    "                        margin='0px 0px 5px 0px'),  \n",
    "            style={'button_color': 'white', 'font_size': '18px'},  \n",
    "            icon='home',  \n",
    "        )\n",
    "        home_button.add_class('my-font')\n",
    "        home_button.on_click(lambda b: display_home_screen())  # Use lambda for simplicity\n",
    "        \n",
    "        home_button_box = widgets.Box(children=[home_button], layout=Layout(\n",
    "            overflow='hidden',\n",
    "            width='100%', \n",
    "            height='auto',\n",
    "            display='flex',\n",
    "            flex_flow='column',  \n",
    "            align_items='flex-start',\n",
    "        ))\n",
    "        home_button_box.add_class('header-box')  # Assuming this class sets the necessary CSS\n",
    "        \n",
    "        page_title = widgets.Label(\n",
    "            'Bias Detection Toolkit', \n",
    "            layout=widgets.Layout(\n",
    "                margin='0px 0px 15px 0px',\n",
    "                padding='0px',\n",
    "                justify_content='center'\n",
    "            ),\n",
    "            style=pipeline_title_style\n",
    "        )\n",
    "        page_title.add_class('my-font')\n",
    "        \n",
    "        ### PIPELINE STEPS ###\n",
    "        # Upload Button #\n",
    "        # upload_button = widgets.FileUpload(accept='.csv', \n",
    "        #                                 description='',\n",
    "        #                                 multiple=False, \n",
    "        #                                 layout=Layout(width='70px', height='70px', margin='0px 5px'))\n",
    "        # upload_button.style.button_color = 'lightgray'\n",
    "        # upload_button.style.border_radius = '35px'\n",
    "        # upload_button.add_class('circular')\n",
    "        # upload_button.observe(on_file_upload_change, names='value')\n",
    "        # upload_button.add_class('my-font')\n",
    "\n",
    "        # label = HTML(value=\"<div style='text-align:center; color:grey;'>Upload</div>\", \n",
    "        #             layout=Layout(height='auto', width='auto'))\n",
    "        # label.add_class('my-font')\n",
    "        # # Combine button and label\n",
    "        # upload_step = VBox([upload_button, label], layout=Layout(align_items='center', justify_content='center', margin='0px 10px', overflow='hidden'))\n",
    "\n",
    "        # Upload Button #\n",
    "        upload_step = create_step_widget('upload', 'Data') \n",
    "        upload_step.children[0].on_click(upload_bias_detection_data)\n",
    "        \n",
    "        # Analyze Button #\n",
    "        analyze_step = create_step_widget('area-chart', 'Analyze')\n",
    "        analyze_step.children[0].on_click(dataset_analysis)\n",
    "        \n",
    "        # Features Button #\n",
    "        features_step = create_step_widget('tasks', 'Features')\n",
    "        features_step.children[0].on_click(select_features)\n",
    "\n",
    "        # Model Button #\n",
    "\n",
    "        #We modify this in order to get the available algorithms here\n",
    "        # At the moment, apart from those in the toolkit, we will have\n",
    "        # from AIF360, Reweighing for pre-processing and for post-processing\n",
    "        # EqOddsPostprocessing, CalibratedEqOddsPostprocessing, RejectOptionClassification\n",
    "        # \n",
    "        model_step = create_step_widget('cogs', 'Model')\n",
    "        model_step.children[0].on_click(give_model_to_detect_bias_updated_checkboxes_new)\n",
    "        \n",
    "        # Parameters Button #\n",
    "        parameters_step = create_step_widget('sliders-h', 'Parameters')\n",
    "        parameters_step.children[0].on_click(give_parameters_updated_and_extended_all_newer_integr)\n",
    "        \n",
    "        # Run Button #\n",
    "        run_step = create_step_widget('play', 'Run')\n",
    "        run_step.children[0].on_click(run_bias_detection_newer_version)\n",
    "        \n",
    "        # Define arrows\n",
    "        arrow_1 = create_arrow()\n",
    "        arrow_2 = create_arrow()\n",
    "        arrow_3 = create_arrow()\n",
    "        arrow_4 = create_arrow()\n",
    "        arrow_5 = create_arrow()\n",
    "        global header, steps_box\n",
    "        header.children = [home_button_box, page_title]\n",
    "        header.add_class('fixed-header')        \n",
    "        \n",
    "        steps_box.children = [upload_step, arrow_1, analyze_step, arrow_2, features_step, \n",
    "                                arrow_3, model_step, arrow_4, parameters_step, \n",
    "                                arrow_5, run_step]\n",
    "        steps_box.layout = Layout(display='flex', flex_flow='row', \n",
    "                                    justify_content='center', align_items='center', \n",
    "                                    margin='0px', width='100%', height='20vh')\n",
    "\n",
    "        steps_box.add_class('fixed-steps-box')\n",
    "        \n",
    "        info_message = \"\"\"\n",
    "        <div style=\"background-color: #f0f0f0; border: 1px solid #ccc; color: #333333; padding: 15px; border-radius: 5px; width: auto; margin: 10px auto; text-align: left;\">\n",
    "            <span style=\"font-weight: bold; color: #333333; font-size: 16px;\">\n",
    "                <i class=\"fa fa-info-circle\" style=\"margin-right: 10px;\"></i> This is the automated bias detection toolkit.\n",
    "            </span>\n",
    "            <p style=\"font-size: 14px; margin-top: 10px;\">\n",
    "                Follow the pipeline to load your desired data, analyze them, and run bias detection algorithms.\n",
    "            </p>\n",
    "            <h3 style=\"font-size: 16px; color: #333333;\">Bias Detection</h3>\n",
    "            <p style=\"font-size: 14px;\">\n",
    "                Bias occurs in data used to train a model. We provide sample datasets, metrics and algorithms that you can use to explore bias checking.\n",
    "            </p>\n",
    "            <h3 style=\"font-size: 16px; color: #333333;\">How to Use This Toolkit</h3>\n",
    "            <ol style=\"font-size: 14px; padding-left: 20px;\">\n",
    "                <li>Load your dataset by following the pipeline steps. Currently you can only select from available options.</li>\n",
    "                <li>Analyze the dataset and plot metrics for potential biases.</li>\n",
    "                <li>Select and run the bias detection algorithm to identify biased subgroups.</li>\n",
    "                <li>Review the results and take necessary actions to mitigate bias.</li>\n",
    "            </ol>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "        \n",
    "        info_box = widgets.HTML(\n",
    "            value=info_message,\n",
    "            layout=widgets.Layout(margin='15px 0px', width='100%', padding='5px 0px 5px 0px')\n",
    "        )\n",
    "        \n",
    "        start_button = widgets.Button(\n",
    "            description='Start',\n",
    "            layout=widgets.Layout(width='150px', height='50px', margin='10px 0px', border_radius='10px'),\n",
    "            style={'button_color': 'MediumSeaGreen', 'font_size': '16px', 'text_color': 'white','font_weight': 'bold', 'color': 'white'}\n",
    "        )\n",
    "        start_button.add_class('my-font')\n",
    "        start_button.on_click(upload_bias_detection_data)\n",
    "        # Create an HBox to right-align the button\n",
    "        start_button_hbox = widgets.HBox([start_button], layout=widgets.Layout(justify_content='center', width='100%'))\n",
    "        \n",
    "        toolkit_layout_start = widgets.VBox([header, info_box, start_button_hbox], \n",
    "                                      layout=widgets.Layout(width='100%', flex_flow='column'))\n",
    "        display(toolkit_layout_start)  # Display the toolkit layout  \n",
    "   \n",
    "def show_explainability_toolkit():\n",
    "    with global_output:\n",
    "        global_output.clear_output(wait=True)\n",
    "        set_variables()\n",
    "        #print(\"here I am!!\")\n",
    "        # Home button\n",
    "        back_button = Button(\n",
    "            description='Home',\n",
    "            layout=Layout(width='auto', \n",
    "                        height='auto', \n",
    "                        margin='0px 0px 5px 0px'),  \n",
    "            style={'button_color': 'white', 'font_size': '18px'},  \n",
    "            icon='home',  \n",
    "        )\n",
    "        back_button.add_class('my-font')\n",
    "        back_button.on_click(lambda b: display_home_screen())  # Use lambda for simplicity\n",
    "        \n",
    "        back_button_box = widgets.Box(children=[back_button], layout=Layout(\n",
    "            overflow='hidden',\n",
    "            width='100%', \n",
    "            height='auto',\n",
    "            display='flex',\n",
    "            flex_flow='column',  \n",
    "            align_items='flex-start',\n",
    "        ))\n",
    "        back_button_box.add_class('header-box')\n",
    "        \n",
    "        page_title = widgets.Label(\n",
    "            'Explainability Toolkit', \n",
    "            layout=widgets.Layout(\n",
    "                margin='0px 0px 15px 0px',\n",
    "                padding='0px',\n",
    "                justify_content='center'\n",
    "            ),\n",
    "            style=pipeline_title_style\n",
    "        )\n",
    "        page_title.add_class('my-font')\n",
    "\n",
    "        info_message = \"\"\"\n",
    "        <div style=\"background-color: #f0f0f0; border: 1px solid #ccc; color: #333333; padding: 15px; border-radius: 5px; width: auto; margin: 10px auto; text-align: left;\">\n",
    "            <span style=\"font-weight: bold; color: #333333; font-size: 16px;\">\n",
    "                <i class=\"fa fa-info-circle\" style=\"margin-right: 10px;\"></i> This is the automated explainability toolkit.\n",
    "            </span>\n",
    "            <p style=\"font-size: 14px; margin-top: 10px;\">\n",
    "                Follow the pipeline to load your desired data, analyze them, and run explainability algorithms.\n",
    "            </p>\n",
    "            <h3 style=\"font-size: 16px; color: #333333;\">Explainability</h3>\n",
    "            <p style=\"font-size: 14px;\">\n",
    "                Explainability focuses on the reasoning behind the decisions or predictions made by ML models to make them more understandable and transparent. We provide sample datasets, metrics and algorithms that you can use to explore explainability.\n",
    "            </p>\n",
    "            <h3 style=\"font-size: 16px; color: #333333;\">How to Use This Toolkit</h3>\n",
    "            <ol style=\"font-size: 14px; padding-left: 20px;\">\n",
    "                <li>Load your dataset by following the pipeline steps. Currently you can upload your own or select from available options.</li>\n",
    "                <li>Analyze the dataset and plot metrics for potential biases.</li>\n",
    "                <li>Select and run explainability algorithms with different parameters to identify biased subgroups.</li>\n",
    "                <li>Review the results and take necessary actions to mitigate bias.</li>\n",
    "            </ol>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "        \n",
    "        info_box = widgets.HTML(\n",
    "            value=info_message,\n",
    "            layout=widgets.Layout(margin='15px 0px', width='100%', padding='5px 0px 5px 0px')\n",
    "        )\n",
    "\n",
    "        start_button = widgets.Button(\n",
    "            description='Start',\n",
    "            layout=widgets.Layout(width='150px', height='50px', margin='10px 0px', border_radius='10px'),\n",
    "            style={'button_color': 'MediumSeaGreen', 'font_size': '16px', 'text_color': 'white','font_weight': 'bold', 'color': 'white'}\n",
    "        )\n",
    "        start_button.add_class('my-font')\n",
    "        start_button.on_click(upload_bias_detection_data)\n",
    "        # Create an HBox to right-align the button\n",
    "        start_button_hbox = widgets.HBox([start_button], layout=widgets.Layout(justify_content='center', width='100%'))\n",
    "        \n",
    "        ### PIPELINE STEPS ###\n",
    "        # Upload Button #\n",
    "        upload_button = widgets.FileUpload(accept='.csv', \n",
    "                                        description='',\n",
    "                                        multiple=False, \n",
    "                                        layout=Layout(width='70px', height='70px', margin='0px 5px'))\n",
    "        upload_button.style.button_color = 'lightgray'\n",
    "        upload_button.style.border_radius = '35px'\n",
    "        upload_button.add_class('circular')\n",
    "        upload_button.observe(select_explainability_dataset, names='value')\n",
    "        upload_button.add_class('my-font')\n",
    "\n",
    "        label = widgets.HTML(value=\"<div style='text-align:center; color:grey;'>Upload</div>\", \n",
    "                    layout=Layout(height='auto', width='auto'))\n",
    "        label.add_class('my-font')\n",
    "        # Combine button and label\n",
    "        upload_step = VBox([upload_button, label], layout=Layout(align_items='center', justify_content='center', margin='0px 10px', overflow='hidden'))\n",
    "        \n",
    "        # Model Button #\n",
    "        model_step = create_step_widget('cogs', 'Model')\n",
    "        model_step.children[0].on_click(give_parameters_and_explainability_model)\n",
    "        \n",
    "        # Features Button #\n",
    "        features_step = create_step_widget('tasks', 'Action')\n",
    "        features_step.children[0].on_click(select_explainability_action)\n",
    "\n",
    "        \n",
    "        # # Parameters Button #\n",
    "        # parameters_step = create_step_widget('sliders-h', 'Parameters')\n",
    "        # parameters_step.children[0].on_click(give_parameters)\n",
    "        \n",
    "        # Run Button #\n",
    "        run_step = create_step_widget('play', 'Run')\n",
    "        run_step.children[0].on_click(run_explainability)\n",
    "        \n",
    "        # Define arrows\n",
    "        arrow_1 = create_arrow()\n",
    "        arrow_2 = create_arrow()\n",
    "        arrow_3 = create_arrow()\n",
    "        global header\n",
    "        header.children = [back_button_box, page_title]\n",
    "        header.add_class('fixed-header')\n",
    "        global steps_box\n",
    "        steps_box.children = [upload_step, arrow_1, features_step, \n",
    "                                arrow_2, model_step, arrow_3, run_step]\n",
    "        steps_box.layout = Layout(display='flex', flex_flow='row', \n",
    "                                    justify_content='center', align_items='center', \n",
    "                                    margin='0px', width='100%', height='20vh')\n",
    "\n",
    "        steps_box.add_class('fixed-steps-box')\n",
    "\n",
    "        # Combine everything into the main layout for the toolkit\n",
    "        toolkit_layout = widgets.VBox([header, info_box, start_button_hbox], \n",
    "                                      layout=widgets.Layout(width='100%', flex_flow='column'))\n",
    "        \n",
    "        display(toolkit_layout)  # Display the toolkit layout  \n",
    "\n",
    "def show_tradeoff_toolkit():\n",
    "    with global_output:\n",
    "        global_output.clear_output(wait=True)\n",
    "        set_variables()\n",
    "\n",
    "        # Home button\n",
    "        back_button = widgets.Button(\n",
    "            description='Home',\n",
    "            layout=Layout(width='auto', height='auto', margin='0px 0px 5px 0px'),\n",
    "            style={'button_color': 'white', 'font_size': '18px'},\n",
    "            icon='home',\n",
    "        )\n",
    "        back_button.add_class('my-font')\n",
    "        back_button.on_click(lambda b: display_home_screen())\n",
    "\n",
    "        back_button_box = widgets.Box(\n",
    "            children=[back_button],\n",
    "            layout=Layout(\n",
    "                overflow='hidden',\n",
    "                width='100%',\n",
    "                height='auto',\n",
    "                display='flex',\n",
    "                flex_flow='column',\n",
    "                align_items='flex-start',\n",
    "            ),\n",
    "        )\n",
    "        back_button_box.add_class('header-box')\n",
    "\n",
    "        page_title = widgets.Label(\n",
    "            'Examine Trade-off Between Measures of Fairness',\n",
    "            layout=widgets.Layout(margin='0px 0px 15px 0px', padding='0px', justify_content='center'),\n",
    "            style=pipeline_title_style\n",
    "        )\n",
    "        page_title.add_class('my-font')\n",
    "\n",
    "        # Info box\n",
    "        info_message = \"\"\"\n",
    "        <div style=\"background-color: #f0f0f0; border: 1px solid #ccc; color: #333333; padding: 15px; border-radius: 5px; width: auto; margin: 10px auto; text-align: left;\">\n",
    "            <span style=\"font-weight: bold; color: #333333; font-size: 16px;\">\n",
    "                <i class=\"fa fa-info-circle\" style=\"margin-right: 10px;\"></i> This is the automated explainability toolkit.\n",
    "            </span>\n",
    "            <p style=\"font-size: 14px; margin-top: 10px;\">\n",
    "                Follow the pipeline to load your desired data, analyze them, and run explainability algorithms.\n",
    "            </p>\n",
    "            <h3 style=\"font-size: 16px; color: #333333;\">Fairness Trade-offs</h3>\n",
    "            <p style=\"font-size: 14px;\">\n",
    "                The tradeo  between di erent measures of fairness is captured by the so-called Pareto front, a visual representing the most one can achieve of a particular measure without sacri cing another.\n",
    "            </p>\n",
    "            <h3 style=\"font-size: 16px; color: #333333;\">How to Use This Toolkit</h3>\n",
    "            <ol style=\"font-size: 14px; padding-left: 20px;\">\n",
    "                <li>Load your dataset by following the pipeline steps. Currently you can upload your own or select from available options.</li>\n",
    "                <li>Analyze the dataset and plot metrics to explore.</li>\n",
    "                <li>Select and run fairness measure trade-off algorithms with different parameters.</li>\n",
    "                <li>Review the results and take necessary actions.</li>\n",
    "            </ol>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "        info_box = widgets.HTML(\n",
    "            value=info_message,\n",
    "            layout=widgets.Layout(margin='15px 0px', width='100%', padding='5px 0px 5px 0px')\n",
    "        )\n",
    "\n",
    "        # Start button (launch first step)\n",
    "        start_button = widgets.Button(\n",
    "            description='Start',\n",
    "            layout=widgets.Layout(width='150px', height='50px', margin='10px 0px', border_radius='10px'),\n",
    "            style={'button_color': 'MediumSeaGreen', 'font_size': '16px', 'text_color': 'white', 'font_weight': 'bold', 'color': 'white'}\n",
    "        )\n",
    "        start_button.add_class('my-font')\n",
    "        if 'upload_bias_detection_data' in globals():\n",
    "            start_button.on_click(upload_bias_detection_data)\n",
    "\n",
    "        start_button_hbox = widgets.HBox([start_button], layout=widgets.Layout(justify_content='center', width='100%'))\n",
    "\n",
    "        # ---- PIPELINE STEPS ----\n",
    "        # Data\n",
    "        data_step = create_step_widget('upload', 'Data')\n",
    "        if 'upload_bias_detection_data' in globals():\n",
    "            data_step.children[0].on_click(upload_bias_detection_data)\n",
    "\n",
    "        # Measures (select which fairness metrics to compare)\n",
    "        measures_step = create_step_widget('balance-scale', 'Measures')\n",
    "        if 'select_tradeoff_measures' in globals():\n",
    "            measures_step.children[0].on_click(select_tradeoff_measures)\n",
    "\n",
    "        # Parameters\n",
    "        parameters_step = create_step_widget('sliders-h', 'Parameters')\n",
    "        if 'give_parameters_updated_and_extended_all_newer_integr' in globals():\n",
    "            parameters_step.children[0].on_click(give_parameters_updated_and_extended_all_newer_integr)\n",
    "\n",
    "        # Run\n",
    "        run_step = create_step_widget('play', 'Run')\n",
    "        if 'run_tradeoff' in globals():\n",
    "            run_step.children[0].on_click(run_tradeoff)\n",
    "\n",
    "        # Arrows\n",
    "        arrow_1 = create_arrow()\n",
    "        arrow_2 = create_arrow()\n",
    "        arrow_3 = create_arrow()\n",
    "\n",
    "        # Header + steps box (fixed)\n",
    "        global header, steps_box\n",
    "        header.children = [back_button_box, page_title]\n",
    "        header.add_class('fixed-header')\n",
    "\n",
    "        steps_box.children = [data_step, arrow_1, measures_step, arrow_2, parameters_step, arrow_3, run_step]\n",
    "        steps_box.layout = Layout(display='flex', flex_flow='row',\n",
    "                                  justify_content='center', align_items='center',\n",
    "                                  margin='0px', width='100%', height='20vh')\n",
    "        steps_box.add_class('fixed-steps-box')\n",
    "\n",
    "\n",
    "\n",
    "        # Display layout\n",
    "        toolkit_layout = widgets.VBox([header, info_box, start_button_hbox],\n",
    "                                      layout=widgets.Layout(width='100%', flex_flow='column'))\n",
    "        display(toolkit_layout)\n",
    "\n",
    "\n",
    "def show_apriori_certification():\n",
    "    with global_output:\n",
    "        global_output.clear_output(wait=True)\n",
    "        set_variables()\n",
    "\n",
    "        # Home button\n",
    "        back_button = widgets.Button(\n",
    "            description='Home',\n",
    "            layout=Layout(width='auto', height='auto', margin='0px 0px 5px 0px'),\n",
    "            style={'button_color': 'white', 'font_size': '18px'},\n",
    "            icon='home',\n",
    "        )\n",
    "        back_button.add_class('my-font')\n",
    "        back_button.on_click(lambda b: display_home_screen())\n",
    "\n",
    "        back_button_box = widgets.Box(\n",
    "            children=[back_button],\n",
    "            layout=Layout(\n",
    "                overflow='hidden',\n",
    "                width='100%',\n",
    "                height='auto',\n",
    "                display='flex',\n",
    "                flex_flow='column',\n",
    "                align_items='flex-start',\n",
    "            ),\n",
    "        )\n",
    "        back_button_box.add_class('header-box')\n",
    "\n",
    "        page_title = widgets.Label(\n",
    "            'Apriori Certify Fairness',\n",
    "            layout=widgets.Layout(margin='0px 0px 15px 0px', padding='0px', justify_content='center'),\n",
    "            style=pipeline_title_style\n",
    "        )\n",
    "        page_title.add_class('my-font')\n",
    "\n",
    "        # Info box\n",
    "        info_message = \"\"\"\n",
    "        <div style=\"background-color: #f0f0f0; border: 1px solid #ccc; color: #333333; padding: 15px; border-radius: 5px; width: auto; margin: 10px auto; text-align: left;\">\n",
    "            <span style=\"font-weight: bold; color: #333333; font-size: 16px;\">\n",
    "                <i class=\"fa fa-info-circle\" style=\"margin-right: 10px;\"></i> This tool certifies fairness a priori.\n",
    "            </span>\n",
    "            <p style=\"font-size: 14px; margin-top: 10px;\">\n",
    "                Provide a model and constraints to verify fairness properties before deployment, using data schema and selected features.\n",
    "            </p>\n",
    "            <h3 style=\"font-size: 16px; color: #333333;\">How to Use</h3>\n",
    "            <ol style=\"font-size: 14px; padding-left: 20px;\">\n",
    "                <li>Load or select a dataset (or schema) as context.</li>\n",
    "                <li>Select/inspect features relevant to certification.</li>\n",
    "                <li>Provide input parameters (thresholds, protected attributes, constraints).</li>\n",
    "                <li>Choose the model to certify.</li>\n",
    "                <li>Run the certification and review results.</li>\n",
    "            </ol>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "        info_box = widgets.HTML(\n",
    "            value=info_message,\n",
    "            layout=widgets.Layout(margin='15px 0px', width='100%', padding='5px 0px 5px 0px')\n",
    "        )\n",
    "\n",
    "        # Start button (launch first step)\n",
    "        start_button = widgets.Button(\n",
    "            description='Start',\n",
    "            layout=widgets.Layout(width='150px', height='50px', margin='10px 0px', border_radius='10px'),\n",
    "            style={'button_color': 'MediumSeaGreen', 'font_size': '16px', 'text_color': 'white', 'font_weight': 'bold', 'color': 'white'}\n",
    "        )\n",
    "        start_button.add_class('my-font')\n",
    "        if 'upload_bias_detection_data' in globals():\n",
    "            start_button.on_click(upload_bias_detection_data)\n",
    "\n",
    "        start_button_hbox = widgets.HBox([start_button], layout=widgets.Layout(justify_content='center', width='100%'))\n",
    "\n",
    "        # ---- PIPELINE STEPS ----\n",
    "        # Data\n",
    "        data_step = create_step_widget('upload', 'Data')\n",
    "        if 'upload_bias_detection_data' in globals():\n",
    "            data_step.children[0].on_click(upload_bias_detection_data)\n",
    "\n",
    "        # Features\n",
    "        features_step = create_step_widget('tasks', 'Features')\n",
    "        if 'select_features' in globals():\n",
    "            features_step.children[0].on_click(select_features)\n",
    "\n",
    "        # Parameters\n",
    "        parameters_step = create_step_widget('sliders-h', 'Parameters')\n",
    "        # Reuse the unified parameters panel if available\n",
    "        if 'give_parameters_updated_and_extended_all_newer_integr' in globals():\n",
    "            parameters_step.children[0].on_click(give_parameters_updated_and_extended_all_newer_integr)\n",
    "        elif 'give_input_parameters' in globals():\n",
    "            parameters_step.children[0].on_click(give_input_parameters)\n",
    "\n",
    "        # Model (to certify)\n",
    "        model_step = create_step_widget('cogs', 'Model')\n",
    "        # Prefer a specific cert function if present\n",
    "        if 'give_model_to_certify' in globals():\n",
    "            model_step.children[0].on_click(give_model_to_certify)\n",
    "        elif 'give_model_to_detect_bias_updated_checkboxes_new' in globals():\n",
    "            model_step.children[0].on_click(give_model_to_detect_bias_updated_checkboxes_new)\n",
    "\n",
    "        # Run\n",
    "        run_step = create_step_widget('play', 'Run')\n",
    "        if 'run_apriori_certification' in globals():\n",
    "            run_step.children[0].on_click(run_apriori_certification)\n",
    "        elif 'run_bias_detection_newer_version' in globals():\n",
    "            run_step.children[0].on_click(run_bias_detection_newer_version)\n",
    "\n",
    "        # Arrows\n",
    "        arrow_1 = create_arrow()\n",
    "        arrow_2 = create_arrow()\n",
    "        arrow_3 = create_arrow()\n",
    "        arrow_4 = create_arrow()\n",
    "\n",
    "        # Header + steps box (fixed)\n",
    "        global header, steps_box\n",
    "        header.children = [back_button_box, page_title]\n",
    "        header.add_class('fixed-header')\n",
    "\n",
    "        steps_box.children = [data_step, arrow_1, features_step, arrow_2, parameters_step, arrow_3, model_step, arrow_4, run_step]\n",
    "        steps_box.layout = Layout(display='flex', flex_flow='row',\n",
    "                                  justify_content='center', align_items='center',\n",
    "                                  margin='0px', width='100%', height='20vh')\n",
    "        steps_box.add_class('fixed-steps-box')\n",
    "\n",
    "        # Display layout\n",
    "        toolkit_layout = widgets.VBox([header, info_box, start_button_hbox],\n",
    "                                      layout=widgets.Layout(width='100%', flex_flow='column'))\n",
    "        display(toolkit_layout)\n",
    "\n",
    "\n",
    "\n",
    "def show_tradeoff_old():\n",
    "    # Clear the vbox contents\n",
    "    vbox.children = []\n",
    "\n",
    "    # Back to Pipeline button\n",
    "    back_button = widgets.Button(description='Back to Pipeline', layout=widgets.Layout(width='150px', height='30px', margin='5px'))\n",
    "    def back_to_pipeline(b):\n",
    "        vbox.children = home_grid\n",
    "    back_button.on_click(back_to_pipeline)\n",
    "    \n",
    "    title_label = widgets.Label('Examine Trade-off Between Measures of Fairness', \n",
    "                                layout=widgets.Layout(margin='10px'),\n",
    "                                style={'font_size': '20px', 'font_weight': 'bold'})\n",
    "\n",
    "    # Updated layout for wider buttons\n",
    "    button_layout_wide = widgets.Layout(width='300px', height='50px', margin='5px', border='solid black 1px')\n",
    "\n",
    "    # Creating new buttons for the bias detection toolkit\n",
    "    button_load_data = widgets.Button(description='Load Data', layout=button_layout_wide)\n",
    "    button_visualize_features = widgets.Button(description='Visualize/Select Features', layout=button_layout_wide)\n",
    "    button_input_parameters = widgets.Button(description='Give Parameters of Model', layout=button_layout_wide)\n",
    "    button_select_action = widgets.Button(description='Select Measures', layout=button_layout_wide)\n",
    "    button_run = widgets.Button(description='Run', layout=button_layout_wide)\n",
    "    button_return_results = widgets.Button(description='Return Results & Visualize', layout=button_layout_wide)\n",
    "\n",
    "    # Creating centered downward arrow labels\n",
    "    arrow_down_style = {'font_size': '24px'}\n",
    "    arrow_down1 = widgets.Label(value='↓', layout=widgets.Layout(width='auto'), style=arrow_down_style)\n",
    "    arrow_down2 = widgets.Label(value='↓', layout=widgets.Layout(width='auto'), style=arrow_down_style)\n",
    "    arrow_down3 = widgets.Label(value='↓', layout=widgets.Layout(width='auto'), style=arrow_down_style)\n",
    "    arrow_down4 = widgets.Label(value='↓', layout=widgets.Layout(width='auto'), style=arrow_down_style)\n",
    "    arrow_down5 = widgets.Label(value='↓', layout=widgets.Layout(width='auto'), style=arrow_down_style)\n",
    "\n",
    "    # Create a new vertical box (VBox) with centered alignment\n",
    "    vbox_new_layout = widgets.Layout(display='flex', flex_flow='column', align_items='center', width='100%')\n",
    "    vbox_new = widgets.VBox([back_button, title_label, button_load_data, arrow_down1, button_visualize_features, \n",
    "                             arrow_down2, button_input_parameters, arrow_down3, button_select_action, arrow_down4, \n",
    "                             button_run, arrow_down5, button_return_results], layout=vbox_new_layout)\n",
    "\n",
    "    # Add the new VBox to the vbox\n",
    "    vbox.children = [vbox_new]\n",
    "    \n",
    "def show_apriori_certification_old():\n",
    "    # Clear the vbox contents\n",
    "    vbox.children = []\n",
    "\n",
    "    # Back to Pipeline button\n",
    "    back_button = widgets.Button(description='Back to Pipeline', layout=widgets.Layout(width='150px', height='30px', margin='5px'))\n",
    "    def back_to_pipeline(b):\n",
    "        vbox.children = home_grid\n",
    "    back_button.on_click(back_to_pipeline)\n",
    "    \n",
    "    title_label = widgets.Label('Apriori Certify Fairness', \n",
    "                                layout=widgets.Layout(margin='10px'),\n",
    "                                style={'font_size': '20px', 'font_weight': 'bold'})\n",
    "\n",
    "    # Updated layout for wider buttons\n",
    "    button_layout_wide = widgets.Layout(width='300px', height='50px', margin='5px', border='solid black 1px')\n",
    "\n",
    "    # Creating new buttons for the bias detection toolkit\n",
    "    button_load_data = widgets.Button(description='Load Data', layout=button_layout_wide)\n",
    "    button_visualize_features = widgets.Button(description='Visualize/Select Features', layout=button_layout_wide)\n",
    "    button_input_parameters = widgets.Button(description='Give Input Parameters', layout=button_layout_wide)\n",
    "    button_select_action = widgets.Button(description='Give Model to Certify', layout=button_layout_wide)\n",
    "    button_run = widgets.Button(description='Run', layout=button_layout_wide)\n",
    "    button_return_results = widgets.Button(description='Return Results & Visualize', layout=button_layout_wide)\n",
    "\n",
    "    # Creating centered downward arrow labels\n",
    "    arrow_down_style = {'font_size': '24px'}\n",
    "    arrow_down1 = widgets.Label(value='↓', layout=widgets.Layout(width='auto'), style=arrow_down_style)\n",
    "    arrow_down2 = widgets.Label(value='↓', layout=widgets.Layout(width='auto'), style=arrow_down_style)\n",
    "    arrow_down3 = widgets.Label(value='↓', layout=widgets.Layout(width='auto'), style=arrow_down_style)\n",
    "    arrow_down4 = widgets.Label(value='↓', layout=widgets.Layout(width='auto'), style=arrow_down_style)\n",
    "    arrow_down5 = widgets.Label(value='↓', layout=widgets.Layout(width='auto'), style=arrow_down_style)\n",
    "\n",
    "    # Create a new vertical box (VBox) with centered alignment\n",
    "    vbox_new_layout = widgets.Layout(display='flex', flex_flow='column', align_items='center', width='100%')\n",
    "    vbox_new = widgets.VBox([back_button, title_label, button_load_data, arrow_down1, button_visualize_features, arrow_down2, \n",
    "                             button_input_parameters, arrow_down3, button_select_action, arrow_down4, \n",
    "                             button_run, arrow_down5, button_return_results], layout=vbox_new_layout)\n",
    "\n",
    "    # Add the new VBox to the vbox\n",
    "    vbox.children = [vbox_new]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_button_color(b):\n",
    "    global steps_box\n",
    "    for item in steps_box.children:\n",
    "        if not isinstance(item, VBox):\n",
    "            continue\n",
    "        button = item.children[0]\n",
    "        label = item.children[1].value\n",
    "        if current_state in label:\n",
    "        # ifbutton == b or (b.description == \"Start\" and \"Data\" in label): # for the starting case\n",
    "            button.style.button_color = 'LightSkyBlue'\n",
    "        else:\n",
    "            button.style.button_color = 'lightgray'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'widgets' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 231\u001b[0m\n\u001b[1;32m    228\u001b[0m     img \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m    230\u001b[0m \u001b[38;5;66;03m# Create loading bar widget\u001b[39;00m\n\u001b[0;32m--> 231\u001b[0m loading_bar \u001b[38;5;241m=\u001b[39m widgets\u001b[38;5;241m.\u001b[39mImage(value\u001b[38;5;241m=\u001b[39mimg, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgif\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdataset_analysis\u001b[39m(b):\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;28;01mglobal\u001b[39;00m global_output, current_state\n",
      "\u001b[0;31mNameError\u001b[0m: name 'widgets' is not defined"
     ]
    }
   ],
   "source": [
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "### Inner pipelines buttons\n",
    "\n",
    "### for BIAS DETECTION TOOLKIT ###\n",
    "# style2 = \"\"\"\n",
    "# <style>\n",
    "#     .widget-select-multiple {\n",
    "#         border: none !important;\n",
    "#         box-shadow: 0 4px 6px rgba(0,0,0,0.1);\n",
    "#         border-radius: 4px;\n",
    "#         overflow: hidden;\n",
    "#     }\n",
    "#     .widget-label {\n",
    "#         margin-right: 10px;\n",
    "#         color: #333;\n",
    "#     }\n",
    "#     .custom-select-container {\n",
    "#         display: flex;\n",
    "#         align-items: center;\n",
    "#         margin-bottom: 20px;\n",
    "#     }\n",
    "#     .custom-select-container .widget-html {\n",
    "#         margin-right: 10px;\n",
    "#     }\n",
    "# </style>\n",
    "# \"\"\"\n",
    "\n",
    "# display(HTML(style2))\n",
    "\n",
    "# def upload_bias_detection_data(b):\n",
    "#     global df, current_state\n",
    "#     current_state = \"Data\"\n",
    "    \n",
    "#     custom_css = \"\"\"\n",
    "#     <style>\n",
    "#         .custom-radio {\n",
    "#             display: flex;\n",
    "#             align-items: center;\n",
    "#             margin-bottom: 10px;\n",
    "#         }\n",
    "#         .custom-radio input {\n",
    "#             margin-right: 10px;\n",
    "#         }\n",
    "#         .custom-radio label {\n",
    "#             font-size: 16px;\n",
    "#             font-family: Optima, sans-serif;\n",
    "#         }\n",
    "#     </style>\n",
    "#     \"\"\"\n",
    "    \n",
    "#     # Custom HTML and JavaScript for the radio buttons\n",
    "#     dataset_html = \"<div class='radio-group'>\"\n",
    "#     for i, option in enumerate(dataset_options):\n",
    "#         checked_attribute = \"checked\" if i == 0 else \"\"\n",
    "#         dataset_html += f\"<div class='custom-radio'><input type='radio' id='radio{i}' name='dataset' value='{option['name']}' {checked_attribute} onclick='select_dataset(\\\"{option['name']}\\\")'>\"\n",
    "#         dataset_html += f\"<label for='radio{i}'>{option['name']} - <a href='{option['url']}' target='_blank' style='color: #0096FF; text-decoration: none; font-weight: bold;'>Learn more</a></label></div>\"\n",
    "#     dataset_html += \"</div>\"\n",
    "    \n",
    "#     full_html = custom_css + dataset_html\n",
    "    \n",
    "#     # Display the HTML and JavaScript\n",
    "#     dataset_selector = widgets.HTML(value=full_html)\n",
    "\n",
    "#     # Info message for dataset selection\n",
    "#     info_message = \"\"\"\n",
    "#     <div style=\"background-color: #f0f0f0; border: 1px solid #ccc; color: #333333; padding: 15px; border-radius: 5px; width: auto; margin: 10px auto; text-align: left;\">\n",
    "#         <span style=\"font-weight: bold; color: #333333; font-size: 16px;\">\n",
    "#             <i class=\"fa fa-database\" style=\"margin-right: 10px;\"></i> Dataset Information\n",
    "#         </span>\n",
    "#         <p style=\"font-size: 14px; margin-top: 10px;\">\n",
    "#             Choose a sample dataset to perform bias detection. This toolkit allows you to analyze and detect biases in various datasets. \n",
    "#             By selecting a dataset, you can explore how different biases may affect your model's performance and fairness. Select one of the available datasets to start your analysis and understand the biases present in the data.\n",
    "#         </p>\n",
    "#     </div>\n",
    "#     \"\"\"\n",
    "    \n",
    "#     combined_box = widgets.VBox([widgets.HTML(value=info_message), dataset_selector])\n",
    "    \n",
    "#     with global_output:\n",
    "#         # Display the combined box\n",
    "#         update_button_color(b)\n",
    "#         clean_toolkit_content()\n",
    "#         display(combined_box)\n",
    "\n",
    "def on_dataset_selector_change(change):\n",
    "    global df, X_adult, y_adult, sample_weight, selected_dataset\n",
    "    selected_dataset = change['new']\n",
    "    # selected_url = next(option['url'] for option in dataset_options if option['name'] == selected_option)\n",
    "    if selected_dataset == \"Ad Campaign\":\n",
    "        df = pd.read_csv(dataset_name_2_file_name[\"Ad Campaign\"])\n",
    "    elif selected_dataset == \"Adult (Census Income)\":\n",
    "        X_adult, y_adult, sample_weight = fetch_adult()\n",
    "        df = clean_dataset(X_adult.assign(income=y_adult), \"adult\")\n",
    "    elif selected_dataset == \"Workable\":\n",
    "        #df = pd.read_parquet(dataset_name_2_file_name[\"Workable\"],engine=\"pyarrow\")\n",
    "        df_schema = pd.read_parquet(dataset_name_2_file_name[\"Workable\"], engine=\"pyarrow\", columns=None)\n",
    "        all_columns = df_schema.columns.tolist()\n",
    "        # Step 2: Specify columns to exclude\n",
    "        exclude = [\"skills\"]\n",
    "        # Step 3 Filter the remaining columns\n",
    "        include_columns = [col for col in all_columns if col not in exclude]\n",
    "        # Step 4: Load only the desired columns\n",
    "        df = pd.read_parquet(dataset_name_2_file_name[\"Workable\"], columns=include_columns)\n",
    "\n",
    "\n",
    "def on_algorithm_selector_change(change):\n",
    "    global selected_algorithm\n",
    "    selected_algorithm = change['new']\n",
    "\n",
    "# def on_metric_selector_change(change):\n",
    "#     global selected_algorithm_parameters\n",
    "#     selected_algorithm_parameters['metric'] = change['new'].lower().replace(' ', '-')\n",
    "    \n",
    "# Function to handle changes in the metric selector\n",
    "def on_metric_selector_change(change):\n",
    "    global phi_widget, c_widget, selected_algorithm_parameters\n",
    "    selected_algorithm_parameters['metric'] = change['new'].lower().replace(' ', '-')\n",
    "    \n",
    "    if change['new'] in {\"Equal choice for recourse\", \"Equal cost of effectiveness\"}:\n",
    "        phi_widget.layout.display = 'block'\n",
    "        c_widget.layout.display = 'none'\n",
    "        del selected_algorithm_parameters['c'] # delete unused value           \n",
    "    elif change['new'] == \"Equal effectiveness within budget\":\n",
    "        phi_widget.layout.display = 'none'\n",
    "        c_widget.layout.display = 'block'\n",
    "        del selected_algorithm_parameters['phi'] # delete unused value\n",
    "    else:\n",
    "        phi_widget.layout.display = 'none'\n",
    "        c_widget.layout.display = 'none'\n",
    "        # delete unused values\n",
    "        del selected_algorithm_parameters['phi']\n",
    "        del selected_algorithm_parameters['c']\n",
    "    \n",
    "def on_viewpoint_selector_change(change):\n",
    "    global selected_algorithm_parameters\n",
    "    selected_algorithm_parameters['viewpoint'] = change['new'].lower()\n",
    "\n",
    "def on_score_function_selector_change(change):\n",
    "    pass\n",
    "\n",
    "def on_penalty_function_selector_change(change):\n",
    "    global selected_algorithm_parameters\n",
    "    selected_algorithm_parameters['penalty'] = change['new']\n",
    "\n",
    "# Function to upload bias detection data\n",
    "def upload_bias_detection_data(b):\n",
    "    global df, current_state, selected_dataset\n",
    "    current_state = \"Data\"\n",
    "    with global_output:\n",
    "        # Info message for dataset selection\n",
    "        info_message = \"\"\"\n",
    "        <div style=\"background-color: #f0f0f0; border: 1px solid #ccc; color: #333333; padding: 15px; border-radius: 5px; width: auto; margin: 10px auto; text-align: left;\">\n",
    "            <span style=\"font-weight: bold; color: #333333; font-size: 16px;\">\n",
    "                <i class=\"fa fa-database\" style=\"margin-right: 10px;\"></i> Dataset Information\n",
    "            </span>\n",
    "            <p style=\"font-size: 14px; margin-top: 10px;\">\n",
    "                Choose a sample dataset to perform bias detection. This toolkit allows you to analyze and detect biases in various datasets. \n",
    "                By selecting a dataset, you can explore how different biases may affect your model's performance and fairness. Select one of the available datasets to start your analysis and understand the biases present in the data.\n",
    "            </p>\n",
    "            <p style=\"font-size: 14px; font-weight: bold; color: red\">\n",
    "                Note that a dataset may only support a specific algorithm for bias detection. \n",
    "                For example, the dataset \"Ad Campaign\" can only be used with the MDSS algorithm.\n",
    "            </p>\n",
    "            <p style=\"font-size: 14px; margin-top: 10px;\">\n",
    "                <span style=\"font-weight: bold;\">About supported datasets (click on dataset name to learn more):</span>\n",
    "                <ul style=\"font-size: 14px;\">\n",
    "                    <li><b><a href=\"https://developer.ibm.com/exchanges/data/all/bias-in-advertising/\" target=\"_blank\" style=\"color: #0096FF; text-decoration: none;\">Ad Campaign</a>:</b> A synthetic dataset for users who were shown a certain advertisement.</li>\n",
    "                    <li><b><a href=\"https://archive.ics.uci.edu/dataset/2/adult\" target=\"_blank\" style=\"color: #0096FF; text-decoration: none;\">Adult</a>:</b> A dataset to predict whether income exceeds $50K/yr based on census data. Also known as the \"Census Income\" dataset.</li>\n",
    "                    <li><b><a href=\"https://workable.com\" target=\"_blank\" style=\"color: #0096FF; text-decoration: none;\">Workable HR automation Data</a>:</b> A dataset provided by Workable.com</li>\n",
    "                </ul>\n",
    "            </p>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "\n",
    "        # Create Dropdown for dataset selection\n",
    "        dataset_selector = widgets.RadioButtons(\n",
    "            # description='Select Dataset:',\n",
    "            options=[option['name'] for option in dataset_options],\n",
    "            style={'description_width': 'initial'},\n",
    "            layout=widgets.Layout(width='50%', margin='10px 0 0 10px')\n",
    "        )\n",
    "        dataset_selector.add_class('my-radio-style')\n",
    "        # Add event listener to the Dropdown\n",
    "        # By default the selected dataset is \"Ad Campaign\"\n",
    "        df = pd.read_csv(dataset_name_2_file_name[\"Ad Campaign\"])\n",
    "        selected_dataset = \"Ad Campaign\"\n",
    "        dataset_selector.observe(on_dataset_selector_change, names='value')\n",
    "\n",
    "        # Combine the info box and the custom dataset selector\n",
    "        combined_box = widgets.VBox([widgets.HTML(value=info_message), dataset_selector])\n",
    "\n",
    "        # Display the combined box\n",
    "        update_button_color(b)\n",
    "        clean_toolkit_content()\n",
    "        display(combined_box)\n",
    "\n",
    "# def upload_bias_detection_data(b):\n",
    "#     global df, current_state\n",
    "#     current_state = \"Data\"\n",
    "#     with global_output:\n",
    "#         info_message = \"\"\"\n",
    "#         <div style=\"background-color: #f0f0f0; border: 1px solid #ccc; color: #333333; padding: 15px; border-radius: 5px; width: auto; margin: 10px auto; text-align: left;\">\n",
    "#             <span style=\"font-weight: bold; color: #333333; font-size: 16px;\">\n",
    "#                 <i class=\"fa fa-database\" style=\"margin-right: 10px;\"></i> Dataset Information\n",
    "#             </span>\n",
    "#             <p style=\"font-size: 14px; margin-top: 10px;\">\n",
    "#                 Choose a sample dataset to perform bias detection. This toolkit allows you to analyze and detect biases in various datasets. \n",
    "#                 By selecting a dataset, you can explore how different biases may affect your model's performance and fairness. Select one of the available datasets to start your analysis and understand the biases present in the data.\n",
    "#             </p>\n",
    "#         </div>\n",
    "#         \"\"\"\n",
    "        \n",
    "#         dataset_html = \"<div style='font-size: 16px; margin-top: 10px;'>\"\n",
    "#         for i, option in enumerate(dataset_options):\n",
    "#             checked_attribute = \"checked\" if i == 0 else \"\"\n",
    "#             dataset_html += f\"<div style='margin-bottom: 10px;'><input type='radio' name='dataset' value='{option['name']}' style='margin-right: 10px;' {checked_attribute}>\"\n",
    "#             dataset_html += f\"<label style='font-size: 16px;'>{option['name']} - <a href='{option['url']}' target='_blank' style='color: #0096FF; text-decoration: none; font-weight: bold;'>Learn more</a></label></div>\"\n",
    "#         dataset_html += \"</div>\"\n",
    "\n",
    "#         dataset_selector = widgets.HTML(\n",
    "#             value=dataset_html,\n",
    "#             layout=widgets.Layout(margin='10px 0 0 0', width='auto')\n",
    "#         )\n",
    "#         dataset_selector.add_class('my-font')\n",
    "#         # By default the dataset is 'Ad Campaign'\n",
    "        \n",
    "#         # Combine the info box and the custom dataset selector\n",
    "#         combined_box = widgets.VBox([widgets.HTML(value=info_message), dataset_selector])\n",
    "        \n",
    "#         update_button_color(b)\n",
    "#         clean_toolkit_content()\n",
    "#         display(combined_box)\n",
    "\n",
    "# Path to your loading bar GIF\n",
    "gif_address = 'loading_bar.gif'\n",
    "\n",
    "# Load the GIF\n",
    "with open(gif_address, 'rb') as f:\n",
    "    img = f.read()\n",
    "\n",
    "# Create loading bar widget\n",
    "loading_bar = widgets.Image(value=img, format='gif')\n",
    "\n",
    "\n",
    "def plot_histogram_grid_all(df):\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "    features = df.columns\n",
    "    num_features = len(features)\n",
    "    num_rows = num_features // 3 + (num_features % 3 > 0)\n",
    "\n",
    "    fig, axes = plt.subplots(num_rows, 3, figsize=(18, 5 * num_rows))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i, feature in enumerate(features):\n",
    "        ax = axes[i]\n",
    "        series = df[feature]\n",
    "\n",
    "        try:\n",
    "            # Drop missing values\n",
    "            data = series.dropna()\n",
    "\n",
    "            # Determine if the feature is numeric\n",
    "            is_numeric = pd.api.types.is_numeric_dtype(data)\n",
    "\n",
    "            if is_numeric:\n",
    "                sns.histplot(data=data, bins=20, kde=True, ax=ax, color=sns.color_palette(\"Set2\")[i % 8])\n",
    "            else:\n",
    "                # Treat non-numeric (categorical) data\n",
    "                sns.histplot(data=data.astype(str), discrete=True, shrink=0.8, ax=ax, color=sns.color_palette(\"Set2\")[i % 8])\n",
    "\n",
    "            ax.set_title(f'Histogram of {feature}', fontsize=14, fontweight='bold')\n",
    "            ax.set_xlabel(feature, fontsize=12)\n",
    "            ax.set_ylabel('Frequency', fontsize=12)\n",
    "\n",
    "            # Optional: reduce x-tick labels for categorical with many unique values\n",
    "            if not is_numeric and len(data.unique()) > 10:\n",
    "                ax.set_xticks(ax.get_xticks()[::2])\n",
    "            ax.tick_params(axis='x', rotation=45)\n",
    "\n",
    "        except Exception as e:\n",
    "            ax.text(0.5, 0.5, f'Error: {str(e)}', ha='center', va='center')\n",
    "\n",
    "    for i in range(num_features, len(axes)):\n",
    "        fig.delaxes(axes[i])\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Convert the figure to base64\n",
    "    img_buf = io.BytesIO()\n",
    "    plt.savefig(img_buf, format='png', bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    img_buf.seek(0)\n",
    "\n",
    "    img_base64 = base64.b64encode(img_buf.read()).decode('utf-8')\n",
    "    img_html = f'<div style=\"width: 90%; margin: auto; text-align: center;\"><img src=\"data:image/png;base64,{img_base64}\" style=\"width: 100%;\"/></div>'\n",
    "    display(HTML(img_html))\n",
    "\n",
    "\n",
    "def dataset_analysis(b):\n",
    "    global global_output, current_state\n",
    "    current_state = \"Analyze\"\n",
    "    info_message_analyze = f\"\"\"\n",
    "    <div style=\"background-color: #f0f0f0; border: 1px solid #ccc; color: #333333; padding: 15px; border-radius: 5px; width: auto; margin: 10px auto; text-align: left;\">\n",
    "        <span style=\"font-weight: bold; color: #333333; font-size: 16px;\">\n",
    "            <i class=\"fa fa-chart-bar\" style=\"margin-right: 10px;\"></i> Dataset Analysis\n",
    "        </span>\n",
    "        <p style=\"font-size: 14px; margin-top: 10px;\">\n",
    "            <b>Dataset loaded:</b> {selected_dataset}.\n",
    "        </p>\n",
    "        <p style=\"font-size: 14px; margin-top: 10px;\">\n",
    "            We are displaying the first few rows of the dataset to understand its structure. \n",
    "            Also, histograms are generated for numerical and categorical features to visualize their distributions.\n",
    "            Histograms help in understanding the range, central tendency, and variability of the data.\n",
    "        </p>    \n",
    "    </div>\n",
    "    \"\"\"\n",
    "    with global_output:\n",
    "        # Display the loading bar initially\n",
    "        update_button_color(b)\n",
    "        clean_toolkit_content()\n",
    "        \n",
    "        loading_box = widgets.VBox([loading_bar], layout=widgets.Layout(align_items='center', width='100%'))\n",
    "        \n",
    "        # Display the centered loading bar initially\n",
    "        display(loading_box)\n",
    "        \n",
    "        # Create an Output widget to capture all the outputs\n",
    "        tmp_output_widget = widgets.Output()\n",
    "\n",
    "        # Define a function to run the actual analysis\n",
    "        def run_analysis():\n",
    "            with tmp_output_widget: # Capture all the outputs in the output widget\n",
    "                display_dataframe_styled(df.head())\n",
    "                if selected_dataset == \"Adult (Census Income)\":\n",
    "                    plot_histogram_grid(list(df)[1:])\n",
    "                else:\n",
    "                    plot_histogram_grid_top10_spaced(df)\n",
    "                    \n",
    "        # Run the analysis function\n",
    "        run_analysis()\n",
    "        \n",
    "        # Clear the loading bar and display all the captured outputs\n",
    "        clean_toolkit_content()\n",
    "        display(widgets.HTML(value=info_message_analyze))\n",
    "        display(tmp_output_widget)\n",
    "\n",
    "def select_features(b):\n",
    "    global features_4_scanning, features_status_output, current_state\n",
    "    current_state = \"Features\"\n",
    "    \n",
    "    if 'df' in globals():\n",
    "        # Info message for feature selection\n",
    "        info_message = \"\"\"\n",
    "        <div style=\"background-color: #f0f0f0; border: 1px solid #ccc; color: #333333; padding: 15px; border-radius: 5px; width: auto; margin: 10px auto; text-align: left;\">\n",
    "            <span style=\"font-weight: bold; color: #333333; font-size: 16px;\">\n",
    "                <i class=\"fa fa-list\" style=\"margin-right: 10px;\"></i> Feature/Protected Attribute Selection\n",
    "            </span>\n",
    "            <p style=\"font-size: 14px; margin-top: 10px;\">\n",
    "                Select the features or protected attributes (depending on the bias detection model you will select next) you want to include in the bias detection analysis. \n",
    "                The selected features/protected attributes will be used to identify potential biases in the dataset.\n",
    "            </p>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "        \n",
    "        info_box = widgets.HTML(\n",
    "            value=info_message,\n",
    "            layout=widgets.Layout(margin='0px', width='100%', padding='5px 0px 5px 0px')\n",
    "        )\n",
    "\n",
    "        selector = widgets.SelectMultiple(\n",
    "            options=df.columns,\n",
    "            disabled=False,\n",
    "            layout=widgets.Layout(width='20%', height='180px')\n",
    "        )\n",
    "        \n",
    "        selector.add_class('my-select-multiple')\n",
    "        \n",
    "        features_box = widgets.VBox([selector], \n",
    "                                    layout=widgets.Layout(align_items='center', \n",
    "                                    justify_content='center', width='100%'))\n",
    "\n",
    "        status_message = f'<div style=\"background-color: #f0f0f0; border: 1px solid #ccc; border-radius: 5px; padding: 10px; width: auto; margin: 10px auto; text-align: left;\">'\n",
    "        status_message += f'<span style=\"color: red; font-weight: bold;\">No selected features/protected attributes.</span></div>'\n",
    "        \n",
    "        with global_output:\n",
    "            update_button_color(b)\n",
    "            clean_toolkit_content()\n",
    "            display(info_box)\n",
    "            display(features_box)\n",
    "            display(features_status_output)\n",
    "        \n",
    "        with features_status_output:\n",
    "            features_status_output.clear_output(wait=True)\n",
    "            display(HTML(status_message))\n",
    "            \n",
    "        selector.observe(update_selected_features, names='value')\n",
    "    else:\n",
    "        with global_output:\n",
    "            update_button_color(b)\n",
    "            clean_toolkit_content()\n",
    "            display_message(\"No dataset loaded.\", color='red')\n",
    "\n",
    "\n",
    "# def display_parameters_hydra(cfg):\n",
    "#     \"\"\"\n",
    "#     Display all parameters from the configuration file in a VBox.\n",
    "#     \"\"\"\n",
    "#     parameter_widgets = []\n",
    "    \n",
    "#     # Iterate over all parameters and add them to widgets\n",
    "#     for param_name, values in cfg.parameters.items():\n",
    "#         description = widgets.HTML(\n",
    "#             value=f\"<b>{param_name}:</b> {values}\"\n",
    "#         )\n",
    "#         parameter_widgets.append(description)\n",
    "    \n",
    "#     # Create a VBox to display parameters\n",
    "#     vbox = widgets.VBox(parameter_widgets)\n",
    "#     return vbox\n",
    "\n",
    "\n",
    "def give_parameters_updated_and_extended(b):\n",
    "    global current_state, selected_algorithm_parameters\n",
    "    current_state = \"Parameters\"\n",
    "    \n",
    "    with global_output:\n",
    "        info_message = \"\"\"\n",
    "        <div style=\"background-color: #f0f0f0; border: 1px solid #ccc; color: #333333; padding: 15px; border-radius: 5px; width: auto; margin: 10px auto; text-align: left;\">\n",
    "            <span style=\"font-weight: bold; color: #333333; font-size: 16px;\">\n",
    "                <i class=\"fa fa-sliders\" style=\"margin-right: 10px;\"></i> Algorithm Parameters\n",
    "            </span>\n",
    "            <p style=\"font-size: 14px; margin-top: 10px;\">\n",
    "                Each algorithm requires a different set of configuration parameters. You are seeing the parameters associated with algorithm you chose in the 'Model' stage.\n",
    "            </p>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "\n",
    "        if selected_algorithm == \"Multi-Dimensional Subset Scan (MDSS)\":\n",
    "            # Info message for scoring function selection\n",
    "            mdss_info_message = \"\"\"\n",
    "            <div style=\"background-color: #f0f0f0; border: 1px solid #ccc; color: #333333; padding: 15px; border-radius: 5px; width: auto; margin: 10px auto; text-align: left;\">\n",
    "                <span style=\"font-weight: bold; color: #333333; font-size: 16px;\">\n",
    "                    <i class=\"fa fa-sliders\" style=\"margin-right: 10px;\"></i> Select the parameters for MDSS\n",
    "                </span>\n",
    "                <p style=\"font-size: 14px; margin-top: 10px;\">\n",
    "                    <b>MDSS requires the following parameters:</b>\n",
    "                </p>\n",
    "                <ul style=\"font-size: 14px; margin-top: 5px;\">\n",
    "                    <li><b>Scoring function:</b> The scoring function evaluates the quality of subsets by measuring how much the observed data deviates from the expected data under a null hypothesis.</li>\n",
    "                    <li><b>Number of iterations:</b> The number of iterations determines how many times the algorithm will run to find the optimal subset.</li>\n",
    "                    <li><b>Penalty:</b> The penalty parameter controls the trade-off between the size of the subset and the scoring function value, helping to prevent overfitting.</li>\n",
    "                </ul>\n",
    "            </div>\n",
    "            \"\"\"\n",
    "\n",
    "            from omegaconf import OmegaConf\n",
    "\n",
    "            # Load the config.yaml manually\n",
    "            config_path = \"configs/mdss.yaml\"\n",
    "            cfg = OmegaConf.load(config_path)\n",
    "\n",
    "            # Create HTML widgets to display the parameters\n",
    "            C_display = widgets.HTML(value=f\"<b>Scoring Function:</b> Bernoulli\")\n",
    "            penalty_display = widgets.HTML(value=f\"<b>Penalty:</b> {', '.join(map(str, cfg.parameters.penalty))}\")\n",
    "            iterations_display = widgets.HTML(value=f\"<b>Maximum number of iterations:</b> {', '.join(map(str, cfg.parameters.num_iters))}\")\n",
    "            \n",
    "            # Combine all parameter displays into a VBox\n",
    "            combined_box = widgets.VBox([widgets.HTML(value=mdss_info_message),widgets.HTML(value=\"<b>Algorithm Configuration Parameters:</b>\"),penalty_display,C_display,iterations_display])\n",
    "            \n",
    "            # # Create Dropdown for dataset selection\n",
    "            # scoring_function_selector = widgets.RadioButtons(\n",
    "            #     description='Scoring function:',\n",
    "            #     options=[\"Bernoulli\"],\n",
    "            #     style={'description_width': 'initial'},\n",
    "            #     layout=widgets.Layout(width='50%', margin='10px 0 0 10px')\n",
    "            # )\n",
    "            # scoring_function_selector.add_class('my-radio-style')\n",
    "\n",
    "            # # By default the selected algorithm is the first option\n",
    "            # selected_algorithm_parameters['scoring_function'] = scoring_function_selector.options[0]\n",
    "            # scoring_function_selector.observe(on_score_function_selector_change, names='value')\n",
    "            \n",
    "            # # Create IntText widgets for Penalty and Number of iterations\n",
    "            # penalty_widget = widgets.BoundedIntText(\n",
    "            #     value=1,\n",
    "            #     min=1,\n",
    "            #     description='Penalty:',\n",
    "            #     style={'description_width': 'initial'},\n",
    "            #     layout=widgets.Layout(width='30%', margin='10px 0 0 10px')\n",
    "            # )\n",
    "            # penalty_widget.add_class('my-int-text')\n",
    "            \n",
    "            # iterations_widget = widgets.BoundedIntText(\n",
    "            #     value=1,\n",
    "            #     min=1,\n",
    "            #     description='Number of iterations:',\n",
    "            #     style={'description_width': 'initial'},\n",
    "            #     layout=widgets.Layout(width='30%', margin='10px 0 0 10px')\n",
    "            # )\n",
    "            # iterations_widget.add_class('my-int-text')\n",
    "            \n",
    "            # # Store the default values in the selected_algorithm_parameters dictionary\n",
    "            # selected_algorithm_parameters['penalty'] = penalty_widget.value\n",
    "            # selected_algorithm_parameters['num_iterations'] = iterations_widget.value\n",
    "\n",
    "            # # Observe changes in the widgets\n",
    "            # penalty_widget.observe(lambda change: selected_algorithm_parameters.update({'penalty': change['new']}), names='value')\n",
    "            # iterations_widget.observe(lambda change: selected_algorithm_parameters.update({'num_iterations': change['new']}), names='value')\n",
    "\n",
    "            # Combine the info box, scoring function selector, and parameter input widgets\n",
    "            # combined_box = widgets.VBox([widgets.HTML(value=mdss_info_message), scoring_function_selector, penalty_widget, iterations_widget])\n",
    "        elif selected_algorithm == \"Bias Detection via Optimal Transport (Logistic Regression)\":\n",
    "            # Info message for scoring function selection\n",
    "            ot_info_message = \"\"\"\n",
    "            <div style=\"background-color: #f0f0f0; border: 1px solid #ccc; color: #333333; padding: 15px; border-radius: 5px; width: auto; margin: 10px auto; text-align: left;\">\n",
    "                <span style=\"font-weight: bold; color: #333333; font-size: 16px;\">\n",
    "                    <i class=\"fa fa-sliders\" style=\"margin-right: 10px;\"></i> Select the parameters for OT\n",
    "                </span>\n",
    "                <p style=\"font-size: 14px; margin-top: 10px;\">\n",
    "                    <b>OT requires the following parameters:</b>\n",
    "                </p>\n",
    "                <ul style=\"font-size: 14px; margin-top: 5px;\">\n",
    "                    <li><b>Penalty:</b> The penalty parameter controls the trade-off between the size of the subset and the scoring function value, helping to prevent overfitting.</li>\n",
    "                    <li><b>C:</b> The parameter <b>C</b> is a regularization parameter which controls the trade-off between achieving a low error on the training data and minimizing the complexity of the model.</li>\n",
    "                    <li><b>Maximum number of iterations:</b> The number of iterations determines how many times the algorithm will run to find the optimal subset.</li>\n",
    "                </ul>\n",
    "            </div>\n",
    "            \"\"\"\n",
    "            from omegaconf import OmegaConf\n",
    "\n",
    "            # Load the config.yaml manually\n",
    "            config_path = \"configs/config.yaml\"\n",
    "            cfg = OmegaConf.load(config_path)\n",
    "\n",
    "            # Create HTML widgets to display the parameters\n",
    "            penalty_display = widgets.HTML(value=f\"<b>Penalty:</b> {', '.join(cfg.parameters.penalty)}\")\n",
    "\n",
    "            C_display = widgets.HTML(value=f\"<b>C (Regularization):</b> {', '.join(map(str, cfg.parameters.c))}\")\n",
    "\n",
    "            iterations_display = widgets.HTML(value=f\"<b>Maximum number of iterations:</b> {', '.join(map(str, cfg.parameters.n_iter))}\")\n",
    "\n",
    "            # Combine all parameter displays into a VBox\n",
    "            combined_box = widgets.VBox([widgets.HTML(value=ot_info_message),widgets.HTML(value=\"<b>Algorithm Configuration Parameters:</b>\"),penalty_display,C_display,iterations_display])\n",
    "        elif selected_algorithm == \"Fairness Aware Counterfactuals for Subgroups (FACTS)\":\n",
    "            # Info message for scoring function selection\n",
    "            facts_info_message = \"\"\"\n",
    "            <div style=\"background-color: #f0f0f0; border: 1px solid #ccc; color: #333333; padding: 15px; border-radius: 5px; width: auto; margin: 10px auto; text-align: left;\">\n",
    "                <span style=\"font-weight: bold; color: #333333; font-size: 16px;\">\n",
    "                    <i class=\"fa fa-sliders\" style=\"margin-right: 10px;\"></i> Select the parameters for FACTS\n",
    "                </span>\n",
    "                <p style=\"font-size: 14px; margin-top: 10px;\">\n",
    "                    <b>FACTS requires the following parameters:</b>\n",
    "                </p>\n",
    "                <ul style=\"font-size: 14px; margin-top: 5px;\">\n",
    "                    <li><b>Maximum number of iterations:</b> The maximum number of iterations allowed for convergence of the solver of the demonstration ML model, here a simple logistic regression.</li>\n",
    "                    <li><b>Frequent Itemset Minimum Support:</b>All groups of individuals examined are constrained to cover at least this percentage of the whole population.</li>\n",
    "                    <li><b>Viewpoint:</b>One of two viewpoints defined for counterfactual actions by our framework. \"macro\" means that all individuals in a group must receive the same action, while \"micro\" means that each individual can choose, from a set of actions, the one that flips their class and has the minimum cost for the specific individual.</li>\n",
    "                    <li><b>Metric:</b> The fairness metric/definition to be used by the algorithm.</li>\n",
    "                    <li><b>Phi:</b> This is the parameter that determines whether we consider an action sufficiently effective or not.</li>\n",
    "                    <li><b>Top count:</b> The number of (most) biased groups to detect based on the given metric.</li>\n",
    "                    Specifically, an action is considered effective if it manages to flip the prediction of the individuals under study with at least <it>phi</it> probability, and ineffective otherwise.</li>\n",
    "                    <li><b>Features not allowed to change:</b> The features that are not allowed to be changed from the algorithm. By default none. You may select up to two.</li>\n",
    "                </ul>\n",
    "            </div>\n",
    "            \"\"\"\n",
    "            \n",
    "            iterations_widget = widgets.BoundedIntText(\n",
    "                value=1500,\n",
    "                min=1,\n",
    "                max=10000,\n",
    "                description='Maximum number of iterations:',\n",
    "                style={'description_width': 'initial'},\n",
    "                layout=widgets.Layout(width='30%', margin='10px 0 0 10px')\n",
    "            )\n",
    "            iterations_widget.add_class('my-int-text')\n",
    "            selected_algorithm_parameters['num_iterations'] = iterations_widget.value\n",
    "            # Observe changes in the widgets\n",
    "            iterations_widget.observe(lambda change: selected_algorithm_parameters.update({'num_iterations': change['new']}), names='value')\n",
    "\n",
    "            itemset_min_support_widget = widgets.BoundedFloatText(\n",
    "                value=0.1,\n",
    "                min=0,\n",
    "                description='Frequent Itemset Minimum Support:',\n",
    "                style={'description_width': 'initial'},\n",
    "                layout=widgets.Layout(width='30%', margin='10px 0 0 10px')\n",
    "            )\n",
    "            itemset_min_support_widget.add_class('my-int-text')\n",
    "            selected_algorithm_parameters['itemset_min_support'] = itemset_min_support_widget.value\n",
    "            # Observe changes in the widgets\n",
    "            itemset_min_support_widget.observe(lambda change: selected_algorithm_parameters.update({'itemset_min_support': change['new']}), names='value')\n",
    "\n",
    "            # Add viewpoint\n",
    "            viewpoint_selector = widgets.RadioButtons(\n",
    "                description='Viewpoint:',\n",
    "                value=\"macro\",\n",
    "                options=[\"micro\", \"macro\"],\n",
    "                style={'description_width': 'initial'},\n",
    "                layout=widgets.Layout(width='50%', margin='10px 0 0 10px')\n",
    "            )\n",
    "            viewpoint_selector.add_class('my-radio-style')\n",
    "            selected_algorithm_parameters['viewpoint'] = viewpoint_selector.value.lower()\n",
    "            viewpoint_selector.observe(on_viewpoint_selector_change, names='value')\n",
    "\n",
    "            metric_selector = widgets.RadioButtons(\n",
    "                description='Fairness metric:',\n",
    "                value=\"Equal choice for recourse\",\n",
    "                options=[\"Equal choice for recourse\", \n",
    "                         \"Equal effectiveness\", \n",
    "                         \"Equal effectiveness within budget\", \n",
    "                         \"Equal cost of effectiveness\",\n",
    "                         \"Equal mean recourse\",\n",
    "                         \"Fair tradeoff\",],\n",
    "                style={'description_width': 'initial'},\n",
    "                layout=widgets.Layout(width='50%', margin='10px 0 0 10px')\n",
    "            )\n",
    "            metric_selector.add_class('my-radio-style')\n",
    "            selected_algorithm_parameters['metric'] = metric_selector.value.lower().replace(' ','-')\n",
    "            metric_selector.observe(on_metric_selector_change, names='value')            \n",
    "            global phi_widget, c_widget\n",
    "            phi_widget = widgets.BoundedFloatText(\n",
    "                value=0.1,\n",
    "                min=0,\n",
    "                description='Phi:',\n",
    "                style={'description_width': 'initial'},\n",
    "                layout=widgets.Layout(width='30%', margin='10px 0 0 10px', display='block')\n",
    "            )\n",
    "            phi_widget.add_class('my-int-text')\n",
    "            selected_algorithm_parameters['phi'] = phi_widget.value\n",
    "\n",
    "            # Observe changes in the widgets\n",
    "            phi_widget.observe(lambda change: selected_algorithm_parameters.update({'phi': change['new']}), names='value')\n",
    "            \n",
    "            c_widget = widgets.BoundedIntText(\n",
    "                value=1,\n",
    "                min=1,\n",
    "                description='Cost budget (c):',\n",
    "                style={'description_width': 'initial'},\n",
    "                layout=widgets.Layout(width='30%', margin='10px 0 0 10px', display='none')  # Initially hidden\n",
    "            )\n",
    "            c_widget.add_class('my-int-text')\n",
    "            # selected_algorithm_parameters['c'] = c_widget.value\n",
    "            c_widget.observe(lambda change: selected_algorithm_parameters.update({'c': change['new']}), names='value')\n",
    "\n",
    "            features_not_to_change_selector = widgets.SelectMultiple(\n",
    "                description=\"Features not to change:\",\n",
    "                options=df.columns,\n",
    "                layout=widgets.Layout(width='30%', height='180px', margin='10px 0 0 10px'),\n",
    "                style={'description_width': 'initial'}\n",
    "            )\n",
    "\n",
    "            features_not_to_change_selector.add_class('my-select-multiple')\n",
    "            features_not_to_change_selector.observe(update_selected_not_to_change_features, names='value')\n",
    "            \n",
    "            top_count_widget = widgets.BoundedIntText(\n",
    "                value=3,\n",
    "                min=1,\n",
    "                description='Number of subgroups to show:',\n",
    "                style={'description_width': 'initial'},\n",
    "                layout=widgets.Layout(width='30%', margin='10px 0 0 10px')\n",
    "            )\n",
    "            top_count_widget.add_class('my-int-text')\n",
    "            selected_algorithm_parameters['top_count'] = top_count_widget.value\n",
    "            # Observe changes in the widgets\n",
    "            top_count_widget.observe(lambda change: selected_algorithm_parameters.update({'top_count': change['new']}), names='value')\n",
    "            \n",
    "            status_message = f'<div style=\"background-color: #f0f0f0; border: 1px solid #ccc; border-radius: 5px; padding: 10px; width: auto; margin: 10px auto; text-align: left;\">'\n",
    "            status_message += f'<span style=\"color: red; font-weight: bold;\">No selected not to change features.</span></div>'\n",
    "        \n",
    "            # Combine the info box, scoring function selector, and parameter input widgets\n",
    "            combined_box = widgets.VBox([widgets.HTML(value=facts_info_message), \n",
    "                                         iterations_widget,\n",
    "                                         itemset_min_support_widget,\n",
    "                                         viewpoint_selector,\n",
    "                                         metric_selector, \n",
    "                                         phi_widget,\n",
    "                                         c_widget,\n",
    "                                         top_count_widget,\n",
    "                                         features_not_to_change_selector,\n",
    "                                         not_to_change_features_status_output])\n",
    "            \n",
    "            with not_to_change_features_status_output:\n",
    "                not_to_change_features_status_output.clear_output(wait=True)\n",
    "                display(HTML(status_message))   \n",
    "        elif selected_algorithm == \"Fairness Aware Counterfactuals for Subgroups (FACTS)\":\n",
    "            facts_info_message = \"\"\"\n",
    "            <div style=\"background-color: #f0f0f0; border: 1px solid #ccc; color: #333333; padding: 15px; border-radius: 5px; width: auto; margin: 10px auto; text-align: left;\">\n",
    "                <span style=\"font-weight: bold; color: #333333; font-size: 16px;\">\n",
    "                    <i class=\"fa fa-sliders\" style=\"margin-right: 10px;\"></i> Select the parameters for FACTS\n",
    "                </span>\n",
    "                <p style=\"font-size: 14px; margin-top: 10px;\">\n",
    "                    <b>FACTS requires the following parameters:</b>\n",
    "                </p>\n",
    "                <ul style=\"font-size: 14px; margin-top: 5px;\">\n",
    "                    <li><b>Maximum number of iterations:</b> The maximum number of iterations allowed for convergence of the solver of the demonstration ML model, here a simple logistic regression.</li>\n",
    "                    <li><b>Frequent Itemset Minimum Support:</b>All groups of individuals examined are constrained to cover at least this percentage of the whole population.</li>\n",
    "                    <li><b>Viewpoint:</b>One of two viewpoints defined for counterfactual actions by our framework. \"macro\" means that all individuals in a group must receive the same action, while \"micro\" means that each individual can choose, from a set of actions, the one that flips their class and has the minimum cost for the specific individual.</li>\n",
    "                    <li><b>Metric:</b> The fairness metric/definition to be used by the algorithm.</li>\n",
    "                    <li><b>Phi:</b> This is the parameter that determines whether we consider an action sufficiently effective or not.</li>\n",
    "                    <li><b>Top count:</b> The number of (most) biased groups to detect based on the given metric.</li>\n",
    "                    Specifically, an action is considered effective if it manages to flip the prediction of the individuals under study with at least <it>phi</it> probability, and ineffective otherwise.</li>\n",
    "                    <li><b>Features not allowed to change:</b> The features that are not allowed to be changed from the algorithm. By default none. You may select up to two.</li>\n",
    "                </ul>\n",
    "            </div>\n",
    "            \"\"\"\n",
    "\n",
    "            \n",
    "        update_button_color(b)\n",
    "        clean_toolkit_content()\n",
    "        display(combined_box)\n",
    "\n",
    "\n",
    "def give_parameters_updated_and_extended_new(b):\n",
    "    global current_state, selected_algorithm_parameters\n",
    "    current_state = \"Parameters\"\n",
    "    selected_algorithm_parameters = {}\n",
    "\n",
    "    general_algorithms = [\n",
    "        \"Multi-Dimensional Subset Scan (MDSS)\",\n",
    "        \"Bias Detection via Optimal Transport (Logistic Regression)\",\n",
    "        \"Fairness Aware Counterfactuals for Subgroups (FACTS)\"\n",
    "    ]\n",
    "\n",
    "    with global_output:\n",
    "        update_button_color(b)\n",
    "        clean_toolkit_content()\n",
    "\n",
    "        # Info banner\n",
    "        info_message = \"\"\"\n",
    "        <div style=\"background-color: #f0f0f0; border: 1px solid #ccc; color: #333333; padding: 15px; border-radius: 5px; width: auto; margin: 10px auto; text-align: left;\">\n",
    "            <span style=\"font-weight: bold; color: #333333; font-size: 16px;\">\n",
    "                <i class=\"fa fa-sliders\" style=\"margin-right: 10px;\"></i> Algorithm Parameters\n",
    "            </span>\n",
    "            <p style=\"font-size: 14px; margin-top: 10px;\">\n",
    "                You may review and optionally edit the configuration parameters of the selected algorithm. If supported, you may enable Auto-Tuning using FLAML.\n",
    "            </p>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "        display(widgets.HTML(value=info_message))\n",
    "\n",
    "        auto_tune_checkbox = widgets.Checkbox(\n",
    "            value=False,\n",
    "            description=\"Auto-Tune Parameters with FLAML\"\n",
    "        )\n",
    "        display(auto_tune_checkbox)\n",
    "\n",
    "        if selected_algorithm in general_algorithms:\n",
    "            # Example for OT Logistic Regression\n",
    "            from sklearn.linear_model import LogisticRegression\n",
    "            from omegaconf import OmegaConf\n",
    "\n",
    "            model_class = None\n",
    "            init_args = {}\n",
    "            config_path = \"configs/config.yaml\"\n",
    "            cfg = OmegaConf.load(config_path)\n",
    "\n",
    "            if selected_algorithm == \"Bias Detection via Optimal Transport (Logistic Regression)\":\n",
    "                model_class = LogisticRegression\n",
    "                init_args = {\n",
    "                    \"max_iter\": cfg.parameters.n_iter[0],\n",
    "                    \"C\": cfg.parameters.c[0],\n",
    "                    \"penalty\": cfg.parameters.penalty[0].lower().replace(\" \", \"_\")\n",
    "                }\n",
    "\n",
    "            elif selected_algorithm == \"Multi-Dimensional Subset Scan (MDSS)\":\n",
    "                from subset_scanning.scanners import MDSS\n",
    "                from subset_scanning.scoring import Bernoulli\n",
    "                model_class = MDSS\n",
    "                init_args = {\n",
    "                    \"scoring_function\": Bernoulli(direction='negative')\n",
    "                }\n",
    "\n",
    "            elif selected_algorithm == \"Fairness Aware Counterfactuals for Subgroups (FACTS)\":\n",
    "                from facts import FACTS\n",
    "                model_class = FACTS\n",
    "                init_args = {\n",
    "                    \"clf\": None,\n",
    "                    \"prot_attr\": \"gender\",\n",
    "                    \"freq_itemset_min_supp\": 0.1,\n",
    "                    \"feature_weights\": {},\n",
    "                    \"feats_not_allowed_to_change\": None\n",
    "                }\n",
    "\n",
    "            model = model_class(**init_args)\n",
    "            param_widgets = {}\n",
    "            if hasattr(model, \"get_params\"):\n",
    "                for k, v in model.get_params().items():\n",
    "                    if isinstance(v, bool):\n",
    "                        w = widgets.Checkbox(value=v, description=k)\n",
    "                    elif isinstance(v, int):\n",
    "                        w = widgets.BoundedIntText(value=v, description=k, min=1, max=10000)\n",
    "                    elif isinstance(v, float):\n",
    "                        w = widgets.FloatText(value=v, description=k)\n",
    "                    else:\n",
    "                        w = widgets.Text(value=str(v), description=k)\n",
    "                    param_widgets[k] = w\n",
    "                display(widgets.VBox(list(param_widgets.values())))\n",
    "\n",
    "                if auto_tune_checkbox.value:\n",
    "                    display(widgets.HTML(value=\"<i>FLAML Auto-tuning will be applied during execution.</i>\"))\n",
    "\n",
    "            # Save current parameter widget values on update\n",
    "            def update_selected_algorithm_parameters(change):\n",
    "                for k, widget in param_widgets.items():\n",
    "                    selected_algorithm_parameters[k] = widget.value\n",
    "\n",
    "            for widget in param_widgets.values():\n",
    "                widget.observe(update_selected_algorithm_parameters, names='value')\n",
    "\n",
    "        else:\n",
    "            display(widgets.HTML(\"<b>This algorithm is handled by a custom pre/post-processing pipeline.</b>\"))\n",
    "\n",
    "\n",
    "\n",
    "def give_parameters_updated(b):\n",
    "    global current_state, selected_algorithm_parameters\n",
    "    current_state = \"Parameters\"\n",
    "    \n",
    "    with global_output:\n",
    "        info_message = \"\"\"\n",
    "        <div style=\"background-color: #f0f0f0; border: 1px solid #ccc; color: #333333; padding: 15px; border-radius: 5px; width: auto; margin: 10px auto; text-align: left;\">\n",
    "            <span style=\"font-weight: bold; color: #333333; font-size: 16px;\">\n",
    "                <i class=\"fa fa-sliders\" style=\"margin-right: 10px;\"></i> Algorithm Parameters\n",
    "            </span>\n",
    "            <p style=\"font-size: 14px; margin-top: 10px;\">\n",
    "                Each algorithm requires a different set of configuration parameters. You are seeing the parameters associated with algorithm you chose in the 'Model' stage.\n",
    "            </p>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "\n",
    "        if selected_algorithm == \"Multi-Dimensional Subset Scan (MDSS)\":\n",
    "            # Info message for scoring function selection\n",
    "            mdss_info_message = \"\"\"\n",
    "            <div style=\"background-color: #f0f0f0; border: 1px solid #ccc; color: #333333; padding: 15px; border-radius: 5px; width: auto; margin: 10px auto; text-align: left;\">\n",
    "                <span style=\"font-weight: bold; color: #333333; font-size: 16px;\">\n",
    "                    <i class=\"fa fa-sliders\" style=\"margin-right: 10px;\"></i> Select the parameters for MDSS\n",
    "                </span>\n",
    "                <p style=\"font-size: 14px; margin-top: 10px;\">\n",
    "                    <b>MDSS requires the following parameters:</b>\n",
    "                </p>\n",
    "                <ul style=\"font-size: 14px; margin-top: 5px;\">\n",
    "                    <li><b>Scoring function:</b> The scoring function evaluates the quality of subsets by measuring how much the observed data deviates from the expected data under a null hypothesis.</li>\n",
    "                    <li><b>Number of iterations:</b> The number of iterations determines how many times the algorithm will run to find the optimal subset.</li>\n",
    "                    <li><b>Penalty:</b> The penalty parameter controls the trade-off between the size of the subset and the scoring function value, helping to prevent overfitting.</li>\n",
    "                </ul>\n",
    "            </div>\n",
    "            \"\"\"\n",
    "\n",
    "            from omegaconf import OmegaConf\n",
    "\n",
    "            # Load the config.yaml manually\n",
    "            config_path = \"configs/mdss.yaml\"\n",
    "            cfg = OmegaConf.load(config_path)\n",
    "\n",
    "            # Create HTML widgets to display the parameters\n",
    "            C_display = widgets.HTML(value=f\"<b>Scoring Function:</b> Bernoulli\")\n",
    "            penalty_display = widgets.HTML(value=f\"<b>Penalty:</b> {', '.join(map(str, cfg.parameters.penalty))}\")\n",
    "            iterations_display = widgets.HTML(value=f\"<b>Maximum number of iterations:</b> {', '.join(map(str, cfg.parameters.num_iters))}\")\n",
    "            \n",
    "            # Combine all parameter displays into a VBox\n",
    "            combined_box = widgets.VBox([widgets.HTML(value=mdss_info_message),widgets.HTML(value=\"<b>Algorithm Configuration Parameters:</b>\"),penalty_display,C_display,iterations_display])\n",
    "            \n",
    "            # # Create Dropdown for dataset selection\n",
    "            # scoring_function_selector = widgets.RadioButtons(\n",
    "            #     description='Scoring function:',\n",
    "            #     options=[\"Bernoulli\"],\n",
    "            #     style={'description_width': 'initial'},\n",
    "            #     layout=widgets.Layout(width='50%', margin='10px 0 0 10px')\n",
    "            # )\n",
    "            # scoring_function_selector.add_class('my-radio-style')\n",
    "\n",
    "            # # By default the selected algorithm is the first option\n",
    "            # selected_algorithm_parameters['scoring_function'] = scoring_function_selector.options[0]\n",
    "            # scoring_function_selector.observe(on_score_function_selector_change, names='value')\n",
    "            \n",
    "            # # Create IntText widgets for Penalty and Number of iterations\n",
    "            # penalty_widget = widgets.BoundedIntText(\n",
    "            #     value=1,\n",
    "            #     min=1,\n",
    "            #     description='Penalty:',\n",
    "            #     style={'description_width': 'initial'},\n",
    "            #     layout=widgets.Layout(width='30%', margin='10px 0 0 10px')\n",
    "            # )\n",
    "            # penalty_widget.add_class('my-int-text')\n",
    "            \n",
    "            # iterations_widget = widgets.BoundedIntText(\n",
    "            #     value=1,\n",
    "            #     min=1,\n",
    "            #     description='Number of iterations:',\n",
    "            #     style={'description_width': 'initial'},\n",
    "            #     layout=widgets.Layout(width='30%', margin='10px 0 0 10px')\n",
    "            # )\n",
    "            # iterations_widget.add_class('my-int-text')\n",
    "            \n",
    "            # # Store the default values in the selected_algorithm_parameters dictionary\n",
    "            # selected_algorithm_parameters['penalty'] = penalty_widget.value\n",
    "            # selected_algorithm_parameters['num_iterations'] = iterations_widget.value\n",
    "\n",
    "            # # Observe changes in the widgets\n",
    "            # penalty_widget.observe(lambda change: selected_algorithm_parameters.update({'penalty': change['new']}), names='value')\n",
    "            # iterations_widget.observe(lambda change: selected_algorithm_parameters.update({'num_iterations': change['new']}), names='value')\n",
    "\n",
    "            # Combine the info box, scoring function selector, and parameter input widgets\n",
    "            # combined_box = widgets.VBox([widgets.HTML(value=mdss_info_message), scoring_function_selector, penalty_widget, iterations_widget])\n",
    "        elif selected_algorithm == \"Bias Detection via Optimal Transport (Logistic Regression)\":\n",
    "            # Info message for scoring function selection\n",
    "            ot_info_message = \"\"\"\n",
    "            <div style=\"background-color: #f0f0f0; border: 1px solid #ccc; color: #333333; padding: 15px; border-radius: 5px; width: auto; margin: 10px auto; text-align: left;\">\n",
    "                <span style=\"font-weight: bold; color: #333333; font-size: 16px;\">\n",
    "                    <i class=\"fa fa-sliders\" style=\"margin-right: 10px;\"></i> Select the parameters for OT\n",
    "                </span>\n",
    "                <p style=\"font-size: 14px; margin-top: 10px;\">\n",
    "                    <b>OT requires the following parameters:</b>\n",
    "                </p>\n",
    "                <ul style=\"font-size: 14px; margin-top: 5px;\">\n",
    "                    <li><b>Penalty:</b> The penalty parameter controls the trade-off between the size of the subset and the scoring function value, helping to prevent overfitting.</li>\n",
    "                    <li><b>C:</b> The parameter <b>C</b> is a regularization parameter which controls the trade-off between achieving a low error on the training data and minimizing the complexity of the model.</li>\n",
    "                    <li><b>Maximum number of iterations:</b> The number of iterations determines how many times the algorithm will run to find the optimal subset.</li>\n",
    "                </ul>\n",
    "            </div>\n",
    "            \"\"\"\n",
    "            from omegaconf import OmegaConf\n",
    "\n",
    "            # Load the config.yaml manually\n",
    "            config_path = \"configs/config.yaml\"\n",
    "            cfg = OmegaConf.load(config_path)\n",
    "\n",
    "            # Create HTML widgets to display the parameters\n",
    "            penalty_display = widgets.HTML(value=f\"<b>Penalty:</b> {', '.join(cfg.parameters.penalty)}\")\n",
    "\n",
    "            C_display = widgets.HTML(value=f\"<b>C (Regularization):</b> {', '.join(map(str, cfg.parameters.c))}\")\n",
    "\n",
    "            iterations_display = widgets.HTML(value=f\"<b>Maximum number of iterations:</b> {', '.join(map(str, cfg.parameters.n_iter))}\")\n",
    "\n",
    "            # Combine all parameter displays into a VBox\n",
    "            combined_box = widgets.VBox([widgets.HTML(value=ot_info_message),widgets.HTML(value=\"<b>Algorithm Configuration Parameters:</b>\"),penalty_display,C_display,iterations_display])\n",
    "        elif selected_algorithm == \"Fairness Aware Counterfactuals for Subgroups (FACTS)\":\n",
    "            # Info message for scoring function selection\n",
    "            facts_info_message = \"\"\"\n",
    "            <div style=\"background-color: #f0f0f0; border: 1px solid #ccc; color: #333333; padding: 15px; border-radius: 5px; width: auto; margin: 10px auto; text-align: left;\">\n",
    "                <span style=\"font-weight: bold; color: #333333; font-size: 16px;\">\n",
    "                    <i class=\"fa fa-sliders\" style=\"margin-right: 10px;\"></i> Select the parameters for FACTS\n",
    "                </span>\n",
    "                <p style=\"font-size: 14px; margin-top: 10px;\">\n",
    "                    <b>FACTS requires the following parameters:</b>\n",
    "                </p>\n",
    "                <ul style=\"font-size: 14px; margin-top: 5px;\">\n",
    "                    <li><b>Maximum number of iterations:</b> The maximum number of iterations allowed for convergence of the solver of the demonstration ML model, here a simple logistic regression.</li>\n",
    "                    <li><b>Frequent Itemset Minimum Support:</b>All groups of individuals examined are constrained to cover at least this percentage of the whole population.</li>\n",
    "                    <li><b>Viewpoint:</b>One of two viewpoints defined for counterfactual actions by our framework. \"macro\" means that all individuals in a group must receive the same action, while \"micro\" means that each individual can choose, from a set of actions, the one that flips their class and has the minimum cost for the specific individual.</li>\n",
    "                    <li><b>Metric:</b> The fairness metric/definition to be used by the algorithm.</li>\n",
    "                    <li><b>Phi:</b> This is the parameter that determines whether we consider an action sufficiently effective or not.</li>\n",
    "                    <li><b>Top count:</b> The number of (most) biased groups to detect based on the given metric.</li>\n",
    "                    Specifically, an action is considered effective if it manages to flip the prediction of the individuals under study with at least <it>phi</it> probability, and ineffective otherwise.</li>\n",
    "                    <li><b>Features not allowed to change:</b> The features that are not allowed to be changed from the algorithm. By default none. You may select up to two.</li>\n",
    "                </ul>\n",
    "            </div>\n",
    "            \"\"\"\n",
    "            \n",
    "            iterations_widget = widgets.BoundedIntText(\n",
    "                value=1500,\n",
    "                min=1,\n",
    "                max=10000,\n",
    "                description='Maximum number of iterations:',\n",
    "                style={'description_width': 'initial'},\n",
    "                layout=widgets.Layout(width='30%', margin='10px 0 0 10px')\n",
    "            )\n",
    "            iterations_widget.add_class('my-int-text')\n",
    "            selected_algorithm_parameters['num_iterations'] = iterations_widget.value\n",
    "            # Observe changes in the widgets\n",
    "            iterations_widget.observe(lambda change: selected_algorithm_parameters.update({'num_iterations': change['new']}), names='value')\n",
    "\n",
    "            itemset_min_support_widget = widgets.BoundedFloatText(\n",
    "                value=0.1,\n",
    "                min=0,\n",
    "                description='Frequent Itemset Minimum Support:',\n",
    "                style={'description_width': 'initial'},\n",
    "                layout=widgets.Layout(width='30%', margin='10px 0 0 10px')\n",
    "            )\n",
    "            itemset_min_support_widget.add_class('my-int-text')\n",
    "            selected_algorithm_parameters['itemset_min_support'] = itemset_min_support_widget.value\n",
    "            # Observe changes in the widgets\n",
    "            itemset_min_support_widget.observe(lambda change: selected_algorithm_parameters.update({'itemset_min_support': change['new']}), names='value')\n",
    "\n",
    "            # Add viewpoint\n",
    "            viewpoint_selector = widgets.RadioButtons(\n",
    "                description='Viewpoint:',\n",
    "                value=\"macro\",\n",
    "                options=[\"micro\", \"macro\"],\n",
    "                style={'description_width': 'initial'},\n",
    "                layout=widgets.Layout(width='50%', margin='10px 0 0 10px')\n",
    "            )\n",
    "            viewpoint_selector.add_class('my-radio-style')\n",
    "            selected_algorithm_parameters['viewpoint'] = viewpoint_selector.value.lower()\n",
    "            viewpoint_selector.observe(on_viewpoint_selector_change, names='value')\n",
    "\n",
    "            metric_selector = widgets.RadioButtons(\n",
    "                description='Fairness metric:',\n",
    "                value=\"Equal choice for recourse\",\n",
    "                options=[\"Equal choice for recourse\", \n",
    "                         \"Equal effectiveness\", \n",
    "                         \"Equal effectiveness within budget\", \n",
    "                         \"Equal cost of effectiveness\",\n",
    "                         \"Equal mean recourse\",\n",
    "                         \"Fair tradeoff\",],\n",
    "                style={'description_width': 'initial'},\n",
    "                layout=widgets.Layout(width='50%', margin='10px 0 0 10px')\n",
    "            )\n",
    "            metric_selector.add_class('my-radio-style')\n",
    "            selected_algorithm_parameters['metric'] = metric_selector.value.lower().replace(' ','-')\n",
    "            metric_selector.observe(on_metric_selector_change, names='value')            \n",
    "            global phi_widget, c_widget\n",
    "            phi_widget = widgets.BoundedFloatText(\n",
    "                value=0.1,\n",
    "                min=0,\n",
    "                description='Phi:',\n",
    "                style={'description_width': 'initial'},\n",
    "                layout=widgets.Layout(width='30%', margin='10px 0 0 10px', display='block')\n",
    "            )\n",
    "            phi_widget.add_class('my-int-text')\n",
    "            selected_algorithm_parameters['phi'] = phi_widget.value\n",
    "\n",
    "            # Observe changes in the widgets\n",
    "            phi_widget.observe(lambda change: selected_algorithm_parameters.update({'phi': change['new']}), names='value')\n",
    "            \n",
    "            c_widget = widgets.BoundedIntText(\n",
    "                value=1,\n",
    "                min=1,\n",
    "                description='Cost budget (c):',\n",
    "                style={'description_width': 'initial'},\n",
    "                layout=widgets.Layout(width='30%', margin='10px 0 0 10px', display='none')  # Initially hidden\n",
    "            )\n",
    "            c_widget.add_class('my-int-text')\n",
    "            # selected_algorithm_parameters['c'] = c_widget.value\n",
    "            c_widget.observe(lambda change: selected_algorithm_parameters.update({'c': change['new']}), names='value')\n",
    "\n",
    "            features_not_to_change_selector = widgets.SelectMultiple(\n",
    "                description=\"Features not to change:\",\n",
    "                options=df.columns,\n",
    "                layout=widgets.Layout(width='30%', height='180px', margin='10px 0 0 10px'),\n",
    "                style={'description_width': 'initial'}\n",
    "            )\n",
    "\n",
    "            features_not_to_change_selector.add_class('my-select-multiple')\n",
    "            features_not_to_change_selector.observe(update_selected_not_to_change_features, names='value')\n",
    "            \n",
    "            top_count_widget = widgets.BoundedIntText(\n",
    "                value=3,\n",
    "                min=1,\n",
    "                description='Number of subgroups to show:',\n",
    "                style={'description_width': 'initial'},\n",
    "                layout=widgets.Layout(width='30%', margin='10px 0 0 10px')\n",
    "            )\n",
    "            top_count_widget.add_class('my-int-text')\n",
    "            selected_algorithm_parameters['top_count'] = top_count_widget.value\n",
    "            # Observe changes in the widgets\n",
    "            top_count_widget.observe(lambda change: selected_algorithm_parameters.update({'top_count': change['new']}), names='value')\n",
    "            \n",
    "            status_message = f'<div style=\"background-color: #f0f0f0; border: 1px solid #ccc; border-radius: 5px; padding: 10px; width: auto; margin: 10px auto; text-align: left;\">'\n",
    "            status_message += f'<span style=\"color: red; font-weight: bold;\">No selected not to change features.</span></div>'\n",
    "        \n",
    "            # Combine the info box, scoring function selector, and parameter input widgets\n",
    "            combined_box = widgets.VBox([widgets.HTML(value=facts_info_message), \n",
    "                                         iterations_widget,\n",
    "                                         itemset_min_support_widget,\n",
    "                                         viewpoint_selector,\n",
    "                                         metric_selector, \n",
    "                                         phi_widget,\n",
    "                                         c_widget,\n",
    "                                         top_count_widget,\n",
    "                                         features_not_to_change_selector,\n",
    "                                         not_to_change_features_status_output])\n",
    "            \n",
    "            with not_to_change_features_status_output:\n",
    "                not_to_change_features_status_output.clear_output(wait=True)\n",
    "                display(HTML(status_message))   \n",
    "        elif selected_algorithm == \"Fairness Aware Counterfactuals for Subgroups (FACTS)\":\n",
    "            facts_info_message = \"\"\"\n",
    "            <div style=\"background-color: #f0f0f0; border: 1px solid #ccc; color: #333333; padding: 15px; border-radius: 5px; width: auto; margin: 10px auto; text-align: left;\">\n",
    "                <span style=\"font-weight: bold; color: #333333; font-size: 16px;\">\n",
    "                    <i class=\"fa fa-sliders\" style=\"margin-right: 10px;\"></i> Select the parameters for FACTS\n",
    "                </span>\n",
    "                <p style=\"font-size: 14px; margin-top: 10px;\">\n",
    "                    <b>FACTS requires the following parameters:</b>\n",
    "                </p>\n",
    "                <ul style=\"font-size: 14px; margin-top: 5px;\">\n",
    "                    <li><b>Maximum number of iterations:</b> The maximum number of iterations allowed for convergence of the solver of the demonstration ML model, here a simple logistic regression.</li>\n",
    "                    <li><b>Frequent Itemset Minimum Support:</b>All groups of individuals examined are constrained to cover at least this percentage of the whole population.</li>\n",
    "                    <li><b>Viewpoint:</b>One of two viewpoints defined for counterfactual actions by our framework. \"macro\" means that all individuals in a group must receive the same action, while \"micro\" means that each individual can choose, from a set of actions, the one that flips their class and has the minimum cost for the specific individual.</li>\n",
    "                    <li><b>Metric:</b> The fairness metric/definition to be used by the algorithm.</li>\n",
    "                    <li><b>Phi:</b> This is the parameter that determines whether we consider an action sufficiently effective or not.</li>\n",
    "                    <li><b>Top count:</b> The number of (most) biased groups to detect based on the given metric.</li>\n",
    "                    Specifically, an action is considered effective if it manages to flip the prediction of the individuals under study with at least <it>phi</it> probability, and ineffective otherwise.</li>\n",
    "                    <li><b>Features not allowed to change:</b> The features that are not allowed to be changed from the algorithm. By default none. You may select up to two.</li>\n",
    "                </ul>\n",
    "            </div>\n",
    "            \"\"\"\n",
    "\n",
    "            \n",
    "        update_button_color(b)\n",
    "        clean_toolkit_content()\n",
    "        display(combined_box)\n",
    "\n",
    "\n",
    "def give_parameters(b):\n",
    "    global current_state, selected_algorithm_parameters\n",
    "    current_state = \"Parameters\"\n",
    "    \n",
    "    with global_output:\n",
    "        info_message = \"\"\"\n",
    "        <div style=\"background-color: #f0f0f0; border: 1px solid #ccc; color: #333333; padding: 15px; border-radius: 5px; width: auto; margin: 10px auto; text-align: left;\">\n",
    "            <span style=\"font-weight: bold; color: #333333; font-size: 16px;\">\n",
    "                <i class=\"fa fa-sliders\" style=\"margin-right: 10px;\"></i> Algorithm Parameters\n",
    "            </span>\n",
    "            <p style=\"font-size: 14px; margin-top: 10px;\">\n",
    "                Each algorithm requires a different set of configuration parameters. You are seeing the parameters associated with algorithm you chose in the 'Model' stage.\n",
    "            </p>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "\n",
    "        if selected_algorithm == \"Multi-Dimensional Subset Scan (MDSS)\":\n",
    "            # Info message for scoring function selection\n",
    "            mdss_info_message = \"\"\"\n",
    "            <div style=\"background-color: #f0f0f0; border: 1px solid #ccc; color: #333333; padding: 15px; border-radius: 5px; width: auto; margin: 10px auto; text-align: left;\">\n",
    "                <span style=\"font-weight: bold; color: #333333; font-size: 16px;\">\n",
    "                    <i class=\"fa fa-sliders\" style=\"margin-right: 10px;\"></i> Select the parameters for MDSS\n",
    "                </span>\n",
    "                <p style=\"font-size: 14px; margin-top: 10px;\">\n",
    "                    <b>MDSS requires the following parameters:</b>\n",
    "                </p>\n",
    "                <ul style=\"font-size: 14px; margin-top: 5px;\">\n",
    "                    <li><b>Scoring function:</b> The scoring function evaluates the quality of subsets by measuring how much the observed data deviates from the expected data under a null hypothesis.</li>\n",
    "                    <li><b>Number of iterations:</b> The number of iterations determines how many times the algorithm will run to find the optimal subset.</li>\n",
    "                    <li><b>Penalty:</b> The penalty parameter controls the trade-off between the size of the subset and the scoring function value, helping to prevent overfitting.</li>\n",
    "                </ul>\n",
    "            </div>\n",
    "            \"\"\"\n",
    "\n",
    "            from omegaconf import OmegaConf\n",
    "\n",
    "            # Load the config.yaml manually\n",
    "            config_path = \"configs/mdss.yaml\"\n",
    "            cfg = OmegaConf.load(config_path)\n",
    "\n",
    "            # Create HTML widgets to display the parameters\n",
    "            C_display = widgets.HTML(value=f\"<b>Scoring Function:</b> Bernoulli\")\n",
    "            penalty_display = widgets.HTML(value=f\"<b>Penalty:</b> {', '.join(map(str, cfg.parameters.penalty))}\")\n",
    "            iterations_display = widgets.HTML(value=f\"<b>Maximum number of iterations:</b> {', '.join(map(str, cfg.parameters.num_iters))}\")\n",
    "            \n",
    "            # Combine all parameter displays into a VBox\n",
    "            combined_box = widgets.VBox([widgets.HTML(value=mdss_info_message),widgets.HTML(value=\"<b>Algorithm Configuration Parameters:</b>\"),penalty_display,C_display,iterations_display])\n",
    "            \n",
    "            # # Create Dropdown for dataset selection\n",
    "            # scoring_function_selector = widgets.RadioButtons(\n",
    "            #     description='Scoring function:',\n",
    "            #     options=[\"Bernoulli\"],\n",
    "            #     style={'description_width': 'initial'},\n",
    "            #     layout=widgets.Layout(width='50%', margin='10px 0 0 10px')\n",
    "            # )\n",
    "            # scoring_function_selector.add_class('my-radio-style')\n",
    "\n",
    "            # # By default the selected algorithm is the first option\n",
    "            # selected_algorithm_parameters['scoring_function'] = scoring_function_selector.options[0]\n",
    "            # scoring_function_selector.observe(on_score_function_selector_change, names='value')\n",
    "            \n",
    "            # # Create IntText widgets for Penalty and Number of iterations\n",
    "            # penalty_widget = widgets.BoundedIntText(\n",
    "            #     value=1,\n",
    "            #     min=1,\n",
    "            #     description='Penalty:',\n",
    "            #     style={'description_width': 'initial'},\n",
    "            #     layout=widgets.Layout(width='30%', margin='10px 0 0 10px')\n",
    "            # )\n",
    "            # penalty_widget.add_class('my-int-text')\n",
    "            \n",
    "            # iterations_widget = widgets.BoundedIntText(\n",
    "            #     value=1,\n",
    "            #     min=1,\n",
    "            #     description='Number of iterations:',\n",
    "            #     style={'description_width': 'initial'},\n",
    "            #     layout=widgets.Layout(width='30%', margin='10px 0 0 10px')\n",
    "            # )\n",
    "            # iterations_widget.add_class('my-int-text')\n",
    "            \n",
    "            # # Store the default values in the selected_algorithm_parameters dictionary\n",
    "            # selected_algorithm_parameters['penalty'] = penalty_widget.value\n",
    "            # selected_algorithm_parameters['num_iterations'] = iterations_widget.value\n",
    "\n",
    "            # # Observe changes in the widgets\n",
    "            # penalty_widget.observe(lambda change: selected_algorithm_parameters.update({'penalty': change['new']}), names='value')\n",
    "            # iterations_widget.observe(lambda change: selected_algorithm_parameters.update({'num_iterations': change['new']}), names='value')\n",
    "\n",
    "            # Combine the info box, scoring function selector, and parameter input widgets\n",
    "            # combined_box = widgets.VBox([widgets.HTML(value=mdss_info_message), scoring_function_selector, penalty_widget, iterations_widget])\n",
    "        elif selected_algorithm == \"Bias Detection via Optimal Transport (Logistic Regression)\":\n",
    "            # Info message for scoring function selection\n",
    "            ot_info_message = \"\"\"\n",
    "            <div style=\"background-color: #f0f0f0; border: 1px solid #ccc; color: #333333; padding: 15px; border-radius: 5px; width: auto; margin: 10px auto; text-align: left;\">\n",
    "                <span style=\"font-weight: bold; color: #333333; font-size: 16px;\">\n",
    "                    <i class=\"fa fa-sliders\" style=\"margin-right: 10px;\"></i> Select the parameters for OT\n",
    "                </span>\n",
    "                <p style=\"font-size: 14px; margin-top: 10px;\">\n",
    "                    <b>OT requires the following parameters:</b>\n",
    "                </p>\n",
    "                <ul style=\"font-size: 14px; margin-top: 5px;\">\n",
    "                    <li><b>Penalty:</b> The penalty parameter controls the trade-off between the size of the subset and the scoring function value, helping to prevent overfitting.</li>\n",
    "                    <li><b>C:</b> The parameter <b>C</b> is a regularization parameter which controls the trade-off between achieving a low error on the training data and minimizing the complexity of the model.</li>\n",
    "                    <li><b>Maximum number of iterations:</b> The number of iterations determines how many times the algorithm will run to find the optimal subset.</li>\n",
    "                </ul>\n",
    "            </div>\n",
    "            \"\"\"\n",
    "            from omegaconf import OmegaConf\n",
    "\n",
    "            # Load the config.yaml manually\n",
    "            config_path = \"configs/config.yaml\"\n",
    "            cfg = OmegaConf.load(config_path)\n",
    "\n",
    "            # Create HTML widgets to display the parameters\n",
    "            penalty_display = widgets.HTML(value=f\"<b>Penalty:</b> {', '.join(cfg.parameters.penalty)}\")\n",
    "\n",
    "            C_display = widgets.HTML(value=f\"<b>C (Regularization):</b> {', '.join(map(str, cfg.parameters.c))}\")\n",
    "\n",
    "            iterations_display = widgets.HTML(value=f\"<b>Maximum number of iterations:</b> {', '.join(map(str, cfg.parameters.n_iter))}\")\n",
    "\n",
    "            # Combine all parameter displays into a VBox\n",
    "            combined_box = widgets.VBox([widgets.HTML(value=ot_info_message),widgets.HTML(value=\"<b>Algorithm Configuration Parameters:</b>\"),penalty_display,C_display,iterations_display])\n",
    "        elif selected_algorithm == \"Fairness Aware Counterfactuals for Subgroups (FACTS)\":\n",
    "            # Info message for scoring function selection\n",
    "            facts_info_message = \"\"\"\n",
    "            <div style=\"background-color: #f0f0f0; border: 1px solid #ccc; color: #333333; padding: 15px; border-radius: 5px; width: auto; margin: 10px auto; text-align: left;\">\n",
    "                <span style=\"font-weight: bold; color: #333333; font-size: 16px;\">\n",
    "                    <i class=\"fa fa-sliders\" style=\"margin-right: 10px;\"></i> Select the parameters for FACTS\n",
    "                </span>\n",
    "                <p style=\"font-size: 14px; margin-top: 10px;\">\n",
    "                    <b>FACTS requires the following parameters:</b>\n",
    "                </p>\n",
    "                <ul style=\"font-size: 14px; margin-top: 5px;\">\n",
    "                    <li><b>Maximum number of iterations:</b> The maximum number of iterations allowed for convergence of the solver of the demonstration ML model, here a simple logistic regression.</li>\n",
    "                    <li><b>Frequent Itemset Minimum Support:</b>All groups of individuals examined are constrained to cover at least this percentage of the whole population.</li>\n",
    "                    <li><b>Viewpoint:</b>One of two viewpoints defined for counterfactual actions by our framework. \"macro\" means that all individuals in a group must receive the same action, while \"micro\" means that each individual can choose, from a set of actions, the one that flips their class and has the minimum cost for the specific individual.</li>\n",
    "                    <li><b>Metric:</b> The fairness metric/definition to be used by the algorithm.</li>\n",
    "                    <li><b>Phi:</b> This is the parameter that determines whether we consider an action sufficiently effective or not.</li>\n",
    "                    <li><b>Top count:</b> The number of (most) biased groups to detect based on the given metric.</li>\n",
    "                    Specifically, an action is considered effective if it manages to flip the prediction of the individuals under study with at least <it>phi</it> probability, and ineffective otherwise.</li>\n",
    "                    <li><b>Features not allowed to change:</b> The features that are not allowed to be changed from the algorithm. By default none. You may select up to two.</li>\n",
    "                </ul>\n",
    "            </div>\n",
    "            \"\"\"\n",
    "            \n",
    "            iterations_widget = widgets.BoundedIntText(\n",
    "                value=1500,\n",
    "                min=1,\n",
    "                max=10000,\n",
    "                description='Maximum number of iterations:',\n",
    "                style={'description_width': 'initial'},\n",
    "                layout=widgets.Layout(width='30%', margin='10px 0 0 10px')\n",
    "            )\n",
    "            iterations_widget.add_class('my-int-text')\n",
    "            selected_algorithm_parameters['num_iterations'] = iterations_widget.value\n",
    "            # Observe changes in the widgets\n",
    "            iterations_widget.observe(lambda change: selected_algorithm_parameters.update({'num_iterations': change['new']}), names='value')\n",
    "\n",
    "            itemset_min_support_widget = widgets.BoundedFloatText(\n",
    "                value=0.1,\n",
    "                min=0,\n",
    "                description='Frequent Itemset Minimum Support:',\n",
    "                style={'description_width': 'initial'},\n",
    "                layout=widgets.Layout(width='30%', margin='10px 0 0 10px')\n",
    "            )\n",
    "            itemset_min_support_widget.add_class('my-int-text')\n",
    "            selected_algorithm_parameters['itemset_min_support'] = itemset_min_support_widget.value\n",
    "            # Observe changes in the widgets\n",
    "            itemset_min_support_widget.observe(lambda change: selected_algorithm_parameters.update({'itemset_min_support': change['new']}), names='value')\n",
    "\n",
    "            # Add viewpoint\n",
    "            viewpoint_selector = widgets.RadioButtons(\n",
    "                description='Viewpoint:',\n",
    "                value=\"macro\",\n",
    "                options=[\"micro\", \"macro\"],\n",
    "                style={'description_width': 'initial'},\n",
    "                layout=widgets.Layout(width='50%', margin='10px 0 0 10px')\n",
    "            )\n",
    "            viewpoint_selector.add_class('my-radio-style')\n",
    "            selected_algorithm_parameters['viewpoint'] = viewpoint_selector.value.lower()\n",
    "            viewpoint_selector.observe(on_viewpoint_selector_change, names='value')\n",
    "\n",
    "            metric_selector = widgets.RadioButtons(\n",
    "                description='Fairness metric:',\n",
    "                value=\"Equal choice for recourse\",\n",
    "                options=[\"Equal choice for recourse\", \n",
    "                         \"Equal effectiveness\", \n",
    "                         \"Equal effectiveness within budget\", \n",
    "                         \"Equal cost of effectiveness\",\n",
    "                         \"Equal mean recourse\",\n",
    "                         \"Fair tradeoff\",],\n",
    "                style={'description_width': 'initial'},\n",
    "                layout=widgets.Layout(width='50%', margin='10px 0 0 10px')\n",
    "            )\n",
    "            metric_selector.add_class('my-radio-style')\n",
    "            selected_algorithm_parameters['metric'] = metric_selector.value.lower().replace(' ','-')\n",
    "            metric_selector.observe(on_metric_selector_change, names='value')            \n",
    "            global phi_widget, c_widget\n",
    "            phi_widget = widgets.BoundedFloatText(\n",
    "                value=0.1,\n",
    "                min=0,\n",
    "                description='Phi:',\n",
    "                style={'description_width': 'initial'},\n",
    "                layout=widgets.Layout(width='30%', margin='10px 0 0 10px', display='block')\n",
    "            )\n",
    "            phi_widget.add_class('my-int-text')\n",
    "            selected_algorithm_parameters['phi'] = phi_widget.value\n",
    "\n",
    "            # Observe changes in the widgets\n",
    "            phi_widget.observe(lambda change: selected_algorithm_parameters.update({'phi': change['new']}), names='value')\n",
    "            \n",
    "            c_widget = widgets.BoundedIntText(\n",
    "                value=1,\n",
    "                min=1,\n",
    "                description='Cost budget (c):',\n",
    "                style={'description_width': 'initial'},\n",
    "                layout=widgets.Layout(width='30%', margin='10px 0 0 10px', display='none')  # Initially hidden\n",
    "            )\n",
    "            c_widget.add_class('my-int-text')\n",
    "            # selected_algorithm_parameters['c'] = c_widget.value\n",
    "            c_widget.observe(lambda change: selected_algorithm_parameters.update({'c': change['new']}), names='value')\n",
    "\n",
    "            features_not_to_change_selector = widgets.SelectMultiple(\n",
    "                description=\"Features not to change:\",\n",
    "                options=df.columns,\n",
    "                layout=widgets.Layout(width='30%', height='180px', margin='10px 0 0 10px'),\n",
    "                style={'description_width': 'initial'}\n",
    "            )\n",
    "\n",
    "            features_not_to_change_selector.add_class('my-select-multiple')\n",
    "            features_not_to_change_selector.observe(update_selected_not_to_change_features, names='value')\n",
    "            \n",
    "            top_count_widget = widgets.BoundedIntText(\n",
    "                value=3,\n",
    "                min=1,\n",
    "                description='Number of subgroups to show:',\n",
    "                style={'description_width': 'initial'},\n",
    "                layout=widgets.Layout(width='30%', margin='10px 0 0 10px')\n",
    "            )\n",
    "            top_count_widget.add_class('my-int-text')\n",
    "            selected_algorithm_parameters['top_count'] = top_count_widget.value\n",
    "            # Observe changes in the widgets\n",
    "            top_count_widget.observe(lambda change: selected_algorithm_parameters.update({'top_count': change['new']}), names='value')\n",
    "            \n",
    "            status_message = f'<div style=\"background-color: #f0f0f0; border: 1px solid #ccc; border-radius: 5px; padding: 10px; width: auto; margin: 10px auto; text-align: left;\">'\n",
    "            status_message += f'<span style=\"color: red; font-weight: bold;\">No selected not to change features.</span></div>'\n",
    "        \n",
    "            # Combine the info box, scoring function selector, and parameter input widgets\n",
    "            combined_box = widgets.VBox([widgets.HTML(value=facts_info_message), \n",
    "                                         iterations_widget,\n",
    "                                         itemset_min_support_widget,\n",
    "                                         viewpoint_selector,\n",
    "                                         metric_selector, \n",
    "                                         phi_widget,\n",
    "                                         c_widget,\n",
    "                                         top_count_widget,\n",
    "                                         features_not_to_change_selector,\n",
    "                                         not_to_change_features_status_output])\n",
    "            \n",
    "            with not_to_change_features_status_output:\n",
    "                not_to_change_features_status_output.clear_output(wait=True)\n",
    "                display(HTML(status_message))   \n",
    "                                \n",
    "        update_button_color(b)\n",
    "        clean_toolkit_content()\n",
    "        display(combined_box)\n",
    "\n",
    "\n",
    "selected_algorithms = []\n",
    "selected_algorithm_general = []\n",
    "selected_algorithm_pre = []\n",
    "selected_algorithm_post = []\n",
    "\n",
    "def create_checkbox_group(options, on_change_callback):\n",
    "    checkboxes = []\n",
    "    for option in options:\n",
    "        cb = widgets.Checkbox(value=False, description=option, layout=widgets.Layout(width='90%'))\n",
    "        cb.observe(on_change_callback, names='value')\n",
    "        checkboxes.append(cb)\n",
    "    return widgets.VBox(checkboxes)\n",
    "\n",
    "\n",
    "def update_selected_algorithms(change, group):\n",
    "    cb = change['owner']\n",
    "    if group == \"general\":\n",
    "        if cb.value and cb.description not in selected_algorithm_general:\n",
    "            selected_algorithm_general.append(cb.description)\n",
    "        elif not cb.value and cb.description in selected_algorithm_general:\n",
    "            selected_algorithm_general.remove(cb.description)\n",
    "    elif group == \"pre\":\n",
    "        if cb.value and cb.description not in selected_algorithm_pre:\n",
    "            selected_algorithm_pre.append(cb.description)\n",
    "        elif not cb.value and cb.description in selected_algorithm_pre:\n",
    "            selected_algorithm_pre.remove(cb.description)\n",
    "    elif group == \"post\":\n",
    "        if cb.value and cb.description not in selected_algorithm_post:\n",
    "            selected_algorithm_post.append(cb.description)\n",
    "        elif not cb.value and cb.description in selected_algorithm_post:\n",
    "            selected_algorithm_post.remove(cb.description)\n",
    "\n",
    "\n",
    "def give_model_to_detect_bias_updated_checkboxes(b):\n",
    "    global current_state\n",
    "    current_state = \"Model\"\n",
    "    with global_output:\n",
    "        update_button_color(b)\n",
    "        clean_toolkit_content()\n",
    "        info_message = \"\"\"\n",
    "        <div style=\"background-color: #f0f0f0; border: 1px solid #ccc; color: #333333; padding: 15px; border-radius: 5px; width: auto; margin: 10px auto; text-align: left;\">\n",
    "            <span style=\"font-weight: bold; color: #333333; font-size: 16px;\">\n",
    "                <i class=\"fa fa-cogs\" style=\"margin-right: 10px;\"></i> Algorithm Selection\n",
    "            </span>\n",
    "            <p style=\"font-size: 14px; margin-top: 10px;\">\n",
    "                Select the algorithm to be used for detecting bias in the provided dataset. \n",
    "                The chosen algorithm will analyze the data and identify any potential biases that may affect the model's performance and fairness.\n",
    "            </p>\n",
    "            <p style=\"font-size: 14px; font-weight: bold; color: red\">\n",
    "                Note that a dataset may only support a specific algorithm for bias detection. \n",
    "                For example, if you chose the dataset \"Ad Campaign\", you must select the MDSS algorithm.\n",
    "                You are only seeing the supported algorithms per dataset as options, as those defined next.\n",
    "            </p>\n",
    "            <span style=\"font-weight: bold; color: #333333; font-size: 16px;\">\n",
    "               Supported algorithms per dataset:\n",
    "            </span>\n",
    "            <span style=\"font-size: 14px;\">\n",
    "                <ul>\n",
    "                    <li>Ad Campaign: Multi-Dimensional Subset Scan (MDSS)</li>\n",
    "                    <li>Adult: Bias Detection via Optimal Transport, FACTS</li>\n",
    "                </ul>\n",
    "            </span>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "\n",
    "        # Dataset options with \"Learn more\" links\n",
    "        algorithm_options_per_dataset = {\n",
    "            'Ad Campaign': ['Multi-Dimensional Subset Scan (MDSS)'],\n",
    "            'Adult (Census Income)': ['Bias Detection via Optimal Transport (Logistic Regression)', 'Fairness Aware Counterfactuals for Subgroups (FACTS)']\n",
    "        }\n",
    "\n",
    "        algorithm_options_for_preprocessing = {\n",
    "            'Ad Campaign' : ['Reweighing Pre-processing technique (Reweighing)'],\n",
    "            'Adult (Census Income)' : ['Reweighing Pre-processing technique (Reweighing)']\n",
    "        }\n",
    "\n",
    "        algorithm_options_for_postprocessing = {\n",
    "            #'Ad Campaign' : ['Equalized Odds Post-processing technique (EqOddsPostprocessing)'],\n",
    "            #'Ad Campaign' : ['Calibrated Equalized Odds Post-processing technique (CalibratedEqOddsPostprocessing)'],\n",
    "            #'Ad Campaign' : ['Reject Option Classification Post-processing technique (RejectOptionClassification)'],\n",
    "            'Ad Campaign' : ['Equalized Odds Post-processing technique (EqOddsPostprocessing)','Calibrated Equalized Odds Post-processing technique (CalibratedEqOddsPostprocessing)','Reject Option Classification Post-processing technique (RejectOptionClassification)'],\n",
    "            'Adult (Census Income)' : ['Equalized Odds Post-processing technique (EqOddsPostprocessing)','Calibrated Equalized Odds Post-processing technique (CalibratedEqOddsPostprocessing)','Reject Option Classification Post-processing technique (RejectOptionClassification)']\n",
    "        }\n",
    "\n",
    "        \n",
    "        \n",
    "        algorithm_selector = create_checkbox_group(\n",
    "            algorithm_options_per_dataset[selected_dataset],\n",
    "            lambda change: update_selected_algorithms(change, group=\"general\")\n",
    "        )\n",
    "\n",
    "        algorithm_selector_multiple_preprocess = create_checkbox_group(\n",
    "            algorithm_options_for_preprocessing[selected_dataset],\n",
    "            lambda change: update_selected_algorithms(change, group=\"pre\")\n",
    "        )\n",
    "\n",
    "        algorithm_selector_multiple_postprocess = create_checkbox_group(\n",
    "            algorithm_options_for_postprocessing[selected_dataset],\n",
    "            lambda change: update_selected_algorithms(change, group=\"post\")\n",
    "        )\n",
    "        # algorithm_selector.add_class('my-radio-style')\n",
    "        # algorithm_selector_multiple_preprocess.add_class('my-radio-style')\n",
    "        # algorithm_selector_multiple_postprocess.add_class('my-radio-style')\n",
    "\n",
    "        \n",
    "        global selected_algorithms\n",
    "        # By default the selected algorithm is the first option\n",
    "        # selected_algorithm = algorithm_selector.options[0]\n",
    "        # selected_algorithmspre = algorithm_selector_multiple_preprocess.options[0]\n",
    "        # selected_algorithmspost = algorithm_selector_multiple_postprocess.options[0]        \n",
    "        # selected_algorithm = algorithm_selector.options[0]\n",
    "        # selected_algorithmspre = algorithm_selector_multiple_preprocess.options[0]\n",
    "        # selected_algorithmspost = algorithm_selector_multiple_postprocess.options[0]     \n",
    "        \n",
    "        algorithm_selector.observe(on_algorithm_selector_change, names='value')\n",
    "        algorithm_selector_multiple_preprocess.observe(on_algorithm_selector_change, names='value')\n",
    "        algorithm_selector_multiple_postprocess.observe(on_algorithm_selector_change, names='value')\n",
    "        \n",
    "        # Combine the info box and the custom dataset selector\n",
    "        #combined_box = widgets.VBox([widgets.HTML(value=info_message), algorithm_selector, algorithm_selector_multiple_preprocess,algorithm_selector_multiple_postprocess])\n",
    "\n",
    "        combined_box = widgets.VBox([widgets.HTML(value=info_message),\n",
    "                                     widgets.HTML(value=\"<h3 style='margin-top:20px;'>General Toolkit Algorithms</h3>\"),algorithm_selector,\n",
    "                                     widgets.HTML(value=\"<h3 style='margin-top:20px;'>Pre-processing Algorithms</h3>\"),algorithm_selector_multiple_preprocess,\n",
    "                                     widgets.HTML(value=\"<h3 style='margin-top:20px;'>Post-processing Algorithms</h3>\"),algorithm_selector_multiple_postprocess,])\n",
    "        \n",
    "        display(combined_box)\n",
    "\n",
    "\n",
    "\n",
    "def give_model_to_detect_bias_updated(b):\n",
    "    global current_state\n",
    "    current_state = \"Model\"\n",
    "    with global_output:\n",
    "        update_button_color(b)\n",
    "        clean_toolkit_content()\n",
    "        info_message = \"\"\"\n",
    "        <div style=\"background-color: #f0f0f0; border: 1px solid #ccc; color: #333333; padding: 15px; border-radius: 5px; width: auto; margin: 10px auto; text-align: left;\">\n",
    "            <span style=\"font-weight: bold; color: #333333; font-size: 16px;\">\n",
    "                <i class=\"fa fa-cogs\" style=\"margin-right: 10px;\"></i> Algorithm Selection\n",
    "            </span>\n",
    "            <p style=\"font-size: 14px; margin-top: 10px;\">\n",
    "                Select the algorithm to be used for detecting bias in the provided dataset. \n",
    "                The chosen algorithm will analyze the data and identify any potential biases that may affect the model's performance and fairness.\n",
    "            </p>\n",
    "            <p style=\"font-size: 14px; font-weight: bold; color: red\">\n",
    "                Note that a dataset may only support a specific algorithm for bias detection. \n",
    "                For example, if you chose the dataset \"Ad Campaign\", you must select the MDSS algorithm.\n",
    "                You are only seeing the supported algorithms per dataset as options, as those defined next.\n",
    "            </p>\n",
    "            <span style=\"font-weight: bold; color: #333333; font-size: 16px;\">\n",
    "               Supported algorithms per dataset:\n",
    "            </span>\n",
    "            <span style=\"font-size: 14px;\">\n",
    "                <ul>\n",
    "                    <li>Ad Campaign: Multi-Dimensional Subset Scan (MDSS)</li>\n",
    "                    <li>Adult: Bias Detection via Optimal Transport, FACTS</li>\n",
    "                </ul>\n",
    "            </span>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "\n",
    "        # Dataset options with \"Learn more\" links\n",
    "        algorithm_options_per_dataset = {\n",
    "            'Ad Campaign': ['Multi-Dimensional Subset Scan (MDSS)'],\n",
    "            'Adult (Census Income)': ['Bias Detection via Optimal Transport (Logistic Regression)', 'Fairness Aware Counterfactuals for Subgroups (FACTS)']\n",
    "        }\n",
    "\n",
    "        algorithm_options_for_preprocessing = {\n",
    "            'Ad Campaign' : ['Reweighing Pre-processing technique (Reweighing)'],\n",
    "            'Adult (Census Income)' : ['Reweighing Pre-processing technique (Reweighing)']\n",
    "        }\n",
    "\n",
    "        algorithm_options_for_postprocessing = {\n",
    "            #'Ad Campaign' : ['Equalized Odds Post-processing technique (EqOddsPostprocessing)'],\n",
    "            #'Ad Campaign' : ['Calibrated Equalized Odds Post-processing technique (CalibratedEqOddsPostprocessing)'],\n",
    "            #'Ad Campaign' : ['Reject Option Classification Post-processing technique (RejectOptionClassification)'],\n",
    "            'Ad Campaign' : ['Equalized Odds Post-processing technique (EqOddsPostprocessing)','Calibrated Equalized Odds Post-processing technique (CalibratedEqOddsPostprocessing)','Reject Option Classification Post-processing technique (RejectOptionClassification)'],\n",
    "            'Adult (Census Income)' : ['Equalized Odds Post-processing technique (EqOddsPostprocessing)','Calibrated Equalized Odds Post-processing technique (CalibratedEqOddsPostprocessing)','Reject Option Classification Post-processing technique (RejectOptionClassification)']\n",
    "        }\n",
    "\n",
    "        \n",
    "        \n",
    "        # Create Dropdown for dataset selection\n",
    "        algorithm_selector = widgets.RadioButtons(\n",
    "            options=[option for option in algorithm_options_per_dataset[selected_dataset]],\n",
    "            value = None,\n",
    "            style={'description_width': 'initial'},\n",
    "            layout=widgets.Layout(width='50%', margin='10px 0 0 10px')\n",
    "        )\n",
    "\n",
    "        algorithm_selector_multiple_preprocess = widgets.RadioButtons(\n",
    "            options=[option for option in algorithm_options_for_preprocessing[selected_dataset]],\n",
    "            value = None,\n",
    "            style={'description_width': 'initial'},\n",
    "            layout=widgets.Layout(width='50%', margin='10px 0 0 10px')\n",
    "        )\n",
    "\n",
    "        algorithm_selector_multiple_postprocess = widgets.RadioButtons(\n",
    "            options=[option for option in algorithm_options_for_postprocessing[selected_dataset]],\n",
    "            value = None,\n",
    "            style={'description_width': 'initial'},\n",
    "            layout=widgets.Layout(width='50%', margin='10px 0 0 10px')\n",
    "        )\n",
    "        \n",
    "        algorithm_selector.add_class('my-radio-style')\n",
    "        algorithm_selector_multiple_preprocess.add_class('my-radio-style')\n",
    "        algorithm_selector_multiple_postprocess.add_class('my-radio-style')\n",
    "\n",
    "        \n",
    "        global selected_algorithm\n",
    "        # By default the selected algorithm is the first option\n",
    "        selected_algorithm = algorithm_selector.options[0]\n",
    "        selected_algorithmspre = algorithm_selector_multiple_preprocess.options[0]\n",
    "        selected_algorithmspost = algorithm_selector_multiple_postprocess.options[0]        \n",
    "        # selected_algorithm = algorithm_selector.options[0]\n",
    "        # selected_algorithmspre = algorithm_selector_multiple_preprocess.options[0]\n",
    "        # selected_algorithmspost = algorithm_selector_multiple_postprocess.options[0]     \n",
    "        \n",
    "        algorithm_selector.observe(on_algorithm_selector_change, names='value')\n",
    "        algorithm_selector_multiple_preprocess.observe(on_algorithm_selector_change, names='value')\n",
    "        algorithm_selector_multiple_postprocess.observe(on_algorithm_selector_change, names='value')\n",
    "        \n",
    "        # Combine the info box and the custom dataset selector\n",
    "        #combined_box = widgets.VBox([widgets.HTML(value=info_message), algorithm_selector, algorithm_selector_multiple_preprocess,algorithm_selector_multiple_postprocess])\n",
    "\n",
    "        combined_box = widgets.VBox([widgets.HTML(value=info_message),\n",
    "                                     widgets.HTML(value=\"<h3 style='margin-top:20px;'>General Toolkit Algorithms</h3>\"),algorithm_selector,\n",
    "                                     widgets.HTML(value=\"<h3 style='margin-top:20px;'>Pre-processing Algorithms</h3>\"),algorithm_selector_multiple_preprocess,\n",
    "                                     widgets.HTML(value=\"<h3 style='margin-top:20px;'>Post-processing Algorithms</h3>\"),algorithm_selector_multiple_postprocess,])\n",
    "        \n",
    "        display(combined_box)\n",
    "\n",
    "\n",
    "def give_model_to_detect_bias(b):\n",
    "    global current_state\n",
    "    current_state = \"Model\"\n",
    "    with global_output:\n",
    "        update_button_color(b)\n",
    "        clean_toolkit_content()\n",
    "        info_message = \"\"\"\n",
    "        <div style=\"background-color: #f0f0f0; border: 1px solid #ccc; color: #333333; padding: 15px; border-radius: 5px; width: auto; margin: 10px auto; text-align: left;\">\n",
    "            <span style=\"font-weight: bold; color: #333333; font-size: 16px;\">\n",
    "                <i class=\"fa fa-cogs\" style=\"margin-right: 10px;\"></i> Algorithm Selection\n",
    "            </span>\n",
    "            <p style=\"font-size: 14px; margin-top: 10px;\">\n",
    "                Select the algorithm to be used for detecting bias in the provided dataset. \n",
    "                The chosen algorithm will analyze the data and identify any potential biases that may affect the model's performance and fairness.\n",
    "            </p>\n",
    "            <p style=\"font-size: 14px; font-weight: bold; color: red\">\n",
    "                Note that a dataset may only support a specific algorithm for bias detection. \n",
    "                For example, if you chose the dataset \"Ad Campaign\", you must select the MDSS algorithm.\n",
    "                You are only seeing the supported algorithms per dataset as options, as those defined next.\n",
    "            </p>\n",
    "            <span style=\"font-weight: bold; color: #333333; font-size: 16px;\">\n",
    "               Supported algorithms per dataset:\n",
    "            </span>\n",
    "            <span style=\"font-size: 14px;\">\n",
    "                <ul>\n",
    "                    <li>Ad Campaign: Multi-Dimensional Subset Scan (MDSS)</li>\n",
    "                    <li>Adult: Bias Detection via Optimal Transport, FACTS</li>\n",
    "                </ul>\n",
    "            </span>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "\n",
    "        # Dataset options with \"Learn more\" links\n",
    "        algorithm_options_per_dataset = {\n",
    "            'Ad Campaign': ['Multi-Dimensional Subset Scan (MDSS)'],\n",
    "            'Adult (Census Income)': ['Bias Detection via Optimal Transport (Logistic Regression)', 'Fairness Aware Counterfactuals for Subgroups (FACTS)']\n",
    "        }\n",
    "\n",
    "        \n",
    "        # Create Dropdown for dataset selection\n",
    "        algorithm_selector = widgets.RadioButtons(\n",
    "            options=[option for option in algorithm_options_per_dataset[selected_dataset]],\n",
    "            style={'description_width': 'initial'},\n",
    "            layout=widgets.Layout(width='50%', margin='10px 0 0 10px')\n",
    "        )\n",
    "        \n",
    "        algorithm_selector.add_class('my-radio-style')\n",
    "        global selected_algorithm\n",
    "        # By default the selected algorithm is the first option\n",
    "        selected_algorithm = algorithm_selector.options[0]\n",
    "        algorithm_selector.observe(on_algorithm_selector_change, names='value')\n",
    "\n",
    "        # Combine the info box and the custom dataset selector\n",
    "        combined_box = widgets.VBox([widgets.HTML(value=info_message), algorithm_selector])\n",
    "\n",
    "        display(combined_box)\n",
    "\n",
    "####################################################################\n",
    "\n",
    "def give_parameters_updated_and_extended_all_newer_integr(b):\n",
    "    global current_state, selected_algorithm_parameters, selected_algorithms\n",
    "    current_state = \"Parameters\"\n",
    "    selected_algorithm_parameters = {}\n",
    "\n",
    "    general_algorithms = [\n",
    "        \"Multi-Dimensional Subset Scan (MDSS)\",\n",
    "        \"Bias Detection via Optimal Transport (Logistic Regression)\",\n",
    "        \"Fairness Aware Counterfactuals for Subgroups (FACTS)\"\n",
    "    ]\n",
    "\n",
    "    preprocessing_algorithms = [\n",
    "        \"Reweighing Pre-processing technique (Reweighing)\"\n",
    "    ]\n",
    "\n",
    "    postprocessing_algorithms = [\n",
    "        \"Equalized Odds Post-processing technique (EqOddsPostprocessing)\",\n",
    "        \"Calibrated Equalized Odds Post-processing technique (CalibratedEqOddsPostprocessing)\",\n",
    "        \"Reject Option Classification Post-processing technique (RejectOptionClassification)\"\n",
    "    ]\n",
    "\n",
    "    # Create summary HTML widget placeholder\n",
    "    summary_widget = widgets.HTML()\n",
    "\n",
    "    def update_summary(_=None):\n",
    "        summary = \"<h4>Selected Algorithm Parameters Summary</h4><ul>\"\n",
    "        for alg in selected_algorithms:\n",
    "            summary += f\"<li><b>{alg}</b><ul>\"\n",
    "            params = selected_algorithm_parameters.get(alg, {})\n",
    "            for k, v in params.items():\n",
    "                summary += f\"<li>{k}: {v}</li>\"\n",
    "            summary += \"</ul></li>\"\n",
    "        summary += \"</ul>\"\n",
    "        summary_widget.value = summary\n",
    "\n",
    "    with global_output:\n",
    "        update_button_color(b)\n",
    "        clean_toolkit_content()\n",
    "\n",
    "        info_message = \"\"\"\n",
    "        <div style=\"background-color: #f0f0f0; border: 1px solid #ccc; color: #333333; padding: 15px; border-radius: 5px; width: auto; margin: 10px auto; text-align: left;\">\n",
    "            <span style=\"font-weight: bold; color: #333333; font-size: 16px;\">\n",
    "                <i class=\"fa fa-sliders\" style=\"margin-right: 10px;\"></i> Algorithm Parameters\n",
    "            </span>\n",
    "            <p style=\"font-size: 14px; margin-top: 10px;\">\n",
    "                You may review and optionally edit the configuration parameters of the selected algorithm(s). General algorithms can also be auto-tuned via FLAML.\n",
    "            </p>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "        display(widgets.HTML(value=info_message))\n",
    "\n",
    "        auto_tune_checkbox = widgets.Checkbox(\n",
    "            value=False,\n",
    "            layout=widgets.Layout(width='90%'),\n",
    "            description=\"Auto-Tune Parameters with FLAML\"\n",
    "        )\n",
    "        display(auto_tune_checkbox)\n",
    "\n",
    "        for algorithm in selected_algorithms:\n",
    "            display(widgets.HTML(value=f\"<h4>{algorithm}</h4>\"))\n",
    "\n",
    "            if algorithm in general_algorithms:\n",
    "                from sklearn.linear_model import LogisticRegression\n",
    "                from omegaconf import OmegaConf\n",
    "\n",
    "                model_class = None\n",
    "                init_args = {}\n",
    "                config_path = \"configs/config.yaml\"\n",
    "                cfg = OmegaConf.load(config_path)\n",
    "\n",
    "                if algorithm == \"Bias Detection via Optimal Transport (Logistic Regression)\":\n",
    "                    model_class = LogisticRegression\n",
    "                    init_args = {\n",
    "                        \"max_iter\": cfg.parameters.n_iter[0],\n",
    "                        \"C\": cfg.parameters.c[0],\n",
    "                        \"penalty\": cfg.parameters.penalty[0].lower().replace(\" \", \"_\")\n",
    "                    }\n",
    "\n",
    "                elif algorithm == \"Multi-Dimensional Subset Scan (MDSS)\":\n",
    "                    from aif360.algorithms.mdss import MDSS\n",
    "                    model_class = MDSS\n",
    "                    init_args = {\n",
    "                        \"scoring_function\": \"Bernoulli\",\n",
    "                        \"max_iters\": 50,\n",
    "                        \"penalty\": 1.0\n",
    "                    }\n",
    "\n",
    "                elif algorithm == \"Fairness Aware Counterfactuals for Subgroups (FACTS)\":\n",
    "                    from facts import FACTS\n",
    "                    model_class = FACTS\n",
    "                    init_args = {\n",
    "                        \"clf\": None,\n",
    "                        \"prot_attr\": \"gender\",\n",
    "                        \"freq_itemset_min_supp\": 0.1,\n",
    "                        \"feature_weights\": {},\n",
    "                        \"feats_not_allowed_to_change\": None\n",
    "                    }\n",
    "\n",
    "                model = model_class(**init_args)\n",
    "                param_widgets = {}\n",
    "                selected_algorithm_parameters[algorithm] = {}\n",
    "\n",
    "                if hasattr(model, \"get_params\"):\n",
    "                    for k, v in model.get_params().items():\n",
    "                        if isinstance(v, bool):\n",
    "                            w = widgets.Checkbox(value=v, description=k)\n",
    "                        elif isinstance(v, int):\n",
    "                            w = widgets.BoundedIntText(value=v, description=k, min=1, max=10000)\n",
    "                        elif isinstance(v, float):\n",
    "                            w = widgets.FloatText(value=v, description=k)\n",
    "                        else:\n",
    "                            w = widgets.Text(value=str(v), description=k)\n",
    "\n",
    "                        param_widgets[k] = w\n",
    "                        selected_algorithm_parameters[algorithm][k] = w.value\n",
    "\n",
    "                        w.observe(lambda change, k=k, alg=algorithm: (\n",
    "                            selected_algorithm_parameters[alg].update({k: change['new']}), update_summary()\n",
    "                        ), names='value')\n",
    "\n",
    "                    display(widgets.VBox(list(param_widgets.values())))\n",
    "\n",
    "                    if auto_tune_checkbox.value:\n",
    "                        display(widgets.HTML(value=\"<i>FLAML Auto-tuning will be applied during execution.</i>\"))\n",
    "\n",
    "            elif algorithm == \"Reweighing Pre-processing technique (Reweighing)\":\n",
    "                from aif360.algorithms.preprocessing import Reweighing\n",
    "                param_widgets = {\n",
    "                    \"unprivileged_groups\": widgets.Text(value=\"[{'job.experience_no'<= 2}]\", description=\"Unprivileged groups:\"),\n",
    "                    \"privileged_groups\": widgets.Text(value=\"[{'job.experience_no'> 2}]\", description=\"Privileged groups:\")\n",
    "                }\n",
    "                selected_algorithm_parameters[algorithm] = {}\n",
    "                for k, w in param_widgets.items():\n",
    "                    selected_algorithm_parameters[algorithm][k] = w.value\n",
    "                    w.observe(lambda change, k=k, alg=algorithm: (\n",
    "                        selected_algorithm_parameters[alg].update({k: change['new']}), update_summary()\n",
    "                    ), names='value')\n",
    "                    display(w)\n",
    "\n",
    "            elif algorithm == \"Equalized Odds Post-processing technique (EqOddsPostprocessing)\":\n",
    "                from aif360.algorithms.postprocessing import EqOddsPostprocessing\n",
    "                param_widgets = {\n",
    "                    \"protected_attr\": widgets.Text(value=\"job.experience_no\", description=\"Protected attribute:\"),\n",
    "                    \"label_attr\": widgets.Text(value=\"job.remote\", description=\"Label column:\"),\n",
    "                    \"score_attr\": widgets.Text(value=\"score\", description=\"Score column:\")\n",
    "                }\n",
    "                selected_algorithm_parameters[algorithm] = {}\n",
    "                for k, w in param_widgets.items():\n",
    "                    selected_algorithm_parameters[algorithm][k] = w.value\n",
    "                    w.observe(lambda change, k=k, alg=algorithm: (\n",
    "                        selected_algorithm_parameters[alg].update({k: change['new']}), update_summary()\n",
    "                    ), names='value')\n",
    "                    display(w)\n",
    "\n",
    "            elif algorithm == \"Calibrated Equalized Odds Post-processing technique (CalibratedEqOddsPostprocessing)\":\n",
    "                from aif360.algorithms.postprocessing import CalibratedEqOddsPostprocessing\n",
    "                param_widgets = {\n",
    "                    \"cost_constraint\": widgets.Dropdown(options=[\"fnr\", \"fpr\", \"weighted\"], value=\"weighted\", description=\"Cost Constraint:\"),\n",
    "                    \"unprivileged_groups\": widgets.Text(value=\"[{'job.experience_no' <= 2}]\", description=\"Unprivileged groups:\"),\n",
    "                    \"privileged_groups\": widgets.Text(value=\"[{'job.experience_no'> 2}]\", description=\"Privileged groups:\")\n",
    "                }\n",
    "                selected_algorithm_parameters[algorithm] = {}\n",
    "                for k, w in param_widgets.items():\n",
    "                    selected_algorithm_parameters[algorithm][k] = w.value\n",
    "                    w.observe(lambda change, k=k, alg=algorithm: (\n",
    "                        selected_algorithm_parameters[alg].update({k: change['new']}), update_summary()\n",
    "                    ), names='value')\n",
    "                    display(w)\n",
    "\n",
    "            elif algorithm == \"Reject Option Classification Post-processing technique (RejectOptionClassification)\":\n",
    "                from aif360.algorithms.postprocessing import RejectOptionClassification\n",
    "                param_widgets = {\n",
    "                    \"unprivileged_groups\": widgets.Text(value=\"[{'sex': 0}]\", description=\"Unprivileged groups:\"),\n",
    "                    \"privileged_groups\": widgets.Text(value=\"[{'sex': 1}]\", description=\"Privileged groups:\"),\n",
    "                    \"low_class_thresh\": widgets.FloatSlider(value=0.01, min=0, max=1, step=0.01, description=\"Low threshold:\"),\n",
    "                    \"high_class_thresh\": widgets.FloatSlider(value=0.99, min=0, max=1, step=0.01, description=\"High threshold:\")\n",
    "                }\n",
    "                selected_algorithm_parameters[algorithm] = {}\n",
    "                for k, w in param_widgets.items():\n",
    "                    selected_algorithm_parameters[algorithm][k] = w.value\n",
    "                    w.observe(lambda change, k=k, alg=algorithm: (\n",
    "                        selected_algorithm_parameters[alg].update({k: change['new']}), update_summary()\n",
    "                    ), names='value')\n",
    "                    display(w)\n",
    "\n",
    "            else:\n",
    "                display(widgets.HTML(\"<i>No parameters available for this algorithm.</i>\"))\n",
    "\n",
    "        # Initial summary render\n",
    "        update_summary()\n",
    "        display(summary_widget)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###################################################################\n",
    "def give_parameters_updated_and_extended_all_newer_integ(b):\n",
    "    global current_state, selected_algorithm_parameters, selected_algorithms\n",
    "    current_state = \"Parameters\"\n",
    "    selected_algorithm_parameters = {}\n",
    "\n",
    "    general_algorithms = [\n",
    "        \"Multi-Dimensional Subset Scan (MDSS)\",\n",
    "        \"Bias Detection via Optimal Transport (Logistic Regression)\",\n",
    "        \"Fairness Aware Counterfactuals for Subgroups (FACTS)\"\n",
    "    ]\n",
    "\n",
    "    preprocessing_algorithms = [\n",
    "        \"Reweighing Pre-processing technique (Reweighing)\"\n",
    "    ]\n",
    "\n",
    "    postprocessing_algorithms = [\n",
    "        \"Equalized Odds Post-processing technique (EqOddsPostprocessing)\",\n",
    "        \"Calibrated Equalized Odds Post-processing technique (CalibratedEqOddsPostprocessing)\",\n",
    "        \"Reject Option Classification Post-processing technique (RejectOptionClassification)\"\n",
    "    ]\n",
    "\n",
    "    with global_output:\n",
    "        update_button_color(b)\n",
    "        clean_toolkit_content()\n",
    "\n",
    "        info_message = \"\"\"\n",
    "        <div style=\"background-color: #f0f0f0; border: 1px solid #ccc; color: #333333; padding: 15px; border-radius: 5px; width: auto; margin: 10px auto; text-align: left;\">\n",
    "            <span style=\"font-weight: bold; color: #333333; font-size: 16px;\">\n",
    "                <i class=\"fa fa-sliders\" style=\"margin-right: 10px;\"></i> Algorithm Parameters\n",
    "            </span>\n",
    "            <p style=\"font-size: 14px; margin-top: 10px;\">\n",
    "                You may review and optionally edit the configuration parameters of the selected algorithm(s). General algorithms can also be auto-tuned via FLAML.\n",
    "            </p>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "        display(widgets.HTML(value=info_message))\n",
    "\n",
    "        auto_tune_checkbox = widgets.Checkbox(\n",
    "            value=False,\n",
    "            layout=widgets.Layout(width='90%'),\n",
    "            description=\"Auto-Tune Parameters with FLAML\"\n",
    "        )\n",
    "        display(auto_tune_checkbox)\n",
    "\n",
    "        for algorithm in selected_algorithms:\n",
    "            display(widgets.HTML(value=f\"<h4>{algorithm}</h4>\"))\n",
    "\n",
    "            if algorithm in general_algorithms:\n",
    "                from sklearn.linear_model import LogisticRegression\n",
    "                from omegaconf import OmegaConf\n",
    "\n",
    "                model_class = None\n",
    "                init_args = {}\n",
    "                config_path = \"configs/config.yaml\"\n",
    "                cfg = OmegaConf.load(config_path)\n",
    "\n",
    "                if algorithm == \"Bias Detection via Optimal Transport (Logistic Regression)\":\n",
    "                    model_class = LogisticRegression\n",
    "                    init_args = {\n",
    "                        \"max_iter\": cfg.parameters.n_iter[0],\n",
    "                        \"C\": cfg.parameters.c[0],\n",
    "                        \"penalty\": cfg.parameters.penalty[0].lower().replace(\" \", \"_\")\n",
    "                    }\n",
    "\n",
    "                elif algorithm == \"Multi-Dimensional Subset Scan (MDSS)\":\n",
    "                    from aif360.algorithms.mdss import MDSS\n",
    "                    model_class = MDSS\n",
    "                    init_args = {\n",
    "                        \"scoring_function\": \"Bernoulli\",\n",
    "                        \"max_iters\": 50,\n",
    "                        \"penalty\": 1.0\n",
    "                    }\n",
    "\n",
    "                elif algorithm == \"Fairness Aware Counterfactuals for Subgroups (FACTS)\":\n",
    "                    from facts import FACTS\n",
    "                    model_class = FACTS\n",
    "                    init_args = {\n",
    "                        \"clf\": None,\n",
    "                        \"prot_attr\": \"gender\",\n",
    "                        \"freq_itemset_min_supp\": 0.1,\n",
    "                        \"feature_weights\": {},\n",
    "                        \"feats_not_allowed_to_change\": None\n",
    "                    }\n",
    "\n",
    "                model = model_class(**init_args)\n",
    "                param_widgets = {}\n",
    "\n",
    "                if hasattr(model, \"get_params\"):\n",
    "                    for k, v in model.get_params().items():\n",
    "                        if isinstance(v, bool):\n",
    "                            w = widgets.Checkbox(value=v, description=k)\n",
    "                        elif isinstance(v, int):\n",
    "                            w = widgets.BoundedIntText(value=v, description=k, min=1, max=10000)\n",
    "                        elif isinstance(v, float):\n",
    "                            w = widgets.FloatText(value=v, description=k)\n",
    "                        else:\n",
    "                            w = widgets.Text(value=str(v), description=k)\n",
    "                        param_widgets[k] = w\n",
    "\n",
    "                    display(widgets.VBox(list(param_widgets.values())))\n",
    "\n",
    "                    if auto_tune_checkbox.value:\n",
    "                        display(widgets.HTML(value=\"<i>FLAML Auto-tuning will be applied during execution.</i>\"))\n",
    "\n",
    "                    def update_selected_algorithm_parameters(change):\n",
    "                        for k, widget in param_widgets.items():\n",
    "                            selected_algorithm_parameters[k] = widget.value\n",
    "\n",
    "                    for widget in param_widgets.values():\n",
    "                        widget.observe(update_selected_algorithm_parameters, names='value')\n",
    "\n",
    "            elif algorithm == \"Reweighing Pre-processing technique (Reweighing)\":\n",
    "                from aif360.algorithms.preprocessing import Reweighing\n",
    "                param_widgets = {\n",
    "                    \"unprivileged_groups\": widgets.Text(value=\"[{'sex': 0}]\", description=\"Unprivileged groups:\"),\n",
    "                    \"privileged_groups\": widgets.Text(value=\"[{'sex': 1}]\", description=\"Privileged groups:\")\n",
    "                }\n",
    "                for widget in param_widgets.values():\n",
    "                    display(widget)\n",
    "                selected_algorithm_parameters[algorithm] = {k: w.value for k, w in param_widgets.items()}\n",
    "                for k, w in param_widgets.items():\n",
    "                    w.observe(lambda change, k=k: selected_algorithm_parameters[algorithm].update({k: change['new']}), names='value')\n",
    "\n",
    "            elif algorithm == \"Equalized Odds Post-processing technique (EqOddsPostprocessing)\":\n",
    "                from aif360.algorithms.postprocessing import EqOddsPostprocessing\n",
    "                param_widgets = {\n",
    "                    \"protected_attr\": widgets.Text(value=\"sex\", description=\"Protected attribute:\"),\n",
    "                    \"label_attr\": widgets.Text(value=\"label\", description=\"Label column:\"),\n",
    "                    \"score_attr\": widgets.Text(value=\"score\", description=\"Score column:\")\n",
    "                }\n",
    "                for widget in param_widgets.values():\n",
    "                    display(widget)\n",
    "                selected_algorithm_parameters[algorithm] = {k: w.value for k, w in param_widgets.items()}\n",
    "                for k, w in param_widgets.items():\n",
    "                    w.observe(lambda change, k=k: selected_algorithm_parameters[algorithm].update({k: change['new']}), names='value')\n",
    "\n",
    "            elif algorithm == \"Calibrated Equalized Odds Post-processing technique (CalibratedEqOddsPostprocessing)\":\n",
    "                from aif360.algorithms.postprocessing import CalibratedEqOddsPostprocessing\n",
    "                param_widgets = {\n",
    "                    \"cost_constraint\": widgets.Dropdown(options=[\"fnr\", \"fpr\", \"weighted\"], value=\"weighted\", description=\"Cost Constraint:\"),\n",
    "                    \"unprivileged_groups\": widgets.Text(value=\"[{'sex': 0}]\", description=\"Unprivileged groups:\"),\n",
    "                    \"privileged_groups\": widgets.Text(value=\"[{'sex': 1}]\", description=\"Privileged groups:\")\n",
    "                }\n",
    "                for widget in param_widgets.values():\n",
    "                    display(widget)\n",
    "                selected_algorithm_parameters[algorithm] = {k: w.value for k, w in param_widgets.items()}\n",
    "                for k, w in param_widgets.items():\n",
    "                    w.observe(lambda change, k=k: selected_algorithm_parameters[algorithm].update({k: change['new']}), names='value')\n",
    "\n",
    "            elif algorithm == \"Reject Option Classification Post-processing technique (RejectOptionClassification)\":\n",
    "                from aif360.algorithms.postprocessing import RejectOptionClassification\n",
    "                param_widgets = {\n",
    "                    \"unprivileged_groups\": widgets.Text(value=\"[{'sex': 0}]\", description=\"Unprivileged groups:\"),\n",
    "                    \"privileged_groups\": widgets.Text(value=\"[{'sex': 1}]\", description=\"Privileged groups:\"),\n",
    "                    \"low_class_thresh\": widgets.FloatSlider(value=0.01, min=0, max=1, step=0.01, description=\"Low threshold:\"),\n",
    "                    \"high_class_thresh\": widgets.FloatSlider(value=0.99, min=0, max=1, step=0.01, description=\"High threshold:\")\n",
    "                }\n",
    "                for widget in param_widgets.values():\n",
    "                    display(widget)\n",
    "                selected_algorithm_parameters[algorithm] = {k: w.value for k, w in param_widgets.items()}\n",
    "                for k, w in param_widgets.items():\n",
    "                    w.observe(lambda change, k=k: selected_algorithm_parameters[algorithm].update({k: change['new']}), names='value')\n",
    "\n",
    "            else:\n",
    "                display(widgets.HTML(\"<i>No parameters available for this algorithm.</i>\"))\n",
    "\n",
    "                # Display selected algorithm(s) and their parameters summary\n",
    "        # Button to show final selected parameters\n",
    "        def print_selected_parameters(_=None):\n",
    "            summary = \"<h4>Selected Algorithm Parameters Summary</h4><ul>\"\n",
    "            for alg in selected_algorithms:\n",
    "                summary += f\"<li><b>{alg}</b><ul>\"\n",
    "\n",
    "                # Check if parameters are nested per algorithm\n",
    "                if alg in selected_algorithm_parameters:\n",
    "                    params = selected_algorithm_parameters[alg]\n",
    "                else:\n",
    "                    # Fallback for general algorithms (flat dict)\n",
    "                    params = selected_algorithm_parameters\n",
    "\n",
    "                for k, v in params.items():\n",
    "                    summary += f\"<li>{k}: {v}</li>\"\n",
    "                summary += \"</ul></li>\"\n",
    "            summary += \"</ul>\"\n",
    "            display(widgets.HTML(value=summary))\n",
    "\n",
    "        # Button widget\n",
    "        show_summary_button = widgets.Button(\n",
    "            description=\"Show Selected Parameters Summary\",\n",
    "            button_style='info',\n",
    "            layout=widgets.Layout(margin=\"20px 0px\")\n",
    "        )\n",
    "        show_summary_button.on_click(print_selected_parameters)\n",
    "        display(show_summary_button)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def give_parameters_updated_and_extended_all_newer_integrated(b):\n",
    "    global current_state, selected_algorithm_parameters, selected_algorithms\n",
    "    current_state = \"Parameters\"\n",
    "    selected_algorithm_parameters = {}\n",
    "\n",
    "    general_algorithms = [\n",
    "        \"Multi-Dimensional Subset Scan (MDSS)\",\n",
    "        \"Bias Detection via Optimal Transport (Logistic Regression)\",\n",
    "        \"Fairness Aware Counterfactuals for Subgroups (FACTS)\"\n",
    "    ]\n",
    "\n",
    "    preprocessing_algorithms = [\n",
    "        \"Reweighing Pre-processing technique (Reweighing)\"\n",
    "    ]\n",
    "\n",
    "    postprocessing_algorithms = [\n",
    "        \"Equalized Odds Post-processing technique (EqOddsPostprocessing)\",\n",
    "        \"Calibrated Equalized Odds Post-processing technique (CalibratedEqOddsPostprocessing)\",\n",
    "        \"Reject Option Classification Post-processing technique (RejectOptionClassification)\"\n",
    "    ]\n",
    "\n",
    "    with global_output:\n",
    "        update_button_color(b)\n",
    "        clean_toolkit_content()\n",
    "\n",
    "        info_message = \"\"\"\n",
    "        <div style=\"background-color: #f0f0f0; border: 1px solid #ccc; color: #333333; padding: 15px; border-radius: 5px; width: auto; margin: 10px auto; text-align: left;\">\n",
    "            <span style=\"font-weight: bold; color: #333333; font-size: 16px;\">\n",
    "                <i class=\"fa fa-sliders\" style=\"margin-right: 10px;\"></i> Algorithm Parameters\n",
    "            </span>\n",
    "            <p style=\"font-size: 14px; margin-top: 10px;\">\n",
    "                You may review and optionally edit the configuration parameters of the selected algorithm(s). General algorithms can also be auto-tuned via FLAML.\n",
    "            </p>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "        display(widgets.HTML(value=info_message))\n",
    "\n",
    "        auto_tune_checkbox = widgets.Checkbox(\n",
    "            value=False,\n",
    "            layout=widgets.Layout(width='90%'),\n",
    "            description=\"Auto-Tune Parameters with FLAML\"\n",
    "        )\n",
    "        display(auto_tune_checkbox)\n",
    "\n",
    "        for algorithm in selected_algorithms:\n",
    "            display(widgets.HTML(value=f\"<h4>{algorithm}</h4>\"))\n",
    "\n",
    "            if algorithm in general_algorithms:\n",
    "                from sklearn.linear_model import LogisticRegression\n",
    "                from omegaconf import OmegaConf\n",
    "\n",
    "                model_class = None\n",
    "                init_args = {}\n",
    "                config_path = \"configs/config.yaml\"\n",
    "                cfg = OmegaConf.load(config_path)\n",
    "\n",
    "                if algorithm == \"Bias Detection via Optimal Transport (Logistic Regression)\":\n",
    "                    model_class = LogisticRegression\n",
    "                    init_args = {\n",
    "                        \"max_iter\": cfg.parameters.n_iter[0],\n",
    "                        \"C\": cfg.parameters.c[0],\n",
    "                        \"penalty\": cfg.parameters.penalty[0].lower().replace(\" \", \"_\")\n",
    "                    }\n",
    "\n",
    "                elif algorithm == \"Multi-Dimensional Subset Scan (MDSS)\":\n",
    "                    from aif360.metrics import MDSSClassificationMetric\n",
    "                    from aif360.datasets import BinaryLabelDataset\n",
    "\n",
    "                    dataset = BinaryLabelDataset(...)  # Replace with actual\n",
    "                    classified_dataset = BinaryLabelDataset(...)  # Replace with actual\n",
    "\n",
    "                    model_class = MDSSClassificationMetric\n",
    "                    init_args = {\n",
    "                        \"dataset\": dataset,\n",
    "                        \"classified_dataset\": classified_dataset,\n",
    "                        \"scoring\": \"Bernoulli\",\n",
    "                        \"privileged_groups\": [{'protected_attribute': 1}],\n",
    "                        \"unprivileged_groups\": [{'protected_attribute': 0}]\n",
    "                    }\n",
    "\n",
    "                elif algorithm == \"Fairness Aware Counterfactuals for Subgroups (FACTS)\":\n",
    "                    from facts import FACTS\n",
    "                    model_class = FACTS\n",
    "                    init_args = {\n",
    "                        \"clf\": None,\n",
    "                        \"prot_attr\": \"gender\",\n",
    "                        \"freq_itemset_min_supp\": 0.1,\n",
    "                        \"feature_weights\": {},\n",
    "                        \"feats_not_allowed_to_change\": None\n",
    "                    }\n",
    "\n",
    "                model = model_class(**init_args)\n",
    "                param_widgets = {}\n",
    "\n",
    "                if hasattr(model, \"get_params\"):\n",
    "                    for k, v in model.get_params().items():\n",
    "                        if isinstance(v, bool):\n",
    "                            w = widgets.Checkbox(value=v, description=k)\n",
    "                        elif isinstance(v, int):\n",
    "                            w = widgets.BoundedIntText(value=v, description=k, min=1, max=10000)\n",
    "                        elif isinstance(v, float):\n",
    "                            w = widgets.FloatText(value=v, description=k)\n",
    "                        else:\n",
    "                            w = widgets.Text(value=str(v), description=k)\n",
    "                        param_widgets[k] = w\n",
    "\n",
    "                    display(widgets.VBox(list(param_widgets.values())))\n",
    "\n",
    "                    if auto_tune_checkbox.value:\n",
    "                        display(widgets.HTML(value=\"<i>FLAML Auto-tuning will be applied during execution.</i>\"))\n",
    "\n",
    "                    def update_selected_algorithm_parameters(change):\n",
    "                        for k, widget in param_widgets.items():\n",
    "                            selected_algorithm_parameters[k] = widget.value\n",
    "\n",
    "                    for widget in param_widgets.values():\n",
    "                        widget.observe(update_selected_algorithm_parameters, names='value')\n",
    "\n",
    "            elif algorithm in preprocessing_algorithms:\n",
    "                param_widgets = {\n",
    "                    \"reweighing_attr\": widgets.Text(value=\"sex\", description=\"Protected attribute:\"),\n",
    "                    \"reweighing_label\": widgets.Text(value=\"label\", description=\"Label column:\")\n",
    "                }\n",
    "                for widget in param_widgets.values():\n",
    "                    display(widget)\n",
    "                selected_algorithm_parameters[algorithm] = {k: w.value for k, w in param_widgets.items()}\n",
    "                for k, w in param_widgets.items():\n",
    "                    w.observe(lambda change, k=k: selected_algorithm_parameters[algorithm].update({k: change['new']}), names='value')\n",
    "\n",
    "            elif algorithm in postprocessing_algorithms:\n",
    "                param_widgets = {\n",
    "                    \"protected_attr\": widgets.Text(value=\"sex\", description=\"Protected attribute:\"),\n",
    "                    \"label_attr\": widgets.Text(value=\"label\", description=\"Label column:\"),\n",
    "                    \"score_attr\": widgets.Text(value=\"score\", description=\"Score column:\")\n",
    "                }\n",
    "                for widget in param_widgets.values():\n",
    "                    display(widget)\n",
    "                selected_algorithm_parameters[algorithm] = {k: w.value for k, w in param_widgets.items()}\n",
    "                for k, w in param_widgets.items():\n",
    "                    w.observe(lambda change, k=k: selected_algorithm_parameters[algorithm].update({k: change['new']}), names='value')\n",
    "\n",
    "            else:\n",
    "                display(widgets.HTML(\"<i>No parameters available for this algorithm.</i>\"))\n",
    "\n",
    "\n",
    "\n",
    "def give_parameters_updated_and_extended_all_newer(b):\n",
    "    global current_state, selected_algorithm_parameters, selected_algorithms\n",
    "    current_state = \"Parameters\"\n",
    "    selected_algorithm_parameters = {}\n",
    "\n",
    "    general_algorithms = [\n",
    "        \"Multi-Dimensional Subset Scan (MDSS)\",\n",
    "        \"Bias Detection via Optimal Transport (Logistic Regression)\",\n",
    "        \"Fairness Aware Counterfactuals for Subgroups (FACTS)\"\n",
    "    ]\n",
    "\n",
    "    preprocessing_algorithms = [\n",
    "        \"Reweighing Pre-processing technique (Reweighing)\"\n",
    "    ]\n",
    "\n",
    "    postprocessing_algorithms = [\n",
    "        \"Equalized Odds Post-processing technique (EqOddsPostprocessing)\",\n",
    "        \"Calibrated Equalized Odds Post-processing technique (CalibratedEqOddsPostprocessing)\",\n",
    "        \"Reject Option Classification Post-processing technique (RejectOptionClassification)\"\n",
    "    ]\n",
    "\n",
    "    with global_output:\n",
    "        update_button_color(b)\n",
    "        clean_toolkit_content()\n",
    "\n",
    "        info_message = \"\"\"\n",
    "        <div style=\"background-color: #f0f0f0; border: 1px solid #ccc; color: #333333; padding: 15px; border-radius: 5px; width: auto; margin: 10px auto; text-align: left;\">\n",
    "            <span style=\"font-weight: bold; color: #333333; font-size: 16px;\">\n",
    "                <i class=\"fa fa-sliders\" style=\"margin-right: 10px;\"></i> Algorithm Parameters\n",
    "            </span>\n",
    "            <p style=\"font-size: 14px; margin-top: 10px;\">\n",
    "                You may review and optionally edit the configuration parameters of the selected algorithm(s). General algorithms can also be auto-tuned via FLAML.\n",
    "            </p>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "        display(widgets.HTML(value=info_message))\n",
    "\n",
    "        auto_tune_checkbox = widgets.Checkbox(\n",
    "            value=False,\n",
    "            layout=widgets.Layout(width='90%'),\n",
    "            description=\"Auto-Tune Parameters with FLAML\"\n",
    "        )\n",
    "        display(auto_tune_checkbox)\n",
    "\n",
    "        for algorithm in selected_algorithms:\n",
    "            display(widgets.HTML(value=f\"<h4>{algorithm}</h4>\"))\n",
    "\n",
    "            # General algorithms with introspectable params\n",
    "            if algorithm in general_algorithms:\n",
    "                from sklearn.linear_model import LogisticRegression\n",
    "                from omegaconf import OmegaConf\n",
    "\n",
    "                model_class = None\n",
    "                init_args = {}\n",
    "                config_path = \"configs/config.yaml\"\n",
    "                cfg = OmegaConf.load(config_path)\n",
    "\n",
    "                if algorithm == \"Bias Detection via Optimal Transport (Logistic Regression)\":\n",
    "                    model_class = LogisticRegression\n",
    "                    init_args = {\n",
    "                        \"max_iter\": cfg.parameters.n_iter[0],\n",
    "                        \"C\": cfg.parameters.c[0],\n",
    "                        \"penalty\": cfg.parameters.penalty[0].lower().replace(\" \", \"_\")\n",
    "                    }\n",
    "\n",
    "                elif algorithm == \"Multi-Dimensional Subset Scan (MDSS)\":\n",
    "                    from aif360.metrics import MDSSClassificationMetric\n",
    "                    from aif360.datasets import BinaryLabelDataset\n",
    "\n",
    "                    # These must be set in your environment beforehand\n",
    "                    dataset = BinaryLabelDataset(...)  # your true-labeled dataset\n",
    "                    classified_dataset = BinaryLabelDataset(...)  # predictions\n",
    "\n",
    "                    model_class = MDSSClassificationMetric\n",
    "                    init_args = {\n",
    "                        \"dataset\": dataset,\n",
    "                        \"classified_dataset\": classified_dataset,\n",
    "                        \"scoring\": \"Bernoulli\",\n",
    "                        \"privileged_groups\": [{'protected_attribute': 1}],  # adjust accordingly\n",
    "                        \"unprivileged_groups\": [{'protected_attribute': 0}]\n",
    "                    }\n",
    "                elif algorithm == \"Fairness Aware Counterfactuals for Subgroups (FACTS)\":\n",
    "                    from facts import FACTS\n",
    "                    model_class = FACTS\n",
    "                    init_args = {\n",
    "                        \"clf\": None,\n",
    "                        \"prot_attr\": \"gender\",\n",
    "                        \"freq_itemset_min_supp\": 0.1,\n",
    "                        \"feature_weights\": {},\n",
    "                        \"feats_not_allowed_to_change\": None\n",
    "                    }\n",
    "\n",
    "                model = model_class(**init_args)\n",
    "                param_widgets = {}\n",
    "\n",
    "                if hasattr(model, \"get_params\"):\n",
    "                    for k, v in model.get_params().items():\n",
    "                        if isinstance(v, bool):\n",
    "                            w = widgets.Checkbox(value=v, description=k)\n",
    "                        elif isinstance(v, int):\n",
    "                            w = widgets.BoundedIntText(value=v, description=k, min=1, max=10000)\n",
    "                        elif isinstance(v, float):\n",
    "                            w = widgets.FloatText(value=v, description=k)\n",
    "                        else:\n",
    "                            w = widgets.Text(value=str(v), description=k)\n",
    "                        param_widgets[k] = w\n",
    "\n",
    "                    display(widgets.VBox(list(param_widgets.values())))\n",
    "\n",
    "                    if auto_tune_checkbox.value:\n",
    "                        display(widgets.HTML(value=\"<i>FLAML Auto-tuning will be applied during execution.</i>\"))\n",
    "\n",
    "                    def update_selected_algorithm_parameters(change):\n",
    "                        for k, widget in param_widgets.items():\n",
    "                            selected_algorithm_parameters[k] = widget.value\n",
    "\n",
    "                    for widget in param_widgets.values():\n",
    "                        widget.observe(update_selected_algorithm_parameters, names='value')\n",
    "\n",
    "            # Pre-processing algorithms\n",
    "            elif algorithm in preprocessing_algorithms:\n",
    "                # TODO: Replace below with dynamic inspection if your pipeline class is accessible\n",
    "                display(widgets.HTML(\"<b>Reweighing will be applied. Parameters can be configured in the preprocessing pipeline module.</b>\"))\n",
    "                \n",
    "            # Post-processing algorithms\n",
    "            elif algorithm in postprocessing_algorithms:\n",
    "                # TODO: Replace below with dynamic inspection if your pipeline class is accessible\n",
    "                display(widgets.HTML(\"<b>Post-processing (e.g., EqOdds, ROC) will be applied. Tune inside your pipeline or add FLAML tuning support.</b>\"))\n",
    "\n",
    "            else:\n",
    "                display(widgets.HTML(\"<i>No parameters available for this algorithm.</i>\"))\n",
    "\n",
    "\n",
    "def give_model_to_detect_bias_updated_checkboxes_new(b):\n",
    "    global current_state, selected_algorithms, selected_algorithm_general, selected_algorithm_pre, selected_algorithm_post\n",
    "    current_state = \"Model\"\n",
    "    selected_algorithms = []\n",
    "    selected_algorithm_general = []\n",
    "    selected_algorithm_pre = []\n",
    "    selected_algorithm_post = []\n",
    "\n",
    "    with global_output:\n",
    "        update_button_color(b)\n",
    "        clean_toolkit_content()\n",
    "\n",
    "        info_message = \"\"\"\n",
    "        <div style=\"background-color: #f0f0f0; border: 1px solid #ccc; color: #333333; padding: 15px; border-radius: 5px; width: auto; margin: 10px auto; text-align: left;\">\n",
    "            <span style=\"font-weight: bold; color: #333333; font-size: 16px;\">\n",
    "                <i class=\"fa fa-cogs\" style=\"margin-right: 10px;\"></i> Algorithm Selection\n",
    "            </span>\n",
    "            <p style=\"font-size: 14px; margin-top: 10px;\">\n",
    "                Select the algorithm to be used for detecting bias in the provided dataset. \n",
    "                The chosen algorithm will analyze the data and identify any potential biases that may affect the model's performance and fairness.\n",
    "            </p>\n",
    "            <p style=\"font-size: 14px; font-weight: bold; color: red\">\n",
    "                Note that a dataset may only support a specific algorithm for bias detection. \n",
    "                For example, if you chose the dataset \\\"Ad Campaign\\\", you must select the MDSS algorithm.\n",
    "                You are only seeing the supported algorithms per dataset as options, as those defined next.\n",
    "            </p>\n",
    "            <span style=\"font-weight: bold; color: #333333; font-size: 16px;\">\n",
    "               Supported algorithms per dataset:\n",
    "            </span>\n",
    "            <span style=\"font-size: 14px;\">\n",
    "                <ul>\n",
    "                    <li>Ad Campaign: Multi-Dimensional Subset Scan (MDSS)</li>\n",
    "                    <li>Adult: Bias Detection via Optimal Transport, FACTS</li>\n",
    "                    <li>Workable: Reweighing, EqOddsPostprocessing, CalibratedEqOddsPostprocessing,RejectOptionClassification, FACTS</li>\n",
    "                </ul>\n",
    "            </span>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "\n",
    "        algorithm_options_per_dataset = {\n",
    "            'Ad Campaign': ['Multi-Dimensional Subset Scan (MDSS)'],\n",
    "            'Adult (Census Income)': ['Bias Detection via Optimal Transport (Logistic Regression)', 'Fairness Aware Counterfactuals for Subgroups (FACTS)'],\n",
    "            'Workable': ['Bias Detection via Optimal Transport (Logistic Regression)','Fairness Aware Counterfactuals for Subgroups (FACTS)']\n",
    "        }\n",
    "\n",
    "        algorithm_options_for_preprocessing = {\n",
    "            'Ad Campaign': ['Reweighing Pre-processing technique (Reweighing)'],\n",
    "            'Adult (Census Income)': ['Reweighing Pre-processing technique (Reweighing)'],\n",
    "            'Workable' : ['Reweighing Pre-processing technique (Reweighing)']\n",
    "        }\n",
    "\n",
    "        algorithm_options_for_postprocessing = {\n",
    "            'Ad Campaign': [\n",
    "                'Equalized Odds Post-processing technique (EqOddsPostprocessing)',\n",
    "                'Calibrated Equalized Odds Post-processing technique (CalibratedEqOddsPostprocessing)',\n",
    "                'Reject Option Classification Post-processing technique (RejectOptionClassification)'\n",
    "            ],\n",
    "            'Adult (Census Income)': [\n",
    "                'Equalized Odds Post-processing technique (EqOddsPostprocessing)',\n",
    "                'Calibrated Equalized Odds Post-processing technique (CalibratedEqOddsPostprocessing)',\n",
    "                'Reject Option Classification Post-processing technique (RejectOptionClassification)'\n",
    "            ],\n",
    "            'Workable': [\n",
    "                'Equalized Odds Post-processing technique (EqOddsPostprocessing)',\n",
    "                'Calibrated Equalized Odds Post-processing technique (CalibratedEqOddsPostprocessing)',\n",
    "                'Reject Option Classification Post-processing technique (RejectOptionClassification)'\n",
    "            ]            \n",
    "        }\n",
    "\n",
    "        def create_checkbox_group(options, on_change):\n",
    "            checkboxes = []\n",
    "            for opt in options:\n",
    "                cb = widgets.Checkbox(value=False, description=opt, layout=widgets.Layout(width='auto'))\n",
    "                cb.observe(on_change, names='value')\n",
    "                checkboxes.append(cb)\n",
    "            return widgets.VBox(checkboxes)\n",
    "\n",
    "        def update_selected_algorithms(change, group):\n",
    "            selected_algorithms.clear()\n",
    "            selected_algorithm_general.clear()\n",
    "            selected_algorithm_pre.clear()\n",
    "            selected_algorithm_post.clear()\n",
    "            for cb in general_box.children:\n",
    "                if cb.value:\n",
    "                    selected_algorithms.append(cb.description)\n",
    "                    selected_algorithm_general.append(cb.description)\n",
    "            for cb in preprocess_box.children:\n",
    "                if cb.value:\n",
    "                    selected_algorithms.append(cb.description)\n",
    "                    selected_algorithm_pre.append(cb.description)\n",
    "            for cb in postprocess_box.children:\n",
    "                if cb.value:\n",
    "                    selected_algorithms.append(cb.description)\n",
    "                    selected_algorithm_post.append(cb.description)\n",
    "\n",
    "        general_box = create_checkbox_group(\n",
    "            algorithm_options_per_dataset[selected_dataset],\n",
    "            lambda change: update_selected_algorithms(change, group=\"general\")\n",
    "        )\n",
    "\n",
    "        preprocess_box = create_checkbox_group(\n",
    "            algorithm_options_for_preprocessing[selected_dataset],\n",
    "            lambda change: update_selected_algorithms(change, group=\"pre\")\n",
    "        )\n",
    "\n",
    "        postprocess_box = create_checkbox_group(\n",
    "            algorithm_options_for_postprocessing[selected_dataset],\n",
    "            lambda change: update_selected_algorithms(change, group=\"post\")\n",
    "        )\n",
    "\n",
    "        combined_box = widgets.VBox([\n",
    "            widgets.HTML(value=info_message),\n",
    "            widgets.HTML(value=\"<h3 style='margin-top:20px;'>General Toolkit Algorithms</h3>\"),\n",
    "            general_box,\n",
    "            widgets.HTML(value=\"<h3 style='margin-top:20px;'>Pre-processing Algorithms</h3>\"),\n",
    "            preprocess_box,\n",
    "            widgets.HTML(value=\"<h3 style='margin-top:20px;'>Post-processing Algorithms</h3>\"),\n",
    "            postprocess_box\n",
    "        ])\n",
    "\n",
    "        display(combined_box)\n",
    "\n",
    "\n",
    "\n",
    "def give_parameters_updated_and_extended_all(b):\n",
    "    global current_state, selected_algorithm_parameters, selected_algorithms\n",
    "    current_state = \"Parameters\"\n",
    "    selected_algorithm_parameters = {}\n",
    "\n",
    "    general_algorithms = [\n",
    "        \"Multi-Dimensional Subset Scan (MDSS)\",\n",
    "        \"Bias Detection via Optimal Transport (Logistic Regression)\",\n",
    "        \"Fairness Aware Counterfactuals for Subgroups (FACTS)\"\n",
    "    ]\n",
    "\n",
    "    preprocessing_algorithms = [\n",
    "        \"Reweighing Pre-processing technique (Reweighing)\"\n",
    "    ]\n",
    "\n",
    "    postprocessing_algorithms = [\n",
    "        \"Equalized Odds Post-processing technique (EqOddsPostprocessing)\",\n",
    "        \"Calibrated Equalized Odds Post-processing technique (CalibratedEqOddsPostprocessing)\",\n",
    "        \"Reject Option Classification Post-processing technique (RejectOptionClassification)\"\n",
    "    ]\n",
    "\n",
    "    with global_output:\n",
    "        update_button_color(b)\n",
    "        clean_toolkit_content()\n",
    "\n",
    "        # Info banner\n",
    "        info_message = \"\"\"\n",
    "        <div style=\\\"background-color: #f0f0f0; border: 1px solid #ccc; color: #333333; padding: 15px; border-radius: 5px; width: auto; margin: 10px auto; text-align: left;\\\">\n",
    "            <span style=\\\"font-weight: bold; color: #333333; font-size: 16px;\\\">\n",
    "                <i class=\\\"fa fa-sliders\\\" style=\\\"margin-right: 10px;\\\"></i> Algorithm Parameters\n",
    "            </span>\n",
    "            <p style=\\\"font-size: 14px; margin-top: 10px;\\\">\n",
    "                You may review and optionally edit the configuration parameters of the selected algorithm(s). If supported, you may enable Auto-Tuning using FLAML.\n",
    "            </p>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "        display(widgets.HTML(value=info_message))\n",
    "\n",
    "        auto_tune_checkbox = widgets.Checkbox(\n",
    "            value=False,\n",
    "            description=\"Auto-Tune Parameters with FLAML\"\n",
    "        )\n",
    "        display(auto_tune_checkbox)\n",
    "\n",
    "        for algorithm in selected_algorithms:\n",
    "            display(widgets.HTML(value=f\"<h4>{algorithm}</h4>\"))\n",
    "\n",
    "            if algorithm in general_algorithms:\n",
    "                from sklearn.linear_model import LogisticRegression\n",
    "                from omegaconf import OmegaConf\n",
    "\n",
    "                model_class = None\n",
    "                init_args = {}\n",
    "                config_path = \"configs/config.yaml\"\n",
    "                cfg = OmegaConf.load(config_path)\n",
    "\n",
    "                if algorithm == \"Bias Detection via Optimal Transport (Logistic Regression)\":\n",
    "                    model_class = LogisticRegression\n",
    "                    init_args = {\n",
    "                        \"max_iter\": cfg.parameters.n_iter[0],\n",
    "                        \"C\": cfg.parameters.c[0],\n",
    "                        \"penalty\": cfg.parameters.penalty[0].lower().replace(\" \", \"_\")\n",
    "                    }\n",
    "\n",
    "                elif algorithm == \"Multi-Dimensional Subset Scan (MDSS)\":\n",
    "                    from subset_scanning.scanners import MDSS\n",
    "                    from subset_scanning.scoring import Bernoulli\n",
    "                    model_class = MDSS\n",
    "                    init_args = {\n",
    "                        \"scoring_function\": Bernoulli(direction='negative')\n",
    "                    }\n",
    "\n",
    "                elif algorithm == \"Fairness Aware Counterfactuals for Subgroups (FACTS)\":\n",
    "                    from facts import FACTS\n",
    "                    model_class = FACTS\n",
    "                    init_args = {\n",
    "                        \"clf\": None,\n",
    "                        \"prot_attr\": \"gender\",\n",
    "                        \"freq_itemset_min_supp\": 0.1,\n",
    "                        \"feature_weights\": {},\n",
    "                        \"feats_not_allowed_to_change\": None\n",
    "                    }\n",
    "\n",
    "                model = model_class(**init_args)\n",
    "                param_widgets = {}\n",
    "                if hasattr(model, \"get_params\"):\n",
    "                    for k, v in model.get_params().items():\n",
    "                        if isinstance(v, bool):\n",
    "                            w = widgets.Checkbox(value=v, description=k)\n",
    "                        elif isinstance(v, int):\n",
    "                            w = widgets.BoundedIntText(value=v, description=k, min=1, max=10000)\n",
    "                        elif isinstance(v, float):\n",
    "                            w = widgets.FloatText(value=v, description=k)\n",
    "                        else:\n",
    "                            w = widgets.Text(value=str(v), description=k)\n",
    "                        param_widgets[k] = w\n",
    "                    display(widgets.VBox(list(param_widgets.values())))\n",
    "\n",
    "                    if auto_tune_checkbox.value:\n",
    "                        display(widgets.HTML(value=\"<i>FLAML Auto-tuning will be applied during execution.</i>\"))\n",
    "\n",
    "                def update_selected_algorithm_parameters(change):\n",
    "                    for k, widget in param_widgets.items():\n",
    "                        selected_algorithm_parameters[k] = widget.value\n",
    "\n",
    "                for widget in param_widgets.values():\n",
    "                    widget.observe(update_selected_algorithm_parameters, names='value')\n",
    "\n",
    "            elif algorithm in preprocessing_algorithms:\n",
    "                display(widgets.HTML(\"<b>Custom Pre-processing pipeline will be used for this algorithm.</b>\"))\n",
    "\n",
    "            elif algorithm in postprocessing_algorithms:\n",
    "                display(widgets.HTML(\"<b>Custom Post-processing pipeline will be used for this algorithm.</b>\"))\n",
    "\n",
    "            else:\n",
    "                display(widgets.HTML(\"<b>No parameters available for this algorithm.</b>\"))\n",
    "\n",
    "\n",
    "# CONFIG_PATH = os.path.join(os.getcwd(), \"configs\")\n",
    "\n",
    "# # # Hydra Decorator to Load Configurations\n",
    "# # @hydra.main(version_base=None, config_path=\"configs\", config_name=\"config\")\n",
    "# def load_hydra_config():\n",
    "#     hydra.initialize(config_path=CONFIG_PATH, version_base=None)\n",
    "#     cfg = hydra.compose(config_name=\"config\")\n",
    "#     return cfg\n",
    "\n",
    "# Directly load configuration using OmegaConf\n",
    "def load_hydra_config(config_path=\"configs/config.yaml\"):\n",
    "    \"\"\"\n",
    "    Load the configuration file using OmegaConf for use in a Voila-compatible notebook.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(config_path):\n",
    "        raise FileNotFoundError(f\"Configuration file '{config_path}' not found. Ensure it exists.\")\n",
    "    return OmegaConf.load(config_path)\n",
    "\n",
    "\n",
    "def get_best_configuration(metric_name=\"mean_ot_val\", maximize=True):\n",
    "    \"\"\"\n",
    "    Retrieve the best configuration from MLFlow based on a given metric.\n",
    "    \n",
    "    Args:\n",
    "        metric_name (str): Name of the metric to optimize.\n",
    "        maximize (bool): Whether to maximize or minimize the metric.\n",
    "    \n",
    "    Returns:\n",
    "        dict: The best configuration and its metric value.\n",
    "    \"\"\"\n",
    "    client = MlflowClient()\n",
    "    best_run = None\n",
    "    best_metric = float(\"-inf\") if maximize else float(\"inf\")\n",
    "\n",
    "    # Fetch all runs from the default experiment\n",
    "    experiment = client.get_experiment_by_name(\"Default\")\n",
    "    runs = client.search_runs(experiment_ids=[experiment.experiment_id])\n",
    "\n",
    "    # Iterate over runs to find the best configuration\n",
    "    for run in runs:\n",
    "        metrics = run.data.metrics\n",
    "        params = run.data.params\n",
    "        if metric_name in metrics:\n",
    "            current_metric = metrics[metric_name]\n",
    "            if (maximize and current_metric > best_metric) or (not maximize and current_metric < best_metric):\n",
    "                best_metric = current_metric\n",
    "                best_run = {\n",
    "                    \"metric\": best_metric,\n",
    "                    \"parameters\": params\n",
    "                }\n",
    "\n",
    "    return best_run\n",
    "\n",
    "############################################ updated version below\n",
    "\n",
    "\n",
    "\n",
    "def run_bias_detection_newer(b):\n",
    "    global global_output, current_state, selected_algorithm_parameters, selected_algorithms\n",
    "    current_state = \"Run\"\n",
    "    update_button_color(b)\n",
    "    clean_toolkit_content()\n",
    "\n",
    "    with global_output:\n",
    "        if df is None:\n",
    "            warning_msg = \"\"\"\n",
    "            <div>    \n",
    "                <div style=\"background-color: #f0f0f0; border: 1px solid #ccc; color: #333333; padding: 15px; border-radius: 5px; width: auto; margin: 10px auto; text-align: left;\">\n",
    "                <span style=\"font-weight: bold; color: red; font-size: 16px;\">Warning:</span> \n",
    "                <span style=\"font-size: 14px\">No dataset selected.</span>\n",
    "            </div>\"\"\"\n",
    "            display(HTML(warning_msg))\n",
    "            return\n",
    "\n",
    "        # Display algorithm/parameter summary\n",
    "        parameter_summary = \"\"\n",
    "        for alg in selected_algorithms:\n",
    "            param_dict = selected_algorithm_parameters.get(alg, {})\n",
    "            param_items = \"\".join([f\"<li><b>{k}:</b> {v}</li>\" for k, v in param_dict.items()])\n",
    "            parameter_summary += f\"\"\"\n",
    "                <li>\n",
    "                    <b>{alg}</b>\n",
    "                    <ul>{param_items}</ul>\n",
    "                </li>\n",
    "            \"\"\"\n",
    "\n",
    "        info_message_run = f\"\"\"\n",
    "        <div style=\"background-color: #f0f0f0; border: 1px solid #ccc; color: #333333; padding: 15px; border-radius: 5px; width: auto; margin: 10px auto; text-align: left;\">\n",
    "            <span style=\"font-weight: bold; color: #333333; font-size: 16px;\">\n",
    "                <i class=\"fa fa-play-circle\" style=\"margin-right: 10px;\"></i> Run Algorithm\n",
    "            </span>\n",
    "            <p style=\"font-size: 14px; margin-top: 10px;\">\n",
    "                We have run the following algorithm(s) on the selected dataset <b>{selected_dataset}</b>:\n",
    "            </p>\n",
    "            <ul style=\"font-size: 13px;\">\n",
    "                {parameter_summary}\n",
    "            </ul>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "        display(widgets.HTML(value=info_message_run))\n",
    "\n",
    "        # Dropdown for selecting best metric\n",
    "        metric_selector = widgets.Dropdown(\n",
    "            options=[\"FLAML Best Run\", \"Accuracy\", \"Conformal Coverage\"],\n",
    "            value=\"FLAML Best Run\",\n",
    "            description=\"Best by:\",\n",
    "            style={'description_width': 'initial'},\n",
    "            layout=widgets.Layout(width='50%')\n",
    "        )\n",
    "        display(metric_selector)\n",
    "\n",
    "        # Show loading bar\n",
    "        display(widgets.VBox([loading_bar]))\n",
    "        output_widget = widgets.Output()\n",
    "\n",
    "        def run_detection():\n",
    "            with output_widget:\n",
    "                if \"Multi-Dimensional Subset Scan (MDSS)\" in selected_algorithms:\n",
    "                    pass\n",
    "                    # config_path = \"configs/mdss.yaml\"\n",
    "                    # cfg = load_hydra_config(config_path)\n",
    "                    # scoring_function = Bernoulli(direction='negative')\n",
    "                    # scanner = MDSS(scoring_function)\n",
    "                    # mlflow.sklearn.autolog()\n",
    "                    # if mlflow.active_run():\n",
    "                    #     mlflow.end_run()\n",
    "                    # for n_iter in cfg.parameters.num_iters:\n",
    "                    #     for penalty in cfg.parameters.penalty:\n",
    "                    #         with mlflow.start_run(run_name=f\"n_iter={n_iter}_penalty={penalty}\"):\n",
    "                    #             try:\n",
    "                    #                 scanned_subset, _ = scanner.scan(\n",
    "                    #                     df[features_4_scanning],\n",
    "                    #                     expectations=df['predicted_conversion'],\n",
    "                    #                     outcomes=df['true_conversion'],\n",
    "                    #                     penalty=penalty,\n",
    "                    #                     num_iters=n_iter,\n",
    "                    #                     verbose=False\n",
    "                    #                 )\n",
    "                    #                 print(f\"Run complete: n_iter={n_iter}, penalty={penalty}\")\n",
    "                    #                 mlflow.log_param(\"num_iter\", n_iter)\n",
    "                    #                 mlflow.log_metric(\"penalty\", penalty)\n",
    "                    #                 print_report(df, scanned_subset)\n",
    "                    #             except Exception as e:\n",
    "                    #                 print(f\"Error for n_iter={n_iter}, penalty={penalty}: {e}\")\n",
    "                    #                 mlflow.log_param(\"error\", str(e))\n",
    "\n",
    "                elif \"Bias Detection via Optimal Transport (Logistic Regression)\" in selected_algorithms:\n",
    "                    pass\n",
    "                    # data_raw = load_preproc_data_adult()\n",
    "                    # data = data_raw.convert_to_dataframe()[0]\n",
    "                    # X = data.drop('Income Binary', axis=1)\n",
    "                    # y = data['Income Binary']\n",
    "                    # config_path = \"configs/config.yaml\"\n",
    "                    # cfg = load_hydra_config(config_path)\n",
    "                    # if mlflow.active_run():\n",
    "                    #     mlflow.end_run()\n",
    "                    # mlflow.autolog()\n",
    "                    # for n_iter in cfg.parameters.n_iter:\n",
    "                    #     for c in cfg.parameters.c:\n",
    "                    #         for penalty in cfg.parameters.penalty:\n",
    "                    #             with mlflow.start_run(run_name=f\"n_iter={n_iter}_c={c}_penalty={penalty}\"):\n",
    "                    #                 try:\n",
    "                    #                     penalty = penalty.lower().replace(' ', '_')\n",
    "                    #                     penalty_param = penalty if penalty != \"none\" else None\n",
    "                    #                     clf = LogisticRegression(\n",
    "                    #                         solver='lbfgs',\n",
    "                    #                         max_iter=n_iter,\n",
    "                    #                         C=c,\n",
    "                    #                         penalty=penalty_param\n",
    "                    #                     )\n",
    "                    #                     clf.fit(X, y)\n",
    "                    #                     preds = pd.Series(clf.predict_proba(X)[:, 0])\n",
    "                    #                     protected_attribute = features_4_scanning[0]\n",
    "                    #                     ot_val1 = ot_distance(y_true=y, y_pred=preds, prot_attr=data[protected_attribute])\n",
    "                    #                     bs1 = pd.DataFrame({protected_attribute: ot_val1.keys(), \"ot_val\": ot_val1.values()})\n",
    "                    #                     display(bs1)\n",
    "                    #                     mlflow.log_param(\"n_iter\", n_iter)\n",
    "                    #                     mlflow.log_param(\"C\", c)\n",
    "                    #                     mlflow.log_param(\"penalty\", penalty)\n",
    "                    #                     mlflow.log_metric(\"mean_ot_val\", bs1[\"ot_val\"].mean())\n",
    "                    #                     print(f\"Run complete: n_iter={n_iter}, C={c}, penalty={penalty}\")\n",
    "                    #                 except Exception as e:\n",
    "                    #                     print(f\"Error for n_iter={n_iter}, C={c}, penalty={penalty}: {e}\")\n",
    "                    #                     mlflow.log_param(\"error\", str(e))\n",
    "                    # best_run = get_best_configuration(metric_name=\"mean_ot_val\", maximize=False)\n",
    "                    # parameters = best_run[\"parameters\"]\n",
    "                    # metric = best_run[\"metric\"]\n",
    "                    # ot_best = widgets.VBox([\n",
    "                    #     widgets.HTML(\"<br><b><h2>Best Configuration Identified</h2></b>\"),\n",
    "                    #     widgets.HTML(f\"<b>Metric (mean_ot_val):</b> {metric:.6f}\"),\n",
    "                    #     widgets.HTML(\"<b>Best Parameters:</b>\"),\n",
    "                    #     widgets.HTML(\"<ul>\" + \"\".join([f\"<li>{key}: {value}</li>\" for key, value in parameters.items()]) + \"</ul>\")\n",
    "                    # ])\n",
    "                    # display(ot_best)\n",
    "\n",
    "                elif \"Fairness Aware Counterfactuals for Subgroups (FACTS)\" in selected_algorithms:\n",
    "                    data = clean_dataset(X_adult.assign(income=y_adult), \"adult\")\n",
    "                    y = data['income']\n",
    "                    X = data.drop('income', axis=1)\n",
    "                    mlflow.sklearn.autolog()\n",
    "                    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=random_seed, stratify=y)\n",
    "                    categorical_features = X.select_dtypes(include=[\"object\", \"category\"]).columns.to_list()\n",
    "                    categorical_transformer = ColumnTransformer(\n",
    "                        transformers=[(\"one-hot-encoder\", OneHotEncoder(), categorical_features)],\n",
    "                        remainder=\"passthrough\"\n",
    "                    )\n",
    "                    n_iters = selected_algorithm_parameters['num_iterations']\n",
    "                    model = Pipeline([\n",
    "                        (\"one-hot-encoder\", categorical_transformer),\n",
    "                        (\"clf\", LogisticRegression(max_iter=n_iters))\n",
    "                    ])\n",
    "                    model.fit(X_train, y_train)\n",
    "                    metric = selected_algorithm_parameters['metric']\n",
    "                    top_count = selected_algorithm_parameters['top_count']\n",
    "                    viewpoint = selected_algorithm_parameters['viewpoint']\n",
    "                    phi = selected_algorithm_parameters.get('phi', 0.5)\n",
    "                    c = selected_algorithm_parameters.get('c', 0.5)\n",
    "                    freq_itemset_min_supp = selected_algorithm_parameters['itemset_min_support']\n",
    "                    protected_attribute = features_4_scanning[0]\n",
    "                    detector = FACTS(\n",
    "                        clf=model,\n",
    "                        prot_attr=protected_attribute,\n",
    "                        freq_itemset_min_supp=freq_itemset_min_supp,\n",
    "                        feature_weights={f: 1 for f in X.columns},\n",
    "                        feats_not_allowed_to_change=not_to_change_features,\n",
    "                    )\n",
    "                    detector.fit(X_test, verbose=False)\n",
    "                    filter_seq = [\"remove-fair-rules\"]\n",
    "                    if metric == \"equal-effectiveness-within-budget\":\n",
    "                        filter_seq.append(\"remove-above-thr-cost\")\n",
    "                    if metric in [\"equal-choice-for-recourse\", \"equal-cost-of-effectiveness\"] and viewpoint == \"macro\":\n",
    "                        filter_seq.append(\"remove-below-thr-corr\")\n",
    "                    if metric == \"equal-cost-of-effectiveness\" and viewpoint == \"micro\":\n",
    "                        filter_seq.append(\"keep-rules-until-thr-corr-reached\")\n",
    "                    detector.bias_scan(\n",
    "                        metric=metric,\n",
    "                        viewpoint=viewpoint,\n",
    "                        sort_strategy=\"max-cost-diff-decr\",\n",
    "                        top_count=top_count,\n",
    "                        filter_sequence=filter_seq,\n",
    "                        phi=phi,\n",
    "                        c=c,\n",
    "                    )\n",
    "                    correctness_metric = metric in [\"equal-effectiveness\", \"equal-effectiveness-within-budget\"]\n",
    "                    detector.print_recourse_report(\n",
    "                        show_subgroup_costs=True,\n",
    "                        show_action_costs=True,\n",
    "                        correctness_metric=correctness_metric,\n",
    "                    )\n",
    "\n",
    "                else:\n",
    "                    # Fallback to AutoML pipeline\n",
    "                    selected_metric = metric_selector.value\n",
    "                    df_results = run_automl_pipeline(\n",
    "                        search_algo=\"tpe\",\n",
    "                        selected_algorithms=selected_algorithms,\n",
    "                        selected_algorithm_parameters=selected_algorithm_parameters\n",
    "                    )\n",
    "                    if not df_results.empty and selected_metric in df_results.columns:\n",
    "                        best_run = df_results.loc[df_results[selected_metric].idxmax()]\n",
    "                        metric_value = best_run[selected_metric]\n",
    "                        parameters = {\n",
    "                            \"Preprocessing\": best_run[\"Preprocessing\"],\n",
    "                            \"Postprocessing\": best_run[\"Postprocessing\"],\n",
    "                            \"Accuracy\": best_run.get(\"Accuracy\", \"N/A\"),\n",
    "                            \"Conformal Coverage\": best_run.get(\"Conformal Coverage\", \"N/A\")\n",
    "                        }\n",
    "                        ot_best = widgets.VBox([\n",
    "                            widgets.HTML(\"<br><b><h2>Best Configuration Identified</h2></b>\"),\n",
    "                            widgets.HTML(f\"<b>Metric ({selected_metric}):</b> {metric_value:.6f}\"),\n",
    "                            widgets.HTML(\"<b>Best Parameters:</b>\"),\n",
    "                            widgets.HTML(\"<ul>\" + \"\".join([f\"<li>{key}: {value}</li>\" for key, value in parameters.items()]) + \"</ul>\")\n",
    "                        ])\n",
    "                        display(ot_best)\n",
    "                    else:\n",
    "                        display(widgets.HTML(f\"<b>No valid configuration found or metric '{selected_metric}' missing.</b>\"))\n",
    "\n",
    "        run_detection()\n",
    "        clean_toolkit_content()\n",
    "        display(output_widget)\n",
    "\n",
    "\n",
    "##################################################################################################################\n",
    "\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "import ipywidgets as widgets\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "def build_fairness_logs_from_mlflow_df_old(df_results):\n",
    "    \"\"\"\n",
    "    Extract fairness metrics from a DataFrame returned by `run_automl_pipelinev2`.\n",
    "\n",
    "    Returns:\n",
    "        dict: { \"Preprocessing+Postprocessing\": {metric: {\"Preprocessed\": val, \"Postprocessed\": val}} }\n",
    "    \"\"\"\n",
    "    fairness_logs = {}\n",
    "\n",
    "    for _, row in df_results.iterrows():\n",
    "        combo_key = f\"{row['Preprocessing']}+{row['Postprocessing']}\"\n",
    "        fairness_logs[combo_key] = {}\n",
    "\n",
    "        metrics = [\"SPD\", \"DI\", \"EOD\", \"AOD\", \"Theil\"]\n",
    "        for metric in metrics:\n",
    "            pre_val = row.get(f\"preprocessed_{metric}\", None)\n",
    "            post_val = row.get(f\"postprocessed_{metric}\", None)\n",
    "            if pre_val is not None or post_val is not None:\n",
    "                fairness_logs[combo_key][metric] = {\n",
    "                    \"Preprocessed\": pre_val,\n",
    "                    \"Postprocessed\": post_val\n",
    "                }\n",
    "\n",
    "    return fairness_logs\n",
    "\n",
    "\n",
    "def build_fairness_logs_from_best_run(best_run):\n",
    "    \"\"\"\n",
    "    Build fairness metrics logs from the best run for plotting.\n",
    "\n",
    "    Returns:\n",
    "        dict: { \"Preprocessing+Postprocessing\": {metric: {\"Preprocessed\": val, \"Postprocessed\": val}} }\n",
    "    \"\"\"\n",
    "    fairness_logs = {}\n",
    "    combo_key = f\"{best_run['Preprocessing']}+{best_run['Postprocessing']}\"\n",
    "    fairness_logs[combo_key] = {}\n",
    "\n",
    "    metrics = [\"SPD\", \"DI\", \"EOD\", \"AOD\", \"Theil\"]\n",
    "    for metric in metrics:\n",
    "        pre_val = best_run.get(f\"{metric} (Pre)\")\n",
    "        post_val = best_run.get(f\"{metric} (Post)\")\n",
    "        if pre_val is not None or post_val is not None:\n",
    "            fairness_logs[combo_key][metric] = {\n",
    "                \"Preprocessed\": pre_val,\n",
    "                \"Postprocessed\": post_val\n",
    "            }\n",
    "\n",
    "    return fairness_logs\n",
    "\n",
    "\n",
    "def build_fairness_logs_from_mlflow_df(df_results):\n",
    "    \"\"\"\n",
    "    Extract fairness metrics from df_results using explicitly labeled columns like 'SPD (Pre)' and 'SPD (Post)'.\n",
    "\n",
    "    Returns:\n",
    "        dict: { \"Preprocessing+Postprocessing\": {metric: {\"Preprocessed\": val, \"Postprocessed\": val}} }\n",
    "    \"\"\"\n",
    "    fairness_logs = {}\n",
    "\n",
    "    for _, row in df_results.iterrows():\n",
    "        combo_key = f\"{row['Preprocessing']}+{row['Postprocessing']}\"\n",
    "        fairness_logs[combo_key] = {}\n",
    "\n",
    "        metrics = [\"SPD\", \"DI\", \"EOD\", \"AOD\", \"Theil\"]\n",
    "        for metric in metrics:\n",
    "            pre_val = row.get(f\"{metric} (Pre)\", None)\n",
    "            post_val = row.get(f\"{metric} (Post)\", None)\n",
    "            if pre_val is not None or post_val is not None:\n",
    "                fairness_logs[combo_key][metric] = {\n",
    "                    \"Preprocessed\": pre_val,\n",
    "                    \"Postprocessed\": post_val\n",
    "                }\n",
    "\n",
    "    return fairness_logs\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "\n",
    "def plot_fairness_metrics_comparison(fairness_logs):\n",
    "    \"\"\"\n",
    "    Plot bar charts for preprocessed vs postprocessed fairness metrics,\n",
    "    with dynamic scaling and clearer visualization.\n",
    "    \"\"\"\n",
    "    for combo_key, metric_dict in fairness_logs.items():\n",
    "        if not metric_dict:\n",
    "            continue\n",
    "\n",
    "        num_metrics = len(metric_dict)\n",
    "        fig, axes = plt.subplots(num_metrics, 1, figsize=(10, 5 * num_metrics))\n",
    "\n",
    "        if num_metrics == 1:\n",
    "            axes = [axes]\n",
    "\n",
    "        for ax, (metric, stages) in zip(axes, metric_dict.items()):\n",
    "            labels = list(stages.keys())  # e.g., ['Preprocessed', 'Postprocessed']\n",
    "            values = list(stages.values())\n",
    "\n",
    "            ax.bar(labels, values)\n",
    "            ax.set_title(f\"{combo_key} - {metric} (Pre vs Post)\", fontsize=14)\n",
    "            ax.set_ylabel(f\"{metric} Value\", fontsize=12)\n",
    "            ax.tick_params(axis='both', labelsize=12)\n",
    "\n",
    "            # Dynamic Y-axis handling\n",
    "            if all(-1 < v < 1 for v in values):\n",
    "                ax.set_ylim(-0.2, 0.2)\n",
    "            else:\n",
    "                ax.set_yscale('symlog', linthresh=0.01)\n",
    "                ax.set_ylim(-1.1, 1.1)\n",
    "\n",
    "            ax.grid(True, axis='y')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        display(widgets.HTML(f\"<h3>Fairness Metrics for: <code>{combo_key}</code></h3>\"))\n",
    "        display(fig)\n",
    "        plt.close(fig)\n",
    "\n",
    "\n",
    "def plot_fairness_metrics_comparison_old(fairness_logs: dict):\n",
    "    \"\"\"\n",
    "    Display 4 bar plots (SPD, AOD, EOD, DI) showing fairness metrics before and after post-processing.\n",
    "\n",
    "    Args:\n",
    "        fairness_logs (dict): A dictionary where keys are \"Preprocessing+Postprocessing\" combo names\n",
    "                              and values are a list of dicts with fairness metrics (keys: SPD, AOD, EOD, DI)\n",
    "                              at different stages (raw, preprocessed, postprocessed).\n",
    "    \"\"\"\n",
    "\n",
    "    for combo_key, stages in fairness_logs.items():\n",
    "        if len(stages) == 0:\n",
    "            continue\n",
    "\n",
    "        fig, axes = plt.subplots(4, 1, figsize=(8, 16))\n",
    "        metrics = [\n",
    "            \"statistical_parity_difference\",\n",
    "            \"disparate_impact\",\n",
    "            \"equal_opportunity_difference\",\n",
    "            \"average_odds_difference\",\n",
    "            \"theil_index\"\n",
    "        ]\n",
    "\n",
    "        for i, metric in enumerate(metrics):\n",
    "            values = []\n",
    "            labels = []\n",
    "            for idx, stage_dict in enumerate(stages):\n",
    "                label = [\"Raw\", \"Preprocessed\", \"Postprocessed\", \"Postprocessed Fair\"]\n",
    "                val = stage_dict.get(metric, None)\n",
    "                if val is not None:\n",
    "                    values.append(val)\n",
    "                    labels.append(label[idx] if idx < len(label) else f\"Stage {idx+1}\")\n",
    "\n",
    "            if values:\n",
    "                axes[i].bar(labels, values)\n",
    "                axes[i].set_title(f\"{combo_key} - {metric}\")\n",
    "                axes[i].set_ylabel(\"Value\")\n",
    "                axes[i].set_ylim(0, 1)\n",
    "                axes[i].grid(True, axis='y')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        display(widgets.HTML(f\"<h3>Fairness Metrics for: <code>{combo_key}</code></h3>\"))\n",
    "        display(plt.gcf())\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "\n",
    "def run_bias_detection_newer_version(b):\n",
    "    global global_output, current_state, selected_algorithm_parameters, selected_algorithms\n",
    "    current_state = \"Run\"\n",
    "    update_button_color(b)\n",
    "    clean_toolkit_content()\n",
    "\n",
    "    with global_output:\n",
    "        if df is None:\n",
    "            warning_msg = \"\"\"\n",
    "            <div style=\"background-color: #f0f0f0; border: 1px solid #ccc; color: #333333; padding: 15px; border-radius: 5px; width: auto; margin: 10px auto; text-align: left;\">\n",
    "                <span style=\"font-weight: bold; color: red; font-size: 16px;\">Warning:</span> \n",
    "                <span style=\"font-size: 14px\">No dataset selected.</span>\n",
    "            </div>\"\"\"\n",
    "            display(HTML(warning_msg))\n",
    "            return\n",
    "\n",
    "        # Algorithm + parameters summary\n",
    "        parameter_summary = \"\"\n",
    "        for alg in selected_algorithms:\n",
    "            param_dict = selected_algorithm_parameters.get(alg, {})\n",
    "            param_items = \"\".join([f\"<li><b>{k}:</b> {v}</li>\" for k, v in param_dict.items()])\n",
    "            parameter_summary += f\"<li><b>{alg}</b><ul>{param_items}</ul></li>\"\n",
    "\n",
    "        info_message_run = f\"\"\"\n",
    "        <div style=\"background-color: #f0f0f0; border: 1px solid #ccc; color: #333333; padding: 15px; border-radius: 5px; width: auto; margin: 10px auto; text-align: left;\">\n",
    "            <span style=\"font-weight: bold; color: #333333; font-size: 16px;\">\n",
    "                <i class=\"fa fa-play-circle\" style=\"margin-right: 10px;\"></i> Run Algorithm\n",
    "            </span>\n",
    "            <p style=\"font-size: 14px; margin-top: 10px;\">\n",
    "                We have run the following algorithm(s) on the selected dataset <b>{selected_dataset}</b>:\n",
    "            </p>\n",
    "            <ul style=\"font-size: 13px;\">{parameter_summary}</ul>\n",
    "        </div>\"\"\"\n",
    "        display(widgets.HTML(value=info_message_run))\n",
    "\n",
    "        metric_selector = widgets.Dropdown(\n",
    "            options=[\"FLAML Best Run\", \"Accuracy\", \"Conformal Coverage\"],\n",
    "            value=\"FLAML Best Run\",\n",
    "            description=\"Best by:\",\n",
    "            style={'description_width': 'initial'},\n",
    "            layout=widgets.Layout(width='50%')\n",
    "        )\n",
    "        display(metric_selector)\n",
    "\n",
    "        display(widgets.VBox([loading_bar]))\n",
    "        output_widget = widgets.Output()\n",
    "\n",
    "        def run_detection():\n",
    "            with output_widget:\n",
    "                if \"Multi-Dimensional Subset Scan (MDSS)\" in selected_algorithms:\n",
    "                    pass\n",
    "                    # config_path = \"configs/mdss.yaml\"\n",
    "                    # cfg = load_hydra_config(config_path)\n",
    "                    # scoring_function = Bernoulli(direction='negative')\n",
    "                    # scanner = MDSS(scoring_function)\n",
    "                    # mlflow.sklearn.autolog()\n",
    "                    # if mlflow.active_run():\n",
    "                    #     mlflow.end_run()\n",
    "                    # for n_iter in cfg.parameters.num_iters:\n",
    "                    #     for penalty in cfg.parameters.penalty:\n",
    "                    #         with mlflow.start_run(run_name=f\"n_iter={n_iter}_penalty={penalty}\"):\n",
    "                    #             try:\n",
    "                    #                 scanned_subset, _ = scanner.scan(\n",
    "                    #                     df[features_4_scanning],\n",
    "                    #                     expectations=df['predicted_conversion'],\n",
    "                    #                     outcomes=df['true_conversion'],\n",
    "                    #                     penalty=penalty,\n",
    "                    #                     num_iters=n_iter,\n",
    "                    #                     verbose=False\n",
    "                    #                 )\n",
    "                    #                 print(f\"Run complete: n_iter={n_iter}, penalty={penalty}\")\n",
    "                    #                 mlflow.log_param(\"num_iter\", n_iter)\n",
    "                    #                 mlflow.log_metric(\"penalty\", penalty)\n",
    "                    #                 print_report(df, scanned_subset)\n",
    "                    #             except Exception as e:\n",
    "                    #                 print(f\"Error for n_iter={n_iter}, penalty={penalty}: {e}\")\n",
    "                    #                 mlflow.log_param(\"error\", str(e))\n",
    "\n",
    "                elif \"Bias Detection via Optimal Transport (Logistic Regression)\" in selected_algorithms:\n",
    "                    pass\n",
    "                    # data_raw = load_preproc_data_adult()\n",
    "                    # data = data_raw.convert_to_dataframe()[0]\n",
    "                    # X = data.drop('Income Binary', axis=1)\n",
    "                    # y = data['Income Binary']\n",
    "                    # config_path = \"configs/config.yaml\"\n",
    "                    # cfg = load_hydra_config(config_path)\n",
    "                    # if mlflow.active_run():\n",
    "                    #     mlflow.end_run()\n",
    "                    # mlflow.autolog()\n",
    "                    # for n_iter in cfg.parameters.n_iter:\n",
    "                    #     for c in cfg.parameters.c:\n",
    "                    #         for penalty in cfg.parameters.penalty:\n",
    "                    #             with mlflow.start_run(run_name=f\"n_iter={n_iter}_c={c}_penalty={penalty}\"):\n",
    "                    #                 try:\n",
    "                    #                     penalty = penalty.lower().replace(' ', '_')\n",
    "                    #                     penalty_param = penalty if penalty != \"none\" else None\n",
    "                    #                     clf = LogisticRegression(\n",
    "                    #                         solver='lbfgs',\n",
    "                    #                         max_iter=n_iter,\n",
    "                    #                         C=c,\n",
    "                    #                         penalty=penalty_param\n",
    "                    #                     )\n",
    "                    #                     clf.fit(X, y)\n",
    "                    #                     preds = pd.Series(clf.predict_proba(X)[:, 0])\n",
    "                    #                     protected_attribute = features_4_scanning[0]\n",
    "                    #                     ot_val1 = ot_distance(y_true=y, y_pred=preds, prot_attr=data[protected_attribute])\n",
    "                    #                     bs1 = pd.DataFrame({protected_attribute: ot_val1.keys(), \"ot_val\": ot_val1.values()})\n",
    "                    #                     display(bs1)\n",
    "                    #                     mlflow.log_param(\"n_iter\", n_iter)\n",
    "                    #                     mlflow.log_param(\"C\", c)\n",
    "                    #                     mlflow.log_param(\"penalty\", penalty)\n",
    "                    #                     mlflow.log_metric(\"mean_ot_val\", bs1[\"ot_val\"].mean())\n",
    "                    #                     print(f\"Run complete: n_iter={n_iter}, C={c}, penalty={penalty}\")\n",
    "                    #                 except Exception as e:\n",
    "                    #                     print(f\"Error for n_iter={n_iter}, C={c}, penalty={penalty}: {e}\")\n",
    "                    #                     mlflow.log_param(\"error\", str(e))\n",
    "                    # best_run = get_best_configuration(metric_name=\"mean_ot_val\", maximize=False)\n",
    "                    # parameters = best_run[\"parameters\"]\n",
    "                    # metric = best_run[\"metric\"]\n",
    "                    # ot_best = widgets.VBox([\n",
    "                    #     widgets.HTML(\"<br><b><h2>Best Configuration Identified</h2></b>\"),\n",
    "                    #     widgets.HTML(f\"<b>Metric (mean_ot_val):</b> {metric:.6f}\"),\n",
    "                    #     widgets.HTML(\"<b>Best Parameters:</b>\"),\n",
    "                    #     widgets.HTML(\"<ul>\" + \"\".join([f\"<li>{key}: {value}</li>\" for key, value in parameters.items()]) + \"</ul>\")\n",
    "                    # ])\n",
    "                    # display(ot_best)\n",
    "\n",
    "                elif \"Fairness Aware Counterfactuals for Subgroups (FACTS)\" in selected_algorithms:\n",
    "                    data = clean_dataset(X_adult.assign(income=y_adult), \"adult\")\n",
    "                    y = data['income']\n",
    "                    X = data.drop('income', axis=1)\n",
    "                    mlflow.sklearn.autolog()\n",
    "                    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=random_seed, stratify=y)\n",
    "                    categorical_features = X.select_dtypes(include=[\"object\", \"category\"]).columns.to_list()\n",
    "                    categorical_transformer = ColumnTransformer(\n",
    "                        transformers=[(\"one-hot-encoder\", OneHotEncoder(), categorical_features)],\n",
    "                        remainder=\"passthrough\"\n",
    "                    )\n",
    "                    n_iters = selected_algorithm_parameters['num_iterations']\n",
    "                    model = Pipeline([\n",
    "                        (\"one-hot-encoder\", categorical_transformer),\n",
    "                        (\"clf\", LogisticRegression(max_iter=n_iters))\n",
    "                    ])\n",
    "                    model.fit(X_train, y_train)\n",
    "                    metric = selected_algorithm_parameters['metric']\n",
    "                    top_count = selected_algorithm_parameters['top_count']\n",
    "                    viewpoint = selected_algorithm_parameters['viewpoint']\n",
    "                    phi = selected_algorithm_parameters.get('phi', 0.5)\n",
    "                    c = selected_algorithm_parameters.get('c', 0.5)\n",
    "                    freq_itemset_min_supp = selected_algorithm_parameters['itemset_min_support']\n",
    "                    protected_attribute = features_4_scanning[0]\n",
    "                    detector = FACTS(\n",
    "                        clf=model,\n",
    "                        prot_attr=protected_attribute,\n",
    "                        freq_itemset_min_supp=freq_itemset_min_supp,\n",
    "                        feature_weights={f: 1 for f in X.columns},\n",
    "                        feats_not_allowed_to_change=not_to_change_features,\n",
    "                    )\n",
    "                    detector.fit(X_test, verbose=False)\n",
    "                    filter_seq = [\"remove-fair-rules\"]\n",
    "                    if metric == \"equal-effectiveness-within-budget\":\n",
    "                        filter_seq.append(\"remove-above-thr-cost\")\n",
    "                    if metric in [\"equal-choice-for-recourse\", \"equal-cost-of-effectiveness\"] and viewpoint == \"macro\":\n",
    "                        filter_seq.append(\"remove-below-thr-corr\")\n",
    "                    if metric == \"equal-cost-of-effectiveness\" and viewpoint == \"micro\":\n",
    "                        filter_seq.append(\"keep-rules-until-thr-corr-reached\")\n",
    "                    detector.bias_scan(\n",
    "                        metric=metric,\n",
    "                        viewpoint=viewpoint,\n",
    "                        sort_strategy=\"max-cost-diff-decr\",\n",
    "                        top_count=top_count,\n",
    "                        filter_sequence=filter_seq,\n",
    "                        phi=phi,\n",
    "                        c=c,\n",
    "                    )\n",
    "                    correctness_metric = metric in [\"equal-effectiveness\", \"equal-effectiveness-within-budget\"]\n",
    "                    detector.print_recourse_report(\n",
    "                        show_subgroup_costs=True,\n",
    "                        show_action_costs=True,\n",
    "                        correctness_metric=correctness_metric,\n",
    "                    )\n",
    "\n",
    "                else:\n",
    "                    selected_metric = metric_selector.value\n",
    "                    df_results, best_run, mlflow_runs = run_automl_pipelinev2(\n",
    "                        search_algo=\"tpe\",\n",
    "                        selected_algorithms=selected_algorithms,\n",
    "                        selected_algorithm_parameters=selected_algorithm_parameters\n",
    "                    )\n",
    "\n",
    "                    if df_results is None or df_results.empty:\n",
    "                        display(widgets.HTML(\"<b>No MLflow results returned.</b>\"))\n",
    "                        return\n",
    "\n",
    "                    if selected_metric not in df_results.columns:\n",
    "                        display(widgets.HTML(f\"<b>Metric '{selected_metric}' not found in results.</b>\"))\n",
    "                        return\n",
    "\n",
    "                    best_run = df_results.loc[df_results[selected_metric].idxmax()]\n",
    "                    metric_value = best_run[selected_metric]\n",
    "                    parameters = {\n",
    "                        \"Preprocessing\": best_run[\"Preprocessing\"],\n",
    "                        \"Postprocessing\": best_run[\"Postprocessing\"],\n",
    "                        \"Accuracy\": best_run.get(\"Accuracy\", \"N/A\"),\n",
    "                        \"Conformal Coverage\": best_run.get(\"Conformal Coverage\", \"N/A\")\n",
    "                    }\n",
    "                    ot_best = widgets.VBox([\n",
    "                        widgets.HTML(\"<br><b><h2>Best Configuration Identified</h2></b>\"),\n",
    "                        widgets.HTML(f\"<b>Metric ({selected_metric}):</b> {metric_value:.6f}\"),\n",
    "                        widgets.HTML(\"<b>Best Parameters:</b>\"),\n",
    "                        widgets.HTML(\"<ul>\" + \"\".join([f\"<li>{key}: {value}</li>\" for key, value in parameters.items()]) + \"</ul>\")\n",
    "                    ])\n",
    "                    display(ot_best)\n",
    "\n",
    "                    # Fairness metrics visualization\n",
    "                    # fairness_logs = {}\n",
    "                    # combo_key = f\"{best_run['Preprocessing']}+{best_run['Postprocessing']}\"\n",
    "                    # fairness_logs[combo_key] = []\n",
    "\n",
    "                    # for prefix in [\"raw_\", \"preprocessed_\", \"postprocessed_\"]:\n",
    "                    #     stage_metrics = {}\n",
    "                    #     for metric in [\"SPD\", \"AOD\", \"EOD\", \"DI\"]:\n",
    "                    #         col_name = f\"{prefix}{metric}\"\n",
    "                    #         if col_name in best_run:\n",
    "                    #             stage_metrics[metric.upper()] = best_run[col_name]\n",
    "                    #     if stage_metrics:\n",
    "                    #         fairness_logs[combo_key].append(stage_metrics)\n",
    "\n",
    "                    # post_fair_metrics = {}\n",
    "                    # for metric in [\"SPD\", \"AOD\", \"EOD\", \"DI\"]:\n",
    "                    #     col_name = f\"postprocessed_fair_{metric}\"\n",
    "                    #     if col_name in best_run:\n",
    "                    #         post_fair_metrics[metric.upper()] = best_run[col_name]\n",
    "                    # if post_fair_metrics:\n",
    "                    #     fairness_logs[combo_key].append(post_fair_metrics)\n",
    "                    if df_results is not None:\n",
    "                        fairness_logs = build_fairness_logs_from_best_run(best_run)\n",
    "                        # import pprint\n",
    "                        # pprint.pprint(fairness_logs)\n",
    "                        plot_fairness_metrics_comparison(fairness_logs)\n",
    "                    # Call to visualization function\n",
    "                    #plot_fairness_metrics_comparison(fairness_logs)\n",
    "\n",
    "        run_detection()\n",
    "        clean_toolkit_content()\n",
    "        display(output_widget)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###################################################################################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def run_bias_detection_new(b):\n",
    "    \"\"\" Currently only MDSS supported for demo purposes. \"\"\"\n",
    "    global global_output, current_state, selected_algorithm_parameters, selected_algorithms\n",
    "    current_state = \"Run\"\n",
    "    update_button_color(b)\n",
    "    clean_toolkit_content()\n",
    "\n",
    "    with global_output:\n",
    "        if df is None:\n",
    "            warning_msg = \"\"\"\n",
    "            <div>    \n",
    "                <div style=\"background-color: #f0f0f0; border: 1px solid #ccc; color: #333333; padding: 15px; border-radius: 5px; width: auto; margin: 10px auto; text-align: left;\">\n",
    "                <span style=\"font-weight: bold; color: red; font-size: 16px;\">Warning:</span> \n",
    "                <span style=\"font-size: 14px\">No dataset selected.</span>\n",
    "            </div>\"\"\"\n",
    "            display(HTML(warning_msg))\n",
    "            return\n",
    "\n",
    "        # 🔽 NEW: Construct parameter summary for all selected algorithms\n",
    "        parameter_summary = \"\"\n",
    "        for alg in selected_algorithms:\n",
    "            param_dict = selected_algorithm_parameters.get(alg, {})\n",
    "            param_items = \"\".join([f\"<li><b>{k}:</b> {v}</li>\" for k, v in param_dict.items()])\n",
    "            parameter_summary += f\"\"\"\n",
    "                <li>\n",
    "                    <b>{alg}</b>\n",
    "                    <ul>{param_items}</ul>\n",
    "                </li>\n",
    "            \"\"\"\n",
    "\n",
    "        # 🔽 Replace old info message with enhanced HTML block\n",
    "        info_message_run = f\"\"\"\n",
    "        <div style=\"background-color: #f0f0f0; border: 1px solid #ccc; color: #333333; padding: 15px; border-radius: 5px; width: auto; margin: 10px auto; text-align: left;\">\n",
    "            <span style=\"font-weight: bold; color: #333333; font-size: 16px;\">\n",
    "                <i class=\"fa fa-play-circle\" style=\"margin-right: 10px;\"></i> Run Algorithm\n",
    "            </span>\n",
    "            <p style=\"font-size: 14px; margin-top: 10px;\">\n",
    "                We have run the following algorithm(s) on the selected dataset <b>{selected_dataset}</b>:\n",
    "            </p>\n",
    "            <ul style=\"font-size: 13px;\">\n",
    "                {parameter_summary}\n",
    "            </ul>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "\n",
    "        # Create and show loading spinner\n",
    "        loading_box = widgets.VBox([loading_bar], layout=widgets.Layout(align_items='center', width='100%'))\n",
    "        display(loading_box)\n",
    "\n",
    "        output_widget = widgets.Output()\n",
    "\n",
    "        def run_detection():\n",
    "            with output_widget:\n",
    "                pass  # Keep your original implementation here\n",
    "                if selected_algorithm == \"Multi-Dimensional Subset Scan (MDSS)\":\n",
    "                    # Get selected parameters\n",
    "                    config_path = \"configs/mdss.yaml\"  \n",
    "                    cfg = load_hydra_config(config_path)\n",
    "                    # selected_scoring_function = selected_algorithm_parameters['scoring_function']\n",
    "                    # Init parameters\n",
    "                    # scoring_function = None\n",
    "                    # num_iters = selected_algorithm_parameters['num_iterations']\n",
    "                    # penalty = selected_algorithm_parameters['penalty']\n",
    "                    # if selected_scoring_function == \"Bernoulli\":\n",
    "                    scoring_function = Bernoulli(direction='negative')\n",
    "                    scanner = MDSS(scoring_function)\n",
    "                    mlflow.sklearn.autolog()\n",
    "                    if mlflow.active_run():\n",
    "                        mlflow.end_run()\n",
    "                    for n_iter in cfg.parameters.num_iters:\n",
    "                        for penalty in cfg.parameters.penalty:\n",
    "                            with mlflow.start_run(run_name=f\"n_iter={n_iter}_penalty={penalty}\"):\n",
    "                                try:\n",
    "                                    scanned_subset, _ = scanner.scan(df[features_4_scanning], \n",
    "                                        expectations = df['predicted_conversion'],\n",
    "                                        outcomes = df['true_conversion'], \n",
    "                                        penalty = penalty, \n",
    "                                        num_iters = n_iter,\n",
    "                                        verbose = False)\n",
    "                                    print(f\"Run complete: n_iter={n_iter}, penalty={penalty}\") \n",
    "                                    mlflow.log_param(\"num_iter\", n_iter)\n",
    "                                    mlflow.log_metric(\"penalty\", penalty)\n",
    "                                    print_report(df, scanned_subset)\n",
    "                                except Exception as e:\n",
    "                                    print(f\"Error for n_iter={n_iter}, penalty={penalty}: {e}\")\n",
    "                                    mlflow.log_param(\"error\", str(e))    \n",
    "                            #mlflow.log_metric(\"ot_val\", bs1[\"ot_val\"])\n",
    "                            # mlflow.log_metric(\"least_penalty\", bs1[\"ot_val\"].mean())       \n",
    "                elif selected_algorithm == \"Bias Detection via Optimal Transport (Logistic Regression)\":\n",
    "                    # Load the version of Adult that is used in the ot_demo ipynb\n",
    "                    \n",
    "                    data_raw = load_preproc_data_adult()\n",
    "                    data = data_raw.convert_to_dataframe()[0]\n",
    "                    data.head()\n",
    "                    \n",
    "                    X = data.drop('Income Binary',axis=1)\n",
    "                    y = data['Income Binary']\n",
    "                    \n",
    "                    config_path = \"configs/config.yaml\"  \n",
    "                    cfg = load_hydra_config(config_path)\n",
    "                    if mlflow.active_run():\n",
    "                        mlflow.end_run()\n",
    "                    mlflow.autolog()\n",
    "                    for n_iter in cfg.parameters.n_iter:\n",
    "                        for c in cfg.parameters.c:\n",
    "                            for penalty in cfg.parameters.penalty:\n",
    "                                with mlflow.start_run(run_name=f\"n_iter={n_iter}_c={c}_penalty={penalty}\"):\n",
    "                                    try:\n",
    "                                        # Configure penalty\n",
    "                                        penalty = penalty.lower().replace(' ', '_')\n",
    "                                        penalty_param = penalty if penalty != \"none\" else None\n",
    "\n",
    "                                        # Train Logistic Regression model\n",
    "                                        clf = LogisticRegression(\n",
    "                                            solver='lbfgs',\n",
    "                                            max_iter=n_iter,\n",
    "                                            C=c,\n",
    "                                        penalty=penalty_param\n",
    "                                        )\n",
    "                                        clf.fit(X, y)\n",
    "\n",
    "                                        # Predict probabilities and compute OT distance\n",
    "                                        preds = pd.Series(clf.predict_proba(X)[:, 0])\n",
    "                                        protected_attribute = features_4_scanning[0]\n",
    "                                        ot_val1 = ot_distance(y_true=y, y_pred=preds, prot_attr=data[protected_attribute])\n",
    "                                        # Create results DataFrame and display\n",
    "                                        bs1 = pd.DataFrame({protected_attribute: ot_val1.keys(), \"ot_val\": ot_val1.values()})\n",
    "                                        display(bs1)\n",
    "                                        # Log parameters and metrics to MLFlow\n",
    "                                        mlflow.log_param(\"n_iter\", n_iter)\n",
    "                                        mlflow.log_param(\"C\", c)\n",
    "                                        mlflow.log_param(\"penalty\", penalty)\n",
    "                                        #mlflow.log_metric(\"ot_val\", bs1[\"ot_val\"])\n",
    "                                        mlflow.log_metric(\"mean_ot_val\", bs1[\"ot_val\"].mean())\n",
    "                                        print(f\"Run complete: n_iter={n_iter}, C={c}, penalty={penalty}\")\n",
    "                                    except Exception as e:\n",
    "                                        print(f\"Error for n_iter={n_iter}, C={c}, penalty={penalty}: {e}\")\n",
    "                                        mlflow.log_param(\"error\", str(e))\n",
    "                    #identify the best configuration here\n",
    "                    metric_name=\"mean_ot_val\"\n",
    "                    best_run = get_best_configuration(metric_name=\"mean_ot_val\", maximize=False)\n",
    "                    parameters = best_run[\"parameters\"]\n",
    "                    metric = best_run[\"metric\"]\n",
    "                    ot_best = widgets.VBox([widgets.HTML(\"<br><b><h2>Best Configuration Identified</h2></b>\"),\n",
    "                                  widgets.HTML(f\"<b>Metric ({metric_name}):</b> {metric:.20f}\"),\n",
    "                                  widgets.HTML(\"<b>Best Parameters:</b>\"),\n",
    "                                  widgets.HTML(\"<ul>\" + \"\".join([f\"<li>{key}: {value}</li>\" for key, value in parameters.items()]) + \"</ul>\")])\n",
    "                    display(ot_best)\n",
    "                    # n_iter = selected_algorithm_parameters['num_iterations']\n",
    "                    # c = selected_algorithm_parameters['C']\n",
    "                    # penalty = selected_algorithm_parameters['penalty'].lower().replace(' ', '_')\n",
    "                    \n",
    "                    # clf = LogisticRegression(solver='lbfgs', \n",
    "                    #                          max_iter=n_iter, \n",
    "                    #                          C=c, \n",
    "                    #                          penalty=penalty)\n",
    "                    # clf.fit(X, y)\n",
    "                    # preds = pd.Series(clf.predict_proba(X)[:,0])\n",
    "                    # protected_attribute = features_4_scanning[0]\n",
    "                    # ot_val1 = ot_distance(y_true=y, y_pred=preds, prot_attr=data[protected_attribute])\n",
    "                    # bs1 = pd.DataFrame({protected_attribute: ot_val1.keys(), \"ot_val\": ot_val1.values()})\n",
    "                    # display(bs1)\n",
    "                elif selected_algorithm == \"Fairness Aware Counterfactuals for Subgroups (FACTS)\":\n",
    "                    # Load the version of Adult that is used in the ot_demo ipynb\n",
    "                    #### here, we incrementally build the example model. It consists of one preprocessing step,\n",
    "                    #### which is to turn categorical features into the respective one-hot encodings, and\n",
    "                    #### a simple scikit-learn logistic regressor.\n",
    "                    data = clean_dataset(X_adult.assign(income=y_adult), \"adult\")\n",
    "\n",
    "                    # split into train-test data\n",
    "                    y = data['income']\n",
    "                    X = data.drop('income', axis=1)\n",
    "                    mlflow.sklearn.autolog()\n",
    "                    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=random_seed, stratify=y)\n",
    "\n",
    "                    categorical_features = X.select_dtypes(include=[\"object\", \"category\"]).columns.to_list()\n",
    "                    \n",
    "                    categorical_features_onehot_transformer = ColumnTransformer(\n",
    "                        transformers=[\n",
    "                            (\"one-hot-encoder\", OneHotEncoder(), categorical_features)\n",
    "                        ],\n",
    "                        remainder=\"passthrough\"\n",
    "                    )\n",
    "                    n_iters = selected_algorithm_parameters['num_iterations']\n",
    "                    \n",
    "                    model = Pipeline([\n",
    "                        (\"one-hot-encoder\", categorical_features_onehot_transformer),\n",
    "                        (\"clf\", LogisticRegression(max_iter=n_iters))\n",
    "                    ])\n",
    "\n",
    "                    protected_attribute = features_4_scanning[0]\n",
    "                    with global_output:\n",
    "                        #### train the model\n",
    "                        model = model.fit(X_train, y_train)\n",
    "                        # showcase model's accuracy\n",
    "                        # y_pred = model.predict(X_test)\n",
    "                        # print(f\"Accuracy = {(y_test.values == y_pred).sum() / y_test.shape[0]:.2%}\")\n",
    "                        \n",
    "                        # Retrieve selected algorithms\n",
    "                        metric = selected_algorithm_parameters['metric']\n",
    "                        top_count = selected_algorithm_parameters['top_count']\n",
    "                        viewpoint = selected_algorithm_parameters['viewpoint']\n",
    "                        phi = selected_algorithm_parameters['phi'] if 'phi' in selected_algorithm_parameters else 0.5\n",
    "                        c = selected_algorithm_parameters['c'] if 'c' in selected_algorithm_parameters else 0.5\n",
    "                        freq_itemset_min_supp = selected_algorithm_parameters['itemset_min_support']\n",
    "\n",
    "                        detector = FACTS(\n",
    "                            clf=model,\n",
    "                            prot_attr=protected_attribute,\n",
    "                            freq_itemset_min_supp=freq_itemset_min_supp,\n",
    "                            feature_weights={f: 1 for f in X.columns},\n",
    "                            feats_not_allowed_to_change=not_to_change_features,\n",
    "                        )\n",
    "                        detector.fit(X_test, verbose=False)\n",
    "\n",
    "                        filter_seq = [\"remove-fair-rules\"]\n",
    "                        if metric == \"equal-effectiveness-within-budget\":\n",
    "                            filter_seq.append(\"remove-above-thr-cost\")\n",
    "                        if metric == \"equal-choice-for-recourse\" or (metric == \"equal-cost-of-effectiveness\" and viewpoint == \"macro\"):\n",
    "                            filter_seq.append(\"remove-below-thr-corr\")\n",
    "                        if metric == \"equal-cost-of-effectiveness\" and viewpoint == \"micro\":\n",
    "                            filter_seq.append(\"keep-rules-until-thr-corr-reached\")\n",
    "                        detector.bias_scan(\n",
    "                            metric=metric,\n",
    "                            viewpoint=viewpoint,\n",
    "                            sort_strategy=\"max-cost-diff-decr\",\n",
    "                            top_count=top_count,\n",
    "                            filter_sequence=filter_seq,\n",
    "                            phi=phi,\n",
    "                            c=c,\n",
    "                        )\n",
    "                        correctness_metric = metric in [\"equal-effectiveness\", \"equal-effectiveness-within-budget\"]\n",
    "                        detector.print_recourse_report(\n",
    "                            show_subgroup_costs=True,\n",
    "                            show_action_costs=True,\n",
    "                            correctness_metric=correctness_metric,\n",
    "                        )\n",
    "        \n",
    "        run_detection()\n",
    "\n",
    "        clean_toolkit_content()\n",
    "        display(widgets.HTML(value=info_message_run))\n",
    "        display(output_widget)\n",
    "\n",
    "\n",
    "\n",
    "#########adding interface to run_mlflow.py in the docker container\n",
    "\n",
    "import subprocess\n",
    "import time\n",
    "import mlflow\n",
    "import mlflow.tracking\n",
    "import pandas as pd\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "def run_automl_pipelinev2(\n",
    "    search_algo: str = \"tpe\",\n",
    "    mlflow_uri: str = \"http://192.168.1.151:5000\",\n",
    "    output_csv: str = \"mlflow_results.csv\",\n",
    "    parallel_limit: int = 3,\n",
    "    selected_algorithms: list = None,\n",
    "    selected_algorithm_parameters: dict = None\n",
    "):\n",
    "    import mlflow\n",
    "    import time\n",
    "    import subprocess\n",
    "    import pandas as pd\n",
    "    from joblib import Parallel, delayed\n",
    "\n",
    "    if selected_algorithms is None:\n",
    "        selected_algorithms = []\n",
    "\n",
    "    # ✅ Set MLflow URI\n",
    "    mlflow.set_tracking_uri(mlflow_uri)\n",
    "\n",
    "    # ✅ Known combinations\n",
    "    base_commands = [\n",
    "        [\"Reweighing\", \"EqOddsPostprocessing\"],\n",
    "        [\"Reweighing\", \"CalibratedEqOddsPostprocessing\"],\n",
    "        [\"Reweighing\", \"RejectOptionClassification\"]\n",
    "    ]\n",
    "\n",
    "    docker_commands = []\n",
    "    for combo in base_commands:\n",
    "        if all(any(alg_fragment in sel_alg for sel_alg in selected_algorithms) for alg_fragment in combo):\n",
    "            joined = \" \".join(combo)\n",
    "            docker_commands.append(\n",
    "                f\"docker run --rm --network=host workable-experiment {joined} {search_algo}\"\n",
    "            )\n",
    "    if not docker_commands:\n",
    "        print(\"❌ No matching Docker commands for selected algorithms.\")\n",
    "        return None, None\n",
    "\n",
    "    def stop_experiment_containers():\n",
    "        try:\n",
    "            result = subprocess.run([\"docker\", \"ps\", \"--filter\", \"ancestor=workable-experiment\", \"-q\"], stdout=subprocess.PIPE, text=True)\n",
    "            container_ids = result.stdout.strip().split(\"\\n\")\n",
    "            for container in container_ids:\n",
    "                if container:\n",
    "                    subprocess.run([\"docker\", \"stop\", container])\n",
    "                    print(f\"🛑 Stopped container: {container}\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error stopping containers: {e}\")\n",
    "\n",
    "    def run_docker(command):\n",
    "        print(f\"🚀 Running: {command}\")\n",
    "        try:\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "            start_time = time.time()\n",
    "            while process.poll() is None:\n",
    "                time.sleep(1)\n",
    "                if time.time() - start_time > 50:\n",
    "                    print(f\"⏳ Timeout! Killing: {command}\")\n",
    "                    process.terminate()\n",
    "                    stop_experiment_containers()\n",
    "                    return\n",
    "            print(f\"✅ Completed: {command}\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error running: {command}, {e}\")\n",
    "\n",
    "    for i in range(0, len(docker_commands), parallel_limit):\n",
    "        batch = docker_commands[i:i+parallel_limit]\n",
    "        Parallel(n_jobs=len(batch))(delayed(run_docker)(cmd) for cmd in batch)\n",
    "\n",
    "    time.sleep(20)\n",
    "\n",
    "    # ✅ Fetch MLflow runs\n",
    "    client = mlflow.tracking.MlflowClient()\n",
    "    experiment = client.get_experiment_by_name(\"Default\")\n",
    "    if not experiment:\n",
    "        print(\"❌ MLflow experiment 'Default' not found.\")\n",
    "        return None, None\n",
    "\n",
    "    experiment_id = experiment.experiment_id\n",
    "    runs = client.search_runs(experiment_id)\n",
    "\n",
    "    run_data = []\n",
    "    for run in runs:\n",
    "        if run.info.status == \"FINISHED\" and \"mlflow.parentRunId\" not in run.data.tags:\n",
    "            run_data.append({\n",
    "                \"Run ID\": run.info.run_id,\n",
    "                \"Preprocessing\": run.data.params.get(\"preprocessing_algorithm\", \"Unknown\"),\n",
    "                \"Postprocessing\": run.data.params.get(\"postprocessing_algorithm\", \"Unknown\"),\n",
    "                \"Accuracy\": run.data.metrics.get(\"accuracy\", 0),\n",
    "                \"Conformal Coverage\": run.data.metrics.get(\"conformal_coverage\", 0),\n",
    "                \"FLAML Best Run\": run.data.metrics.get(\"flaml.best_run\", 0),\n",
    "                # ✅ Postprocessed Fairness Metrics\n",
    "                \"SPD (Post)\": run.data.metrics.get(\"postprocessed_statistical_parity_difference\", 0),\n",
    "                \"DI (Post)\": run.data.metrics.get(\"postprocessed_disparate_impact\", 0),\n",
    "                \"EOD (Post)\": run.data.metrics.get(\"postprocessed_equal_opportunity_difference\", 0),\n",
    "                \"AOD (Post)\": run.data.metrics.get(\"postprocessed_average_odds_difference\", 0),\n",
    "                \"Theil (Post)\": run.data.metrics.get(\"postprocessed_theil_index\", 0),\n",
    "\n",
    "                # ✅ Preprocessed Fairness Metrics\n",
    "                \"SPD (Pre)\": run.data.metrics.get(\"preprocessed_statistical_parity_difference\", 0),\n",
    "                \"DI (Pre)\": run.data.metrics.get(\"preprocessed_disparate_impact\", 0),\n",
    "                \"EOD (Pre)\": run.data.metrics.get(\"preprocessed_equal_opportunity_difference\", 0),\n",
    "                \"AOD (Pre)\": run.data.metrics.get(\"preprocessed_average_odds_difference\", 0),\n",
    "                \"Theil (Pre)\": run.data.metrics.get(\"preprocessed_theil_index\", 0)\n",
    "            })\n",
    "\n",
    "    df = pd.DataFrame(run_data)\n",
    "    # df.to_csv(output_csv, index=False)\n",
    "    # print(f\"✅ Results saved to `{output_csv}`\")\n",
    "    # print(df)\n",
    "\n",
    "    if not df.empty:\n",
    "        best_flaml_run = df.loc[df[\"FLAML Best Run\"].idxmax()]\n",
    "        print(f\"🏆 Best Run (FLAML):\\n{best_flaml_run}\")\n",
    "    else:\n",
    "        print(\"❌ No successful runs found.\")\n",
    "        best_flaml_run = None\n",
    "\n",
    "    return df, best_flaml_run, runs\n",
    "\n",
    "\n",
    "\n",
    "def run_automl_pipeline(\n",
    "    search_algo: str = \"tpe\",\n",
    "    mlflow_uri: str = \"http://192.168.1.151:5000\",\n",
    "    output_csv: str = \"mlflow_results.csv\",\n",
    "    parallel_limit: int = 3,\n",
    "    selected_algorithms: list = None,\n",
    "    selected_algorithm_parameters: dict = None\n",
    "):\n",
    "    \"\"\"\n",
    "    Run fairness-aware AutoML experiments with selected algorithms and parameters using Docker and aggregate MLflow results.\n",
    "\n",
    "    Args:\n",
    "        search_algo (str): 'tpe' or 'random'\n",
    "        mlflow_uri (str): URI to the MLflow tracking server\n",
    "        output_csv (str): Output file to save results\n",
    "        parallel_limit (int): Number of parallel containers to run\n",
    "        selected_algorithms (list): List of selected algorithm names, e.g. [\"Reweighing\", \"EqOddsPostprocessing\"]\n",
    "        selected_algorithm_parameters (dict): Parameter dict per algorithm (not used here, but for future logic)\n",
    "    \"\"\"\n",
    "\n",
    "    if selected_algorithms is None:\n",
    "        selected_algorithms = []\n",
    "\n",
    "    # ✅ Set MLflow URI\n",
    "    mlflow.set_tracking_uri(mlflow_uri)\n",
    "\n",
    "    # ✅ All known docker command templates\n",
    "    base_commands = [\n",
    "        [\"Reweighing\", \"EqOddsPostprocessing\"],\n",
    "        [\"Reweighing\", \"CalibratedEqOddsPostprocessing\"],\n",
    "        [\"Reweighing\", \"RejectOptionClassification\"]\n",
    "    ]\n",
    "\n",
    "    # ✅ Build only the docker commands that match selected_algorithms\n",
    "    docker_commands = []\n",
    "    for combo in base_commands:\n",
    "        if all(any(alg_fragment in sel_alg for sel_alg in selected_algorithms) for alg_fragment in combo):\n",
    "            joined = \" \".join(combo)\n",
    "            docker_commands.append(\n",
    "                #f\"docker run --rm --network=host mlflow-automl-experiment {joined} {search_algo}\"\n",
    "                f\"docker run --rm --network=host workable-experiment {joined} {search_algo}\"\n",
    "            )\n",
    "    if not docker_commands:\n",
    "        print(\"❌ No matching Docker commands for selected algorithms.\")\n",
    "        return\n",
    "\n",
    "    # ✅ Function to stop related Docker containers\n",
    "    def stop_experiment_containers():\n",
    "        try:\n",
    "            result = subprocess.run([\"docker\", \"ps\", \"--filter\", \"ancestor=workable-experiment\", \"-q\"], stdout=subprocess.PIPE, text=True)\n",
    "            container_ids = result.stdout.strip().split(\"\\n\")\n",
    "            for container in container_ids:\n",
    "                if container:\n",
    "                    subprocess.run([\"docker\", \"stop\", container])\n",
    "                    print(f\"🛑 Stopped container: {container}\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error stopping containers: {e}\")\n",
    "\n",
    "    # ✅ Run each Docker command with timeout\n",
    "    def run_docker(command):\n",
    "        #print(f\"🚀 Running: {command}\")\n",
    "        try:\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "            start_time = time.time()\n",
    "            while process.poll() is None:\n",
    "                time.sleep(1)\n",
    "                if time.time() - start_time > 50:\n",
    "                    print(f\"⏳ Timeout! Killing: {command}\")\n",
    "                    process.terminate()\n",
    "                    stop_experiment_containers()\n",
    "                    return\n",
    "            #print(f\"✅ Completed: {command}\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error running: {command}, {e}\")\n",
    "\n",
    "    # ✅ Run Docker commands in parallel batches\n",
    "    for i in range(0, len(docker_commands), parallel_limit):\n",
    "        batch = docker_commands[i:i+parallel_limit]\n",
    "        Parallel(n_jobs=len(batch))(delayed(run_docker)(cmd) for cmd in batch)\n",
    "\n",
    "    time.sleep(20)  # wait for MLflow logs to flush\n",
    "\n",
    "    # ✅ Fetch completed MLflow runs\n",
    "    client = mlflow.tracking.MlflowClient()\n",
    "    experiment = client.get_experiment_by_name(\"Default\")\n",
    "    if not experiment:\n",
    "        print(\"❌ MLflow experiment 'Default' not found.\")\n",
    "        return\n",
    "\n",
    "    experiment_id = experiment.experiment_id\n",
    "    runs = client.search_runs(experiment_id)\n",
    "\n",
    "    # ✅ Extract relevant run info\n",
    "    run_data = []\n",
    "    for run in runs:\n",
    "        if run.info.status == \"FINISHED\":\n",
    "            run_data.append({\n",
    "                \"Run ID\": run.info.run_id,\n",
    "                \"Preprocessing\": run.data.params.get(\"preprocessing_algorithm\", \"Unknown\"),\n",
    "                \"Postprocessing\": run.data.params.get(\"postprocessing_algorithm\", \"Unknown\"),\n",
    "                \"Accuracy\": run.data.metrics.get(\"accuracy\", 0),\n",
    "                \"Conformal Coverage\": run.data.metrics.get(\"conformal_coverage\", 0),\n",
    "                \"FLAML Best Run\": run.data.metrics.get(\"flaml.best_run\", 0)\n",
    "            })\n",
    "\n",
    "    df = pd.DataFrame(run_data)\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"✅ Results saved to `{output_csv}`\")\n",
    "    print(df)\n",
    "\n",
    "    if not df.empty:\n",
    "        best_flaml_run = df.loc[df[\"FLAML Best Run\"].idxmax()]\n",
    "        print(f\"🏆 Best Run (FLAML):\\n{best_flaml_run}\")\n",
    "    else:\n",
    "        print(\"❌ No successful runs found.\")\n",
    "    return df, best_flaml_run\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#############################################\n",
    "def run_bias_detection(b):\n",
    "    \"\"\" Currently only MDSS supported for demo purposes. \"\"\"\n",
    "    global global_output, current_state\n",
    "    current_state = \"Run\"\n",
    "    update_button_color(b)\n",
    "    clean_toolkit_content()\n",
    "    with global_output:\n",
    "        if df is None:\n",
    "            warning_msg = \"\"\"\n",
    "            <div>    \n",
    "                <div style=\"background-color: #f0f0f0; border: 1px solid #ccc; color: #333333; padding: 15px; border-radius: 5px; width: auto; margin: 10px auto; text-align: left;\">\n",
    "                <span style=\"font-weight: bold; color: red; font-size: 16px;\">Warning:</span> \n",
    "                <span style=\"font-size: 14px\">No dataset selected.</span>\n",
    "            </div>\"\"\"\n",
    "            display(HTML(warning_msg))\n",
    "            return\n",
    "        else:\n",
    "            info_message_run = f\"\"\"\n",
    "            <div style=\"background-color: #f0f0f0; border: 1px solid #ccc; color: #333333; padding: 15px; border-radius: 5px; width: auto; margin: 10px auto; text-align: left;\">\n",
    "                <span style=\"font-weight: bold; color: #333333; font-size: 16px;\">\n",
    "                    <i class=\"fa fa-play-circle\" style=\"margin-right: 10px;\"></i> Run Algorithm\n",
    "                </span>\n",
    "                <p style=\"font-size: 14px; margin-top: 10px;\">\n",
    "                    We have run the algorithm <b>{selected_algorithm}</b> with multiple parameters on the selected dataset <b>{selected_dataset}</b>.\n",
    "                </p>                \n",
    "            </div>\n",
    "            \"\"\"\n",
    "\n",
    "        # Create a VBox to center the loading bar\n",
    "        loading_box = widgets.VBox([loading_bar], layout=widgets.Layout(align_items='center', width='100%'))\n",
    "        \n",
    "        # Display the centered loading bar initially\n",
    "        display(loading_box)\n",
    "        \n",
    "        # Create an Output widget to capture all the outputs\n",
    "        output_widget = widgets.Output()\n",
    "\n",
    "        # Define a function to run the actual bias detection\n",
    "        def run_detection():\n",
    "            with output_widget:\n",
    "                if selected_algorithm == \"Multi-Dimensional Subset Scan (MDSS)\":\n",
    "                    # Get selected parameters\n",
    "                    config_path = \"configs/mdss.yaml\"  \n",
    "                    cfg = load_hydra_config(config_path)\n",
    "                    # selected_scoring_function = selected_algorithm_parameters['scoring_function']\n",
    "                    # Init parameters\n",
    "                    # scoring_function = None\n",
    "                    # num_iters = selected_algorithm_parameters['num_iterations']\n",
    "                    # penalty = selected_algorithm_parameters['penalty']\n",
    "                    # if selected_scoring_function == \"Bernoulli\":\n",
    "                    scoring_function = Bernoulli(direction='negative')\n",
    "                    scanner = MDSS(scoring_function)\n",
    "                    mlflow.sklearn.autolog()\n",
    "                    if mlflow.active_run():\n",
    "                        mlflow.end_run()\n",
    "                    for n_iter in cfg.parameters.num_iters:\n",
    "                        for penalty in cfg.parameters.penalty:\n",
    "                            with mlflow.start_run(run_name=f\"n_iter={n_iter}_penalty={penalty}\"):\n",
    "                                try:\n",
    "                                    scanned_subset, _ = scanner.scan(df[features_4_scanning], \n",
    "                                        expectations = df['predicted_conversion'],\n",
    "                                        outcomes = df['true_conversion'], \n",
    "                                        penalty = penalty, \n",
    "                                        num_iters = n_iter,\n",
    "                                        verbose = False)\n",
    "                                    print(f\"Run complete: n_iter={n_iter}, penalty={penalty}\") \n",
    "                                    mlflow.log_param(\"num_iter\", n_iter)\n",
    "                                    mlflow.log_metric(\"penalty\", penalty)\n",
    "                                    print_report(df, scanned_subset)\n",
    "                                except Exception as e:\n",
    "                                    print(f\"Error for n_iter={n_iter}, penalty={penalty}: {e}\")\n",
    "                                    mlflow.log_param(\"error\", str(e))    \n",
    "                            #mlflow.log_metric(\"ot_val\", bs1[\"ot_val\"])\n",
    "                            # mlflow.log_metric(\"least_penalty\", bs1[\"ot_val\"].mean())       \n",
    "                elif selected_algorithm == \"Bias Detection via Optimal Transport (Logistic Regression)\":\n",
    "                    # Load the version of Adult that is used in the ot_demo ipynb\n",
    "                    \n",
    "                    data_raw = load_preproc_data_adult()\n",
    "                    data = data_raw.convert_to_dataframe()[0]\n",
    "                    data.head()\n",
    "                    \n",
    "                    X = data.drop('Income Binary',axis=1)\n",
    "                    y = data['Income Binary']\n",
    "                    \n",
    "                    config_path = \"configs/config.yaml\"  \n",
    "                    cfg = load_hydra_config(config_path)\n",
    "                    if mlflow.active_run():\n",
    "                        mlflow.end_run()\n",
    "                    mlflow.autolog()\n",
    "                    for n_iter in cfg.parameters.n_iter:\n",
    "                        for c in cfg.parameters.c:\n",
    "                            for penalty in cfg.parameters.penalty:\n",
    "                                with mlflow.start_run(run_name=f\"n_iter={n_iter}_c={c}_penalty={penalty}\"):\n",
    "                                    try:\n",
    "                                        # Configure penalty\n",
    "                                        penalty = penalty.lower().replace(' ', '_')\n",
    "                                        penalty_param = penalty if penalty != \"none\" else None\n",
    "\n",
    "                                        # Train Logistic Regression model\n",
    "                                        clf = LogisticRegression(\n",
    "                                            solver='lbfgs',\n",
    "                                            max_iter=n_iter,\n",
    "                                            C=c,\n",
    "                                        penalty=penalty_param\n",
    "                                        )\n",
    "                                        clf.fit(X, y)\n",
    "\n",
    "                                        # Predict probabilities and compute OT distance\n",
    "                                        preds = pd.Series(clf.predict_proba(X)[:, 0])\n",
    "                                        protected_attribute = features_4_scanning[0]\n",
    "                                        ot_val1 = ot_distance(y_true=y, y_pred=preds, prot_attr=data[protected_attribute])\n",
    "                                        # Create results DataFrame and display\n",
    "                                        bs1 = pd.DataFrame({protected_attribute: ot_val1.keys(), \"ot_val\": ot_val1.values()})\n",
    "                                        display(bs1)\n",
    "                                        # Log parameters and metrics to MLFlow\n",
    "                                        mlflow.log_param(\"n_iter\", n_iter)\n",
    "                                        mlflow.log_param(\"C\", c)\n",
    "                                        mlflow.log_param(\"penalty\", penalty)\n",
    "                                        #mlflow.log_metric(\"ot_val\", bs1[\"ot_val\"])\n",
    "                                        mlflow.log_metric(\"mean_ot_val\", bs1[\"ot_val\"].mean())\n",
    "                                        print(f\"Run complete: n_iter={n_iter}, C={c}, penalty={penalty}\")\n",
    "                                    except Exception as e:\n",
    "                                        print(f\"Error for n_iter={n_iter}, C={c}, penalty={penalty}: {e}\")\n",
    "                                        mlflow.log_param(\"error\", str(e))\n",
    "                    #identify the best configuration here\n",
    "                    metric_name=\"mean_ot_val\"\n",
    "                    best_run = get_best_configuration(metric_name=\"mean_ot_val\", maximize=False)\n",
    "                    parameters = best_run[\"parameters\"]\n",
    "                    metric = best_run[\"metric\"]\n",
    "                    ot_best = widgets.VBox([widgets.HTML(\"<br><b><h2>Best Configuration Identified</h2></b>\"),\n",
    "                                  widgets.HTML(f\"<b>Metric ({metric_name}):</b> {metric:.20f}\"),\n",
    "                                  widgets.HTML(\"<b>Best Parameters:</b>\"),\n",
    "                                  widgets.HTML(\"<ul>\" + \"\".join([f\"<li>{key}: {value}</li>\" for key, value in parameters.items()]) + \"</ul>\")])\n",
    "                    display(ot_best)\n",
    "                    # n_iter = selected_algorithm_parameters['num_iterations']\n",
    "                    # c = selected_algorithm_parameters['C']\n",
    "                    # penalty = selected_algorithm_parameters['penalty'].lower().replace(' ', '_')\n",
    "                    \n",
    "                    # clf = LogisticRegression(solver='lbfgs', \n",
    "                    #                          max_iter=n_iter, \n",
    "                    #                          C=c, \n",
    "                    #                          penalty=penalty)\n",
    "                    # clf.fit(X, y)\n",
    "                    # preds = pd.Series(clf.predict_proba(X)[:,0])\n",
    "                    # protected_attribute = features_4_scanning[0]\n",
    "                    # ot_val1 = ot_distance(y_true=y, y_pred=preds, prot_attr=data[protected_attribute])\n",
    "                    # bs1 = pd.DataFrame({protected_attribute: ot_val1.keys(), \"ot_val\": ot_val1.values()})\n",
    "                    # display(bs1)\n",
    "                elif selected_algorithm == \"Fairness Aware Counterfactuals for Subgroups (FACTS)\":\n",
    "                    # Load the version of Adult that is used in the ot_demo ipynb\n",
    "                    #### here, we incrementally build the example model. It consists of one preprocessing step,\n",
    "                    #### which is to turn categorical features into the respective one-hot encodings, and\n",
    "                    #### a simple scikit-learn logistic regressor.\n",
    "                    data = clean_dataset(X_adult.assign(income=y_adult), \"adult\")\n",
    "\n",
    "                    # split into train-test data\n",
    "                    y = data['income']\n",
    "                    X = data.drop('income', axis=1)\n",
    "                    mlflow.sklearn.autolog()\n",
    "                    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=random_seed, stratify=y)\n",
    "\n",
    "                    categorical_features = X.select_dtypes(include=[\"object\", \"category\"]).columns.to_list()\n",
    "                    \n",
    "                    categorical_features_onehot_transformer = ColumnTransformer(\n",
    "                        transformers=[\n",
    "                            (\"one-hot-encoder\", OneHotEncoder(), categorical_features)\n",
    "                        ],\n",
    "                        remainder=\"passthrough\"\n",
    "                    )\n",
    "                    n_iters = selected_algorithm_parameters['num_iterations']\n",
    "                    \n",
    "                    model = Pipeline([\n",
    "                        (\"one-hot-encoder\", categorical_features_onehot_transformer),\n",
    "                        (\"clf\", LogisticRegression(max_iter=n_iters))\n",
    "                    ])\n",
    "\n",
    "                    protected_attribute = features_4_scanning[0]\n",
    "                    with global_output:\n",
    "                        #### train the model\n",
    "                        model = model.fit(X_train, y_train)\n",
    "                        # showcase model's accuracy\n",
    "                        # y_pred = model.predict(X_test)\n",
    "                        # print(f\"Accuracy = {(y_test.values == y_pred).sum() / y_test.shape[0]:.2%}\")\n",
    "                        \n",
    "                        # Retrieve selected algorithms\n",
    "                        metric = selected_algorithm_parameters['metric']\n",
    "                        top_count = selected_algorithm_parameters['top_count']\n",
    "                        viewpoint = selected_algorithm_parameters['viewpoint']\n",
    "                        phi = selected_algorithm_parameters['phi'] if 'phi' in selected_algorithm_parameters else 0.5\n",
    "                        c = selected_algorithm_parameters['c'] if 'c' in selected_algorithm_parameters else 0.5\n",
    "                        freq_itemset_min_supp = selected_algorithm_parameters['itemset_min_support']\n",
    "\n",
    "                        detector = FACTS(\n",
    "                            clf=model,\n",
    "                            prot_attr=protected_attribute,\n",
    "                            freq_itemset_min_supp=freq_itemset_min_supp,\n",
    "                            feature_weights={f: 1 for f in X.columns},\n",
    "                            feats_not_allowed_to_change=not_to_change_features,\n",
    "                        )\n",
    "                        detector.fit(X_test, verbose=False)\n",
    "\n",
    "                        filter_seq = [\"remove-fair-rules\"]\n",
    "                        if metric == \"equal-effectiveness-within-budget\":\n",
    "                            filter_seq.append(\"remove-above-thr-cost\")\n",
    "                        if metric == \"equal-choice-for-recourse\" or (metric == \"equal-cost-of-effectiveness\" and viewpoint == \"macro\"):\n",
    "                            filter_seq.append(\"remove-below-thr-corr\")\n",
    "                        if metric == \"equal-cost-of-effectiveness\" and viewpoint == \"micro\":\n",
    "                            filter_seq.append(\"keep-rules-until-thr-corr-reached\")\n",
    "                        detector.bias_scan(\n",
    "                            metric=metric,\n",
    "                            viewpoint=viewpoint,\n",
    "                            sort_strategy=\"max-cost-diff-decr\",\n",
    "                            top_count=top_count,\n",
    "                            filter_sequence=filter_seq,\n",
    "                            phi=phi,\n",
    "                            c=c,\n",
    "                        )\n",
    "                        correctness_metric = metric in [\"equal-effectiveness\", \"equal-effectiveness-within-budget\"]\n",
    "                        detector.print_recourse_report(\n",
    "                            show_subgroup_costs=True,\n",
    "                            show_action_costs=True,\n",
    "                            correctness_metric=correctness_metric,\n",
    "                        )\n",
    "                        \n",
    "        # Run the bias detection function\n",
    "        run_detection()\n",
    "        \n",
    "        # Clear the loading bar and display all the captured outputs\n",
    "        clean_toolkit_content()\n",
    "        display(widgets.HTML(value=info_message_run))\n",
    "        display(output_widget)\n",
    "      \n",
    "### for EXPLAINABILITY TOOLKIT ###\n",
    "def select_explainability_dataset(b):\n",
    "    global df\n",
    "    \n",
    "    with global_output:\n",
    "        display_running_animation(duration=10)    \n",
    "        df = helpers.load_adult_income_dataset()\n",
    "        clean_toolkit_content()\n",
    "        # update_status(loaded=True)\n",
    "        display(output_status)\n",
    "\n",
    "        warning_message = \"\"\"\n",
    "        <div style=\"background-color: #ffeb99; border: 1px solid #ffcc00; color: #cc6600; padding: 10px; border-radius: 5px;\">\n",
    "            <span style=\"font-weight: bold; color: #ff6600;\">Warning:</span>\n",
    "            Default dataset (\"Adult\") selected from UCI ML repository.\n",
    "        </div>\n",
    "        \"\"\"\n",
    "\n",
    "        dataset_select_warning = widgets.HTML(\n",
    "            value=warning_message,\n",
    "            layout=widgets.Layout(margin='0px', width='100%', padding='5px 0px 5px 0px')\n",
    "        )\n",
    "        display(dataset_select_warning)\n",
    "        \n",
    "        display_dataframe_styled(df.head())\n",
    "        display_dataframe_styled(df.describe())\n",
    "\n",
    "        features_to_plot = [\"age\", \"workclass\", \"education\", \"marital_status\", \n",
    "                            \"occupation\", \"race\", \"gender\", \"hours_per_week\", \"income\"]\n",
    "        plot_histogram_grid(features_to_plot)\n",
    "              \n",
    "def give_parameters_and_explainability_model(b):\n",
    "    with global_output:\n",
    "        warning_message = \"\"\"\n",
    "        <div style=\"background-color: #ffeb99; border: 1px solid #ffcc00; color: #cc6600; padding: 10px; border-radius: 5px;\">\n",
    "            <span style=\"font-weight: bold; color: #ff6600;\">Warning:</span>\n",
    "            Default input parameters and explainability model (DiCE) selected.\n",
    "        </div>\n",
    "        \"\"\"\n",
    "        explainability_model_warning = widgets.HTML(\n",
    "            value=warning_message,\n",
    "            layout=widgets.Layout(margin='0px', width='100%', padding='5px 0px 5px 0px')\n",
    "        )\n",
    "        clean_toolkit_content()\n",
    "        display(explainability_model_warning)\n",
    "\n",
    "def select_explainability_action(b):\n",
    "    with global_output:\n",
    "        warning_message = \"\"\"\n",
    "        <div style=\"background-color: #ffeb99; border: 1px solid #ffcc00; color: #cc6600; padding: 10px; border-radius: 5px;\">\n",
    "            <span style=\"font-weight: bold; color: #ff6600;\">Warning:</span>\n",
    "            Default action selected: Local Explanations.\n",
    "        </div>\n",
    "        \"\"\"\n",
    "        explainability_action_warning = widgets.HTML(\n",
    "            value=warning_message,\n",
    "            layout=widgets.Layout(margin='0px', width='100%', padding='5px 0px 5px 0px')\n",
    "        )\n",
    "        clean_toolkit_content()\n",
    "        display(explainability_action_warning)\n",
    "\n",
    "def plot_feature_importance(feature_importance, title):\n",
    "    # Convert feature importance to a sorted list of tuples\n",
    "    sorted_importance = sorted(feature_importance.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    if not sorted_importance:\n",
    "        display(HTML(f\"<p>No feature importance data available for {title}.</p>\"))\n",
    "        return\n",
    "    \n",
    "    features, importances = zip(*sorted_importance)\n",
    "\n",
    "    # Plot the feature importance\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    sns.barplot(x=list(importances), y=list(features), palette=\"Set2\", ax=ax)\n",
    "    ax.set_title(title, fontsize=14, fontweight='bold')\n",
    "    ax.set_xlabel('Importance', fontsize=12)\n",
    "    ax.set_ylabel('Features', fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "def run_explainability(b):\n",
    "    \"\"\" Currently only DiCE is supported for demo purposes. \"\"\"\n",
    "    with global_output:\n",
    "        clean_toolkit_content()\n",
    "        display_running_animation(duration=10)\n",
    "        target = df[\"income\"]\n",
    "        train_dataset, test_dataset, y_train, y_test = train_test_split(df,\n",
    "                                                                        target,\n",
    "                                                                        test_size=0.2,\n",
    "                                                                        random_state=0,\n",
    "                                                                        stratify=target)\n",
    "        x_train = train_dataset.drop('income', axis=1)\n",
    "        x_test = test_dataset.drop('income', axis=1)\n",
    "        # Step 1: dice_ml.Data\n",
    "        d = dice_ml.Data(dataframe=train_dataset, continuous_features=['age', 'hours_per_week'], outcome_name='income')\n",
    "        numerical = [\"age\", \"hours_per_week\"]\n",
    "        categorical = x_train.columns.difference(numerical)\n",
    "\n",
    "        categorical_transformer = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "        transformations = ColumnTransformer(transformers=[('cat', categorical_transformer, categorical)])\n",
    "\n",
    "        # Append classifier to preprocessing pipeline.\n",
    "        # Now we have a full prediction pipeline.\n",
    "        clf = Pipeline(steps=[('preprocessor', transformations),('classifier', RandomForestClassifier())])\n",
    "        model = clf.fit(x_train, y_train)\n",
    "        \n",
    "        # Using sklearn backend\n",
    "        m = dice_ml.Model(model=model, backend=\"sklearn\")\n",
    "        # Using method=random for generating CFs\n",
    "        exp = dice_ml.Dice(d, m, method=\"random\")\n",
    "        \n",
    "        e1 = exp.generate_counterfactuals(x_test[0:1], total_CFs=2, desired_class=\"opposite\")\n",
    "        display_message(\"Counterfactuals\", font_weight=\"bold\")\n",
    "        e1.visualize_as_dataframe(show_only_changes=True)\n",
    "        e1.visualize_as_dataframe(show_only_changes=False)\n",
    "        \n",
    "        display_message(\"Local Feature Importance\", font_weight=\"bold\")\n",
    "        query_instance = x_test[0:1]\n",
    "        imp = exp.local_feature_importance(query_instance, total_CFs=10)\n",
    "        # print(imp.local_importance)\n",
    "        plot_feature_importance(imp.local_importance[0], \"Local Feature Importance\")\n",
    "\n",
    "        display_message(\"Global Feature Importance\", font_weight=\"bold\")\n",
    "        query_instances = x_test[0:20]\n",
    "        imp = exp.global_feature_importance(query_instances)\n",
    "        # print(imp.summary_importance)\n",
    "        plot_feature_importance(imp.summary_importance, \"Global Feature Importance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display\n",
    "display_home_screen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
